{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome, Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser=Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://arxiv.org'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_search=browser.find_element_by_name('query')\n",
    "main_search.send_keys('healthcare')\n",
    "main_search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=browser.page_source\n",
    "#tables=pd.read_html(html)\n",
    "#tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(html,'lxml')\n",
    "data=[]\n",
    "#result=soup.select('.arxiv-result')[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=soup.find_all('li', {'class': 'arxiv-result'})\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]\n",
    "title=[]\n",
    "arxiv_id=[]\n",
    "article_link=[]\n",
    "pdf_link=[]\n",
    "author_list_arr=[]\n",
    "abstract=[]\n",
    "date=[]\n",
    "tag_list_arr=[]\n",
    "doi_tag=[]\n",
    "tags=[]\n",
    "\n",
    "for row in result:\n",
    "    title.append(row.find('p', {'class': 'title is-5 mathjax'}).text)   \n",
    "    list_title=row.find('p', {'class': 'list-title is-inline-block'})\n",
    "    arxiv_id.append(list_title.find('a').text[6:])\n",
    "    article_link.append(list_title.find('a')['href'])\n",
    "    pdf_link.append(list_title.find('span').find('a')['href'])\n",
    "    authors=row.find('p', {'class': 'authors'}).find_all('a')\n",
    "    author_list=''\n",
    "    for author in authors:\n",
    "        author_list=author_list + author.text + ','\n",
    "    author_list_arr.append(author_list)\n",
    "    abstract.append(row.find('p', {'class': 'abstract mathjax'}).text)\n",
    "    date.append(row.find('p', {'class': 'is-size-7'}).text[10:26])\n",
    "    tag_list=''\n",
    "    for tag in tags:\n",
    "        tag_list=tag_list + tag.text + ','\n",
    "    tag_list_arr.append(tag_list)\n",
    "    doi=row.find('div', {'class': 'tags has-addons'})\n",
    "    if doi != None:\n",
    "        doi_tag.append(doi.find('span', {'class': 'tag is-light is-size-7'}).find('a').text)\n",
    "    else:\n",
    "        doi_tag.append('')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title=title.str.replace('\\n','',regex=True)\n",
    "#title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nAbstract:\\n      \\n        …of cardiologists, accurate and automatic diagnosis of ECG signals has become a hot research topic. Deep learning methods have demonstrated promising results in predictive healthcare tasks. In this paper, we developed a deep neural network for multi-label classification of cardiac arrhythmias in 12-lead ECG recordings. Experiments on a public 12-lead ECG data…\\n        ▽ More\\n\\n\\n        Electrocardiogram (ECG) is a widely used reliable, non-invasive approach for cardiovascular disease diagnosis. With the rapid growth of ECG examinations and the insufficiency of cardiologists, accurate and automatic diagnosis of ECG signals has become a hot research topic. Deep learning methods have demonstrated promising results in predictive healthcare tasks. In this paper, we developed a deep neural network for multi-label classification of cardiac arrhythmias in 12-lead ECG recordings. Experiments on a public 12-lead ECG dataset showed the effectiveness of our method. The proposed model achieved an average area under the receiver operating characteristic curve (AUC) of 0.970 and an average F1 score of 0.813. The deep model showed superior performance than 4 machine learning methods learned from extracted expert features. Besides, the deep models trained on single-lead ECGs produce lower performance than using all 12 leads simultaneously. The best-performing leads are lead I, aVR, and V5 among 12 leads. Finally, we employed the SHapley Additive exPlanations (SHAP) method to interpret the model's behavior at both patient level and population level. Our code is freely available at https://github.com/onlyzdd/ecg-diagnosis.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        Health data is a sensitive category of personal data. It might result in a high risk to individual and health information handling rights and opportunities unless there is a palatable defense. Reasonable security standards are needed to protect electronic health records (EHR). All personal data handling needs adequate explanation. Maintaining access to medical data even in the developing world wou…\\n        ▽ More\\n\\n\\n        Health data is a sensitive category of personal data. It might result in a high risk to individual and health information handling rights and opportunities unless there is a palatable defense. Reasonable security standards are needed to protect electronic health records (EHR). All personal data handling needs adequate explanation. Maintaining access to medical data even in the developing world would favor health and well-being across the world. Unfortunately, there are still countries that hinder the portability of medical records. Numerous occurrences have shown that it still takes weeks for the medical data to be ported from one general physician (GP) to another. Cross border portability is nearly impossible due to the lack of technical infrastructure and standardization. We demonstrate the difficulty of the portability of medical records with some example case studies as a collaborative engagement exercise through a data mapping process to describe how different people and datapoints interact and evaluate EHR portability techniques. We then propose a blockchain-based EHR system that allows secure, and cross border sharing of medical data. The ethical and technical challenges around having such a system have also been discussed in this study.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …advancement in achieving high compactness, high performance computing, high flexibility, and multiplexed functionality in smartphones have enabled them for many cutting-edge healthcare applications, such as single-molecule imaging, medical diagnosis, and biosensing, which were conventionally done with bulky and sophisticated devices. Most of the current…\\n        ▽ More\\n\\n\\n        Close to half of the world population have smartphones, while a typical flagship smartphone today has been integrated with more than 20 smart components and sensors, making a smartphone a highly integrated platform that can potentially mimic the five senses of humans. Recent advancement in achieving high compactness, high performance computing, high flexibility, and multiplexed functionality in smartphones have enabled them for many cutting-edge healthcare applications, such as single-molecule imaging, medical diagnosis, and biosensing, which were conventionally done with bulky and sophisticated devices. Most of the current healthcare applications are developed based on using the photon-sensitive components, such as CMOS sensors, flash & fill lights, lens modules, and LED lights in the screen, leaving the rest of the smart and high-performance sensors rarely explored. In this Perspective, we review recent progresses in advanced sensors in modern smartphones and discuss how those sensors have great, as yet unmet, promise to offer widespread and easy-to-implement solutions to many emerging healthcare applications, including nanoscale sensing, point-of-care testing, pollution monitoring, etc.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        Modeling infection spread during pandemics is not new, with models using past data to tune simulation parameters for predictions. These help understand the healthcare burden posed by a pandemic and respond accordingly. However, the problem of how college/university campuses should function during a pandemic is new for the following reasons:(i) social contact…\\n        ▽ More\\n\\n\\n        Modeling infection spread during pandemics is not new, with models using past data to tune simulation parameters for predictions. These help understand the healthcare burden posed by a pandemic and respond accordingly. However, the problem of how college/university campuses should function during a pandemic is new for the following reasons:(i) social contact in colleges are structured and can be engineered for chosen objectives, (ii) the last pandemic to cause such societal disruption was over 100 years ago, when higher education was not a critical part of society, (ii) not much was known about causes of pandemics, and hence effective ways of safe operations were not known, and (iii) today with distance learning, remote operation of an academic institution is possible. Our approach is unique in presenting a flexible simulation system, containing a suite of model libraries, one for each major component. The system integrates agent based modeling (ABM) and stochastic network approach, and models the interactions among individual entities, e.g., students, instructors, classrooms, residences, etc. in great detail. For each decision to be made, the system can be used to predict the impact of various choices, and thus enable the administrator to make informed decisions. While current approaches are good for infection modeling, they lack accuracy in social contact modeling. Our ABM approach, combined with ideas from Network Science, presents a novel approach to contact modeling. A detailed case study of the University of Minnesota's Sunrise Plan is presented. For each decisions made, its impact was assessed, and results used to get a measure of confidence. We believe this flexible tool can be a valuable asset for various kinds of organizations to assess their infection risks in pandemic-time operations, including middle and high schools, factories, warehouses, and small/medium sized businesses.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        The recent coronavirus pandemic has highlighted the many challenges faced by the healthcare, public safety, and economic systems when confronted with a surge in patients that require intensive treatment and a population that must be quarantined or shelter in place. The most obvious and pressing challenge is taking care of acutely ill patients while managing…\\n        ▽ More\\n\\n\\n        The recent coronavirus pandemic has highlighted the many challenges faced by the healthcare, public safety, and economic systems when confronted with a surge in patients that require intensive treatment and a population that must be quarantined or shelter in place. The most obvious and pressing challenge is taking care of acutely ill patients while managing spread of infection within the care facility, but this is just the tip of the iceberg if we consider what could be done to prepare in advance for future pandemics. Beyond the obvious need for strengthening medical knowledge and preparedness, there is a complementary need to anticipate and address the engineering challenges associated with infectious disease emergencies. Robotic technologies are inherently programmable, and robotic systems have been adapted and deployed, to some extent, in the current crisis for such purposes as transport, logistics, and disinfection. As technical capabilities advance and as the installed base of robotic systems increases in the future, they could play a much more significant role in future crises. This report is the outcome of a virtual workshop co-hosted by the National Academy of Engineering (NAE) and the Computing Community Consortium (CCC) held on July 9-10, 2020. The workshop consisted of over forty participants including representatives from the engineering/robotics community, clinicians, critical care workers, public health and safety experts, and emergency responders. It identifies key challenges faced by healthcare responders and the general population and then identifies robotic/technological responses to these challenges. Then it identifies the key research/knowledge barriers that need to be addressed in developing effective, scalable solutions. Finally, the report ends with the following recommendations on how to implement this strategy.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        Acute and chronic wounds are a challenge to healthcare systems around the world and affect many people's lives annually. Wound classification is a key step in wound diagnosis that would help clinicians to identify an optimal treatment procedure. Hence, having a high-performance classifier assists the specialists in the field to classify the wounds with l…\\n        ▽ More\\n\\n\\n        Acute and chronic wounds are a challenge to healthcare systems around the world and affect many people's lives annually. Wound classification is a key step in wound diagnosis that would help clinicians to identify an optimal treatment procedure. Hence, having a high-performance classifier assists the specialists in the field to classify the wounds with less financial and time costs. Different machine learning and deep learning-based wound classification methods have been proposed in the literature. In this study, we have developed an ensemble Deep Convolutional Neural Network-based classifier to classify wound images including surgical, diabetic, and venous ulcers, into multi-classes. The output classification scores of two classifiers (patch-wise and image-wise) are fed into a Multi-Layer Perceptron to provide a superior classification performance. A 5-fold cross-validation approach is used to evaluate the proposed method. We obtained maximum and average classification accuracy values of 96.4% and 94.28% for binary and 91.9\\\\% and 87.7\\\\% for 3-class classification problems. The results show that our proposed method can be used effectively as a decision support system in classification of wound images or other related clinical applications.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        Privacy protection in electronic healthcare applications is an important consideration due to the sensitive nature of personal health data. Internet of Health Things (IoHT) networks have privacy requirements within a healthcare setting. However, these networks have unique challenges and security requirements (integrity…\\n        ▽ More\\n\\n\\n        Privacy protection in electronic healthcare applications is an important consideration due to the sensitive nature of personal health data. Internet of Health Things (IoHT) networks have privacy requirements within a healthcare setting. However, these networks have unique challenges and security requirements (integrity, authentication, privacy and availability) must also be balanced with the need to maintain efficiency in order to conserve battery power, which can be a significant limitation in IoHT devices and networks. Data are usually transferred without undergoing filtering or optimization, and this traffic can overload sensors and cause rapid battery consumption when interacting with IoHT networks. This consequently poses restrictions on the practical implementation of these devices. As a solution to address the issues, this paper proposes a privacy-preserving two-tier data inference framework, this can conserve battery consumption by reducing the data size required to transmit through inferring the sensed data and can also protect the sensitive data from leakage to adversaries. Results from experimental evaluations on privacy show the validity of the proposed scheme as well as significant data savings without compromising the accuracy of the data transmission, which contributes to energy efficiency of IoHT sensor devices.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Question Answering (QA) on Electronic Health Records (EHR), namely EHR QA, can work as a crucial milestone towards developing an intelligent agent in healthcare. EHR data are typically stored in a relational database, which can also be converted to a Directed Acyclic Graph (DAG), allowing two approaches for EHR QA: Table-based QA and Knowledge Graph-based QA…\\n        ▽ More\\n\\n\\n        Question Answering (QA) on Electronic Health Records (EHR), namely EHR QA, can work as a crucial milestone towards developing an intelligent agent in healthcare. EHR data are typically stored in a relational database, which can also be converted to a Directed Acyclic Graph (DAG), allowing two approaches for EHR QA: Table-based QA and Knowledge Graph-based QA. We hypothesize that the graph-based approach is more suitable for EHR QA as graphs can represent relations between entities and values more naturally compared to tables, which essentially require JOIN operations. To validate our hypothesis, we first construct EHR QA datasets based on MIMIC-III, where the same question-answer pairs are represented in SQL (table-based) and SPARQL (graph-based), respectively. We then test a state-of-the-art EHR QA model on both datasets where the model demonstrated superior QA performance on the SPARQL version. Finally, we open-source both MIMICSQL* and MIMIC-SPARQL* to encourage further EHR QA research in both direction\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        Smart healthcare which is built as…\\n        ▽ More\\n\\n\\n        Smart healthcare which is built as healthcare Cyber-Physical System (H-CPS) from Internet-of-Medical-Things (IoMT) is becoming more important than before. Medical devices and their connectivity through Internet with alongwith the electronics health record (EHR) and AI analytics making H-CPS possible. IoMT-end devices like wearables and implantables are key for H-CPS based smart healthcare. Smart garment is a specific wearable which can be used for smart healthcare. There are various smart garments that help users to monitor their body vitals in real-time. Many commercially available garments collect the vital data and transmit it to the mobile application for visualization. However, these don't perform real-time analysis for the user to comprehend their health conditions. Also, such garments are not included with an alert system to alert users and contacts in case of emergency. In MyWear, we propose a wearable body vital monitoring garment that captures physiological data and automatically analyses such heart rate, stress level, muscle activity to detect abnormalities. A copy of the physiological data is transmitted to the cloud for detecting any abnormalities in heart beats and predict any potential heart failure in future. We also propose a deep neural network (DNN) model that automatically classifies abnormal heart beat and potential heart failure. For immediate assistance in such a situation, we propose an alert system that sends an alert message to nearby medical officials. The proposed MyWear has an average accuracy of 96.9% and precision of 97.3% for detection of the abnormalities.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        …discussed in detail. This paper also presents the role of IoT forensics in cybercrime investigation in various domains like smart homes, smart cities, automated vehicles, healthcare, etc. Along with the role of advanced technologies like Artificial Intelligence, Machine Learning, Cloud computing, Edge computing, Fog computing, and Blockchain technology in cy…\\n        ▽ More\\n\\n\\n        Internet of Things (IoT) is the utmost assuring framework to facilitate human life with quality and comfort. IoT has contributed significantly in numerous application areas. The stormy expansion of smart devices and their credence for data transfer on wireless mechanics boosts their susceptibility to cyber-attacks. Consequently, the rate of cybercrimes is increasing day by day. Hence, the study of IoT security threats and possible corrective measures can benefit the researchers to identify appropriate solutions to deal with various challenges in cybercrime investigation. IoT forensics plays a vital role in cybercrime investigation. This review paper presents an overview of the IoT framework consisting of IoT architecture, protocols, and technologies. Various security issues at each layer and corrective measures are also discussed in detail. This paper also presents the role of IoT forensics in cybercrime investigation in various domains like smart homes, smart cities, automated vehicles, healthcare, etc. Along with the role of advanced technologies like Artificial Intelligence, Machine Learning, Cloud computing, Edge computing, Fog computing, and Blockchain technology in cybercrime investigation are also discussed. At last, the various open research challenges in the area of IoT to assist cybercrime investigation are explained, which provide a new direction to the researchers to work further.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …technique (Hilbert Vector Arrangement). In this work we analyze fundamental financial data as well as financial ratio data and study companies from the financial, healthcare and IT sectors in the United States. We find that using imaging techniques to input data for CNN works better for financial ratio data but is not significantly better than simply using t…\\n        ▽ More\\n\\n\\n        In 2012, SEC mandated all corporate filings for any company doing business in US be entered into the Electronic Data Gathering, Analysis, and Retrieval (EDGAR) system. In this work we are investigating ways to analyze the data available through EDGAR database. This may serve portfolio managers (pension funds, mutual funds, insurance, hedge funds) to get automated insights into companies they invest in, to better manage their portfolios. The analysis is based on Artificial Neural Networks applied to the data.} In particular, one of the most popular machine learning methods, the Convolutional Neural Network (CNN) architecture, originally developed to interpret and classify images, is now being used to interpret financial data. This work investigates the best way to input data collected from the SEC filings into a CNN architecture. We incorporate accounting principles and mathematical methods into the design of three image encoding methods. Specifically, two methods are derived from accounting principles (Sequential Arrangement, Category Chunk Arrangement) and one is using a purely mathematical technique (Hilbert Vector Arrangement). In this work we analyze fundamental financial data as well as financial ratio data and study companies from the financial, healthcare and IT sectors in the United States. We find that using imaging techniques to input data for CNN works better for financial ratio data but is not significantly better than simply using the 1D input directly for fundamental data. We do not find the Hilbert Vector Arrangement technique to be significantly better than other imaging techniques.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …how this makes a fundamental difference in the interpretability and explainability of current approaches, and illustrate it with examples from natural language processing for healthcare and education applications.\\n        ▽ More\\n\\n\\n        The recent series of innovations in deep learning (DL) have shown enormous potential to impact individuals and society, both positively and negatively. The DL models utilizing massive computing power and enormous datasets have significantly outperformed prior historical benchmarks on increasingly difficult, well-defined research tasks across technology domains such as computer vision, natural language processing, signal processing, and human-computer interactions. However, the Black-Box nature of DL models and their over-reliance on massive amounts of data condensed into labels and dense representations poses challenges for interpretability and explainability of the system. Furthermore, DLs have not yet been proven in their ability to effectively utilize relevant domain knowledge and experience critical to human understanding. This aspect is missing in early data-focused approaches and necessitated knowledge-infused learning and other strategies to incorporate computational knowledge. This article demonstrates how knowledge, provided as a knowledge graph, is incorporated into DL methods using knowledge-infused learning, which is one of the strategies. We then discuss how this makes a fundamental difference in the interpretability and explainability of current approaches, and illustrate it with examples from natural language processing for healthcare and education applications.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …art by using improved claim and title guided hierarchical attention to model effective contextual cues. We show the efficacy of our approach on datasets concerning political, healthcare, and environmental issues.\\n        ▽ More\\n\\n\\n        We present SUMO, a neural attention-based approach that learns to establish the correctness of textual claims based on evidence in the form of text documents (e.g., news articles or Web documents). SUMO further generates an extractive summary by presenting a diversified set of sentences from the documents that explain its decision on the correctness of the textual claim. Prior approaches to address the problem of fact checking and evidence extraction have relied on simple concatenation of claim and document word embeddings as an input to claim driven attention weight computation. This is done so as to extract salient words and sentences from the documents that help establish the correctness of the claim. However, this design of claim-driven attention does not capture the contextual information in documents properly. We improve on the prior art by using improved claim and title guided hierarchical attention to model effective contextual cues. We show the efficacy of our approach on datasets concerning political, healthcare, and environmental issues.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Bacterial colonization ofimplanted biomedical devicesis themain cause of healthcare-associated infections, estimated to be 8.8 million per year in Europe. Many infections originate from damaged skin, which lets microorganisms exploit injuries and surgical accesses as passageways to reach the implant site and inner organs. Therefore, an effective treatment of…\\n        ▽ More\\n\\n\\n        Bacterial colonization ofimplanted biomedical devicesis themain cause of healthcare-associated infections, estimated to be 8.8 million per year in Europe. Many infections originate from damaged skin, which lets microorganisms exploit injuries and surgical accesses as passageways to reach the implant site and inner organs. Therefore, an effective treatment of skin damage is highly desirable for the success of many biomaterial-related surgical procedures. Due to gained resistance to antibiotics, new antibacterial treatments are becoming vital to control nosocomial infections arising as surgical and post-surgical complications. Surface coatings can avoid biofouling and bacterial colonization thanks to biomaterial inherent properties (e.g., super hydrophobicity), specifically without using drugs, which may cause bacterial resistance. The focus of this review is to highlight the emerging role of degradable polymeric micro- and nano-structures that show intrinsic antifouling and antimicrobial properties, with a special outlook towards biomedical applications dealing with skin and skin damage. The intrinsic properties owned by the biomaterials encompass three main categories: (1) physical-mechanical, (2) chemical, and (3) electrostatic. Clinical relevance in ear prostheses and breast implants is reported. Collecting and discussing the updated outcomes in this field would help the development of better performing biomaterial-based antimicrobial strategies, which are useful to prevent infections.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        …is a crucial capability for autonomous systems to operate reliably in uncertain and dynamic environments. The concern of patient safety becomes even more critical in healthcare settings where robots interact with humans. In this paper, we propose a novel risk-aware planning framework to minimize the risk of patient falls by providing a patient with an assist…\\n        ▽ More\\n\\n\\n        Planning under uncertainty is a crucial capability for autonomous systems to operate reliably in uncertain and dynamic environments. The concern of patient safety becomes even more critical in healthcare settings where robots interact with humans. In this paper, we propose a novel risk-aware planning framework to minimize the risk of patient falls by providing a patient with an assistive device. Our approach combines learning-based prediction with model-based control to plan for the fall prevention tasks. This provides advantages compared to end-to-end learning methods in which the robot's performance is limited to specific scenarios, or purely model-based approaches that use relatively simple function approximators and are prone to high modeling errors. We compare two different risk metrics and the combination of them and report the results from various simulated scenarios. The results show that using the proposed cost function, the robot can plan interventions to avoid high fall score events.\\n        △ Less\\n\\n\",\n",
       " \"\\nAbstract:\\n      \\n        …among participants. This work offers implications on virtual reality and 3D-interactive systems, with specific contributions to virtual therapy, and serious games for healthcare applications.\\n        ▽ More\\n\\n\\n        There have been a resurge lately on virtual therapy and other virtual- and tele-medicine services due to the new normal of practicing 'shelter at home'. In this paper, we propose a creative drawing game for virtual therapy and investigate user's comfort and movement freedom in a pilot study. In a mixed-design study, healthy participants (N=16, 8 females) completed one of the easy or hard trajectories of the virtual therapy game in standing and seated arrangements using a virtual-reality headset. The results from participants' movement accuracy, task completion time, and usability questionnaires indicate that participants had significant performance differences on two levels of the game based on its difficulty (between-subjects factor), but no difference in seated and standing configurations (within-subjects factor). Also, the hard mode was more favorable among participants. This work offers implications on virtual reality and 3D-interactive systems, with specific contributions to virtual therapy, and serious games for healthcare applications.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        …platform is preferred to be utilized to achieve this goal, due to its ubiquitous sensing ability and seamless connectivity. IoT technology is changing our lives through smart healthcare, smart home, and smart city, which aims to build a more convenient and intelligent community. This paper presents how the IoT could be incorporated into the epidemic preventi…\\n        ▽ More\\n\\n\\n        As a result of the worldwide transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), coronavirus disease 2019 (COVID-19) has evolved into an unprecedented pandemic. Currently, with unavailable pharmaceutical treatments and vaccines, this novel coronavirus results in a great impact on public health, human society, and global economy, which is likely to last for many years. One of the lessons learned from the COVID-19 pandemic is that a long-term system with non-pharmaceutical interventions for preventing and controlling new infectious diseases is desirable to be implemented. Internet of things (IoT) platform is preferred to be utilized to achieve this goal, due to its ubiquitous sensing ability and seamless connectivity. IoT technology is changing our lives through smart healthcare, smart home, and smart city, which aims to build a more convenient and intelligent community. This paper presents how the IoT could be incorporated into the epidemic prevention and control system. Specifically, we demonstrate a potential fog-cloud combined IoT platform that can be used in the systematic and intelligent COVID-19 prevention and control, which involves five interventions including COVID-19 Symptom Diagnosis, Quarantine Monitoring, Contact Tracing \\\\& Social Distancing, COVID-19 Outbreak Forecasting, and SARS-CoV-2 Mutation Tracking. We investigate and review the state-of-the-art literatures of these five interventions to present the capabilities of IoT in countering against the current COVID-19 pandemic or future infectious disease epidemics.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …its unresolved dying ReLU problem, which poses challenges to reliable applications. This issue has obvious important implications for critical applications, such as those in healthcare. Recent approaches are just proposing variations of the activation function within the same unresolved dying ReLU challenge. This contribution reports a different research dir…\\n        ▽ More\\n\\n\\n        The ReLU activation function (AF) has been extensively applied in deep neural networks, in particular Convolutional Neural Networks (CNN), for image classification despite its unresolved dying ReLU problem, which poses challenges to reliable applications. This issue has obvious important implications for critical applications, such as those in healthcare. Recent approaches are just proposing variations of the activation function within the same unresolved dying ReLU challenge. This contribution reports a different research direction by investigating the development of an innovative quantum approach to the ReLU AF that avoids the dying ReLU problem by disruptive design. The Leaky ReLU was leveraged as a baseline on which the two quantum principles of entanglement and superposition were applied to derive the proposed Quantum ReLU (QReLU) and the modified-QReLU (m-QReLU) activation functions. Both QReLU and m-QReLU are implemented and made freely available in TensorFlow and Keras. This original approach is effective and validated extensively in case studies that facilitate the detection of COVID-19 and Parkinson Disease (PD) from medical images. The two novel AFs were evaluated in a two-layered CNN against nine ReLU-based AFs on seven benchmark datasets, including images of spiral drawings taken via graphic tablets from patients with Parkinson Disease and healthy subjects, and point-of-care ultrasound images on the lungs of patients with COVID-19, those with pneumonia and healthy controls. Despite a higher computational cost, results indicated an overall higher classification accuracy, precision, recall and F1-score brought about by either quantum AFs on five of the seven bench-mark datasets, thus demonstrating its potential to be the new benchmark or gold standard AF in CNNs and aid image classification tasks involved in critical applications, such as medical diagnoses of COVID-19 and PD.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Causal inference, or counterfactual prediction, is central to decision making in healthcare, policy and social sciences. To de-bias causal estimators with high-dimensional data in observational studies, recent advances suggest the importance of combining machine learning models for both the propensity score and the outcome function. We propose a novel scalab…\\n        ▽ More\\n\\n\\n        Causal inference, or counterfactual prediction, is central to decision making in healthcare, policy and social sciences. To de-bias causal estimators with high-dimensional data in observational studies, recent advances suggest the importance of combining machine learning models for both the propensity score and the outcome function. We propose a novel scalable method to learn double-robust representations for counterfactual predictions, leading to consistent causal estimation if the model for either the propensity score or the outcome, but not necessarily both, is correctly specified. Specifically, we use the entropy balancing method to learn the weights that minimize the Jensen-Shannon divergence of the representation between the treated and control groups, based on which we make robust and efficient counterfactual predictions for both individual and average treatment effects. We provide theoretical justifications for the proposed method. The algorithm shows competitive performance with the state-of-the-art on real world and synthetic data.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        …times in patients with emergent clinical findings, such as ICH or pulmonary embolism.We analyzed data of N=9,421 emergency-setting non-contrast head CT studies at a major US healthcare system acquired from November 1, 2019 through June 2, 2020, and compared two observation periods, namely (i) a pre-pandemic epoch from November 1, 2019 through February 29, 20…\\n        ▽ More\\n\\n\\n        Objective: To introduce a method for tracking results and utilization of Artificial Intelligence (tru-AI) in radiology. By tracking both large-scale utilization and AI results data, the tru-AI approach is designed to calculate surrogates for measuring important disease-related observational quantities over time, such as the prevalence of intracranial hemorrhage during the COVID-19 pandemic outbreak. Methods: To quantitatively investigate the clinical applicability of the tru-AI approach, we analyzed service requests for automatically identifying intracranial hemorrhage (ICH) on head CT using a commercial AI solution. This software is typically used for AI-based prioritization of radiologists' reading lists for reducing turnaround times in patients with emergent clinical findings, such as ICH or pulmonary embolism.We analyzed data of N=9,421 emergency-setting non-contrast head CT studies at a major US healthcare system acquired from November 1, 2019 through June 2, 2020, and compared two observation periods, namely (i) a pre-pandemic epoch from November 1, 2019 through February 29, 2020, and (ii) a period during the COVID-19 pandemic outbreak, April 1-30, 2020. Results: Although daily CT scan counts were significantly lower during (40.1 +/- 7.9) than before (44.4 +/- 7.6) the COVID-19 outbreak, we found that ICH was more likely to be observed by AI during than before the COVID-19 outbreak (p<0.05), with approximately one daily ICH+ case more than statistically expected. Conclusion: Our results suggest that, by tracking both large-scale utilization and AI results data in radiology, the tru-AI approach can contribute clinical value as a versatile exploratory tool, aiming at a better understanding of pandemic-related effects on healthcare.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        …group-key establishment and proof of location. Fields of application include secure car-to-car communication, privacy-preserving and secure distance evidence for healthcare or location-based feature activation. Existing technologies do not solve the problem satisfactorily, due to communication restrictions, e.g., ultra-wide band (UWB) based time of flight me…\\n        ▽ More\\n\\n\\n        In this paper, we investigate physical-layer security (PLS) methods for proximity-based group-key establishment and proof of location. Fields of application include secure car-to-car communication, privacy-preserving and secure distance evidence for healthcare or location-based feature activation. Existing technologies do not solve the problem satisfactorily, due to communication restrictions, e.g., ultra-wide band (UWB) based time of flight measurements, or trusted hardware, e.g., using global navigation satellite system (GNSS) positioning data.\\n  We introduce PLS as a solution candidate. It is information theoretically secure, which also means post-quantum resistant, and has the potential to run on resource constrained devices with low latency. Furthermore, we use wireless channel properties of satellite-to-Earth links, demonstrate the first feasibility study using off-the-shelf hardware testbeds and present first evaluation results and future directions for research.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …and millions of people. The virus is deadly, and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality. Medicine and Healthcare industries have surged towards finding a cure, and different policies have been amended to mitigate the spread of the virus. While Machine Learning (ML) methods have been wid…\\n        ▽ More\\n\\n\\n        COVID-19 was first discovered in December 2019 and has continued to rapidly spread across countries worldwide infecting thousands and millions of people. The virus is deadly, and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality. Medicine and Healthcare industries have surged towards finding a cure, and different policies have been amended to mitigate the spread of the virus. While Machine Learning (ML) methods have been widely used in other domains, there is now a high demand for ML-aided diagnosis systems for screening, tracking, and predicting the spread of COVID-19 and finding a cure against it. In this paper, we present a journey of what role ML has played so far in combating the virus, mainly looking at it from a screening, forecasting, and vaccine perspectives. We present a comprehensive survey of the ML algorithms and models that can be used on this expedition and aid with battling the virus.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …radiation, along with distance, isolation and hostile environment are expected to increase medical events with unidentified manifestations along the crewmembers. The current healthcare strategy based on telemedicine and the possibility to stabilise and transport the injured crewmember to a terrestrial definitive medical facility is not applicable in explorat…\\n        ▽ More\\n\\n\\n        Space agencies and private companies prepare the beginning of the human space exploration for the 2030s with missions to put the first human on the Mars surface. The absence of gravity and radiation, along with distance, isolation and hostile environment are expected to increase medical events with unidentified manifestations along the crewmembers. The current healthcare strategy based on telemedicine and the possibility to stabilise and transport the injured crewmember to a terrestrial definitive medical facility is not applicable in exploration class missions. Therefore, full autonomous capability to solve medical situations will guide design of future healthcare systems on-board.\\n  This study presents ten basic principles and the concept design of MEDEA, an on-board clinical decision support system to help crewmembers to deal with medical conditions, with special attention to emergency care situations and critical monitoring. Therefore, MEDEA is conceptually designed as a software suite of four interconnected modules. The main of them is responsible to give direct advice to the crew by means of a deep learning multitask neural network to predict the characters of the medical event, a classifier of the tertiary medical intervention and an optimiser of medical action plans. This module is continuously evaluate and re-trained with changing physiological data from the crew by an adaptive deep learning module, ensuring fairness, interpretability and traceability of decision making during the full operational time of MEDEA. Finally, MEDEA would be semantically interoperable with health information systems on-board by a FHIR module.\\n  The deployment of MEDEA on-board of future missions to Mars will facilitate the deployment of a comprehensive preventive medical strategy, future quantitative medicine on Earth and on the expansion of humans throughout the solar system.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …to specific areas. These systems have become an indispensable element within any hospital. The goal of our study is to discover how the ERP has been used in Moroccan healthcare sector and how these software should be implemented and used to improve healthcare services.\\n        ▽ More\\n\\n\\n        The Hospital Information Systems (HIS) in Morocco take a central place in the process of patient care. An approach is made to analyze the current situation of the HIS within the institutions in order to bring an integral and generic vision, allowing the judicious articulation of the business and IT layers. Currently, the Enterprise Resource Planning (ERP) implemented remains a system consisting of several applications dedicated to specific areas. These systems have become an indispensable element within any hospital. The goal of our study is to discover how the ERP has been used in Moroccan healthcare sector and how these software should be implemented and used to improve healthcare services.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\nHealthcare programs such as Medicaid provide crucial services to vulnerable populations, but due to limited resources, many of the individuals who need these services the most languish on waiting lists. Survival models, e.g. the Cox proportional hazards model, can potentially improve this situation by predicting individuals' levels of need, which can the…\\n        ▽ More\\n\\n\\nHealthcare programs such as Medicaid provide crucial services to vulnerable populations, but due to limited resources, many of the individuals who need these services the most languish on waiting lists. Survival models, e.g. the Cox proportional hazards model, can potentially improve this situation by predicting individuals' levels of need, which can then be used to prioritize the waiting lists. Providing care to those in need can prevent institutionalization for those individuals, which both improves quality of life and reduces overall costs. While the benefits of such an approach are clear, care must be taken to ensure that the prioritization process is fair or independent of demographic information-based harmful stereotypes. In this work, we develop multiple fairness definitions for survival models and corresponding fair Cox proportional hazards models to ensure equitable allocation of healthcare resources. We demonstrate the utility of our methods in terms of fairness and predictive accuracy on two publicly available survival datasets.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        Aim: One of the aims of the Observation Health Data Sciences and Informatics (OHDSI) initiative is population-level treatment effect estimation in large observational databases. Since treatment effects are well-known to vary across groups of patients with different baseline risk, we aimed to extend the OHDSI methods library with a framework for risk-based assessment of treatment effect heterogenei…\\n        ▽ More\\n\\n\\n        Aim: One of the aims of the Observation Health Data Sciences and Informatics (OHDSI) initiative is population-level treatment effect estimation in large observational databases. Since treatment effects are well-known to vary across groups of patients with different baseline risk, we aimed to extend the OHDSI methods library with a framework for risk-based assessment of treatment effect heterogeneity.\\n  Materials and Methods: The proposed framework consists of five steps: 1) definition of the problem, i.e. the population, the treatment, the comparator and the outcome(s) of interest; 2) identification of relevant databases; 3) development of a prediction model for the outcome(s) of interest; 4) estimation of propensity scores within strata of predicted risk and estimation of relative and absolute treatment effect within strata of predicted risk; 5) evaluation and presentation of results.\\n  Results: We demonstrate our framework by evaluating heterogeneity of the effect of angiotensin-converting enzyme (ACE) inhibitors versus beta blockers on a set of 9 outcomes of interest across three observational databases. With increasing risk of acute myocardial infarction we observed increasing absolute benefits, i.e. from -0.03% to 0.54% in the lowest to highest risk groups. Cough-related absolute harms decreased from 4.1% to 2.6%.\\n  Conclusions: The proposed framework may be useful for the evaluation of heterogeneity of treatment effect on observational data that are mapped to the OMOP Common Data Model. The proof of concept study demonstrates its feasibility in large observational data. Further insights may arise by application to safety and effectiveness questions across the global data network.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        COVID-19 spread across the globe at an immense rate has left healthcare systems incapacitated to diagnose and test patients at the needed rate. Studies have shown promising results for detection of COVID-19 from viral bacterial pneumonia in chest X-rays. Automation of COVID-19 testing using medical images can speed up the testing process of patients where he…\\n        ▽ More\\n\\n\\n        COVID-19 spread across the globe at an immense rate has left healthcare systems incapacitated to diagnose and test patients at the needed rate. Studies have shown promising results for detection of COVID-19 from viral bacterial pneumonia in chest X-rays. Automation of COVID-19 testing using medical images can speed up the testing process of patients where health care systems lack sufficient numbers of the reverse-transcription polymerase chain reaction (RT-PCR) tests. Supervised deep learning models such as convolutional neural networks (CNN) need enough labeled data for all classes to correctly learn the task of detection. Gathering labeled data is a cumbersome task and requires time and resources which could further strain health care systems and radiologists at the early stages of a pandemic such as COVID-19. In this study, we propose a randomized generative adversarial network (RANDGAN) that detects images of an unknown class (COVID-19) from known and labelled classes (Normal and Viral Pneumonia) without the need for labels and training data from the unknown class of images (COVID-19). We used the largest publicly available COVID-19 chest X-ray dataset, COVIDx, which is comprised of Normal, Pneumonia, and COVID-19 images from multiple public databases. In this work, we use transfer learning to segment the lungs in the COVIDx dataset. Next, we show why segmentation of the region of interest (lungs) is vital to correctly learn the task of classification, specifically in datasets that contain images from different resources as it is the case for the COVIDx dataset. Finally, we show improved results in detection of COVID-19 cases using our generative model (RANDGAN) compared to conventional generative adversarial networks (GANs) for anomaly detection in medical images, improving the area under the ROC curve from 0.71 to 0.77.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        …mind on previously held opinions: 10% gave more importance to the psychological aspects of medical conditions, and 27% were more favourable to the use of social media data in healthcare, suggesting the importance of persuasive elements in interactive visualizations.\\n        ▽ More\\n\\n\\n        A biological understanding is key for managing medical conditions, yet psychological and social aspects matter too. The main problem is that these two aspects are hard to quantify and inherently difficult to communicate. To quantify psychological aspects, this work mined around half a million Reddit posts in the sub-communities specialised in 14 medical conditions, and it did so with a new deep-learning framework. In so doing, it was able to associate mentions of medical conditions with those of emotions. To then quantify social aspects, this work designed a probabilistic approach that mines open prescription data from the National Health Service in England to compute the prevalence of drug prescriptions, and to relate such a prevalence to census data. To finally visually communicate each medical condition's biological, psychological, and social aspects through storytelling, we designed a narrative-style layered Martini Glass visualization. In a user study involving 52 participants, after interacting with our visualization, a considerable number of them changed their mind on previously held opinions: 10% gave more importance to the psychological aspects of medical conditions, and 27% were more favourable to the use of social media data in healthcare, suggesting the importance of persuasive elements in interactive visualizations.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        To address COVID-19 healthcare challenges, we need frequent sharing of health data, knowledge and resources at a global scale. However, in this digital age, data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data. In this paper, we introduce differential privacy…\\n        ▽ More\\n\\n\\n        To address COVID-19 healthcare challenges, we need frequent sharing of health data, knowledge and resources at a global scale. However, in this digital age, data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data. In this paper, we introduce differential privacy by design (dPbD) framework and discuss its embedding into the federated machine learning system. To limit the scope of our paper, we focus on the problem scenario of COVID-19 imaging data privacy for disease diagnosis by computer vision and deep learning approaches. We discuss the evaluation of the proposed design of federated machine learning systems and discuss how differential privacy by design (dPbD) framework can enhance data privacy in federated learning systems with scalability and robustness. We argue that scalable differentially private federated learning design is a promising solution for building a secure, private and collaborative machine learning model such as required to combat COVID19 challenge.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Virtual coaching has rapidly evolved into a foundational component of modern clinical practice. At a time when healthcare professionals are in short supply and the demand for low-cost treatments is ever-increasing, virtual health coaches (VHCs) offer intervention-on-demand for those limited by finances or geographic access to care. More recently, AI-powered…\\n        ▽ More\\n\\n\\n        Virtual coaching has rapidly evolved into a foundational component of modern clinical practice. At a time when healthcare professionals are in short supply and the demand for low-cost treatments is ever-increasing, virtual health coaches (VHCs) offer intervention-on-demand for those limited by finances or geographic access to care. More recently, AI-powered virtual coaches have become a viable complement to human coaches. However, the push for AI-powered coaching systems raises several important issues for researchers, designers, clinicians, and patients. In this paper, we present a novel framework to guide the design and development of virtual coaching systems. This framework augments a traditional data science pipeline with four key guiding goals: reliability, fairness, engagement, and ethics.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Acute and chronic wounds have varying etiologies and are an economic burden to healthcare systems around the world. The advanced wound care market is expected to exceed $22 billion by 2024. Wound care professionals rely heavily on images and image documentation for proper diagnosis and treatment. Unfortunately lack of expertise can lead to improper diagnosis…\\n        ▽ More\\n\\n\\n        Acute and chronic wounds have varying etiologies and are an economic burden to healthcare systems around the world. The advanced wound care market is expected to exceed $22 billion by 2024. Wound care professionals rely heavily on images and image documentation for proper diagnosis and treatment. Unfortunately lack of expertise can lead to improper diagnosis of wound etiology and inaccurate wound management and documentation. Fully automatic segmentation of wound areas in natural images is an important part of the diagnosis and care protocol since it is crucial to measure the area of the wound and provide quantitative parameters in the treatment. Various deep learning models have gained success in image analysis including semantic segmentation. Particularly, MobileNetV2 stands out among others due to its lightweight architecture and uncompromised performance. This manuscript proposes a novel convolutional framework based on MobileNetV2 and connected component labelling to segment wound regions from natural images. We build an annotated wound image dataset consisting of 1,109 foot ulcer images from 889 patients to train and test the deep learning models. We demonstrate the effectiveness and mobility of our method by conducting comprehensive experiments and analyses on various segmentation neural networks.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        At the heart of causal structure learning from observational data lies a deceivingly simple question: given two statistically dependent random variables, which one has a causal effect on the other? This is impossible to answer using statistical dependence testing alone and requires that we make additional assumptions. We propose several fast and simple criteria for distinguishing cause and effect…\\n        ▽ More\\n\\n\\n        At the heart of causal structure learning from observational data lies a deceivingly simple question: given two statistically dependent random variables, which one has a causal effect on the other? This is impossible to answer using statistical dependence testing alone and requires that we make additional assumptions. We propose several fast and simple criteria for distinguishing cause and effect in pairs of discrete or continuous random variables. The intuition behind them is that predicting the effect variable using the cause variable should be `simpler' than the reverse -- different notions of `simplicity' giving rise to different criteria. We demonstrate the accuracy of the criteria on synthetic data generated under a broad family of causal mechanisms and types of noise.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        …ideas with others about different issues. One such prevalent issue is the COVID-19 pandemic. Detecting and tracking topics on these kinds of issues would help governments and healthcare companies deal with this phenomenon. In this paper, we propose a novel communicative clustering approach, so-called ComStreamClust for clustering sub-topics inside a broader…\\n        ▽ More\\n\\n\\n        Topic detection is the task of determining and tracking hot topics in social media. Twitter is arguably the most popular platform for people to share their ideas with others about different issues. One such prevalent issue is the COVID-19 pandemic. Detecting and tracking topics on these kinds of issues would help governments and healthcare companies deal with this phenomenon. In this paper, we propose a novel communicative clustering approach, so-called ComStreamClust for clustering sub-topics inside a broader topic, e.g. COVID-19. The proposed approach was evaluated on two datasets: the COVID-19 and the FA CUP. The results obtained from ComStreamClust approve the effectiveness of the proposed approach when compared to existing methods such as LDA.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …disease caused by this virus, COVID-19. In the US alone, there have been approximately 7 million cases and over 200,000 deaths. This outbreak has placed an enormous strain on healthcare systems and workers. Severe cases require hospital care, and 8.5\\\\% of patients require mechanical ventilation in an intensive care unit (ICU). One major challenge is the nece…\\n        ▽ More\\n\\n\\n        Since the first reports of a novel coronavirus (SARS-CoV-2) in December 2019, over 33 million people have been infected worldwide and approximately 1 million people worldwide have died from the disease caused by this virus, COVID-19. In the US alone, there have been approximately 7 million cases and over 200,000 deaths. This outbreak has placed an enormous strain on healthcare systems and workers. Severe cases require hospital care, and 8.5\\\\% of patients require mechanical ventilation in an intensive care unit (ICU). One major challenge is the necessity for clinical care personnel to don and doff cumbersome personal protective equipment (PPE) in order to enter an ICU unit to make simple adjustments to ventilator settings. Although future ventilators and other ICU equipment may be controllable remotely through computer networks, the enormous installed base of existing ventilators do not have this capability. This paper reports the development of a simple, low cost telerobotic system that permits adjustment of ventilator settings from outside the ICU. The system consists of a small Cartesian robot capable of operating a ventilator touch screen with camera vision control via a wirelessly connected tablet master device located outside the room. Engineering system tests demonstrated that the open-loop mechanical repeatability of the device was 7.5\\\\,mm, and that the average positioning error of the robotic finger under visual servoing control was 5.94\\\\,mm. Successful usability tests in a simulated ICU environment were carried out and are reported. In addition to enabling a significant reduction in PPE consumption, the prototype system has been shown in a preliminary evaluation to significantly reduce the total time required for a respiratory therapist to perform typical setting adjustments on a commercial ventilator, including donning and doffing PPE, from 271 seconds to 109 seconds.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …patterns vary across narrative time and differ under expressions of anger, fear and sadness. Potential applications of CODYMs range from assessment and training of effective healthcare communication to comparing conversational dynamics across language and culture, with the prospect of identifying universal similarities and unique \"fingerprints\" of in…\\n        ▽ More\\n\\n\\n        Conversation has been a primary means for the exchange of information since ancient times. Understanding patterns of information flow in conversations is a critical step in assessing and improving communication quality. In this paper, we describe COnversational DYnamics Model (CODYM) analysis, a novel approach for studying patterns of information flow in conversations. CODYMs are Markov Models that capture sequential dependencies in the lengths of speaker turns. The proposed method is automated and scalable, and preserves the privacy of the conversational participants. The primary function of CODYM analysis is to quantify and visualize patterns of information flow, concisely summarized over sequential turns from one or more conversations. Our approach is general and complements existing methods, providing a new tool for use in the analysis of any type of conversation. As an important first application, we demonstrate the model on transcribed conversations between palliative care clinicians and seriously ill patients. These conversations are dynamic and complex, taking place amidst heavy emotions, and include difficult topics such as end-of-life preferences and patient values. We perform a versatile set of CODYM analyses that (a) establish the validity of the model by confirming known patterns of conversational turn-taking and word usage, (b) identify normative patterns of information flow in serious illness conversations, and (c) show how these patterns vary across narrative time and differ under expressions of anger, fear and sadness. Potential applications of CODYMs range from assessment and training of effective healthcare communication to comparing conversational dynamics across language and culture, with the prospect of identifying universal similarities and unique \"fingerprints\" of information flow.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        …to show that there is no universal method available that can accurately forecast pandemic data. Still, forecasters' predictions are useful for the effective allocation of healthcare resources and will act as an early-warning system for government policymakers.\\n        ▽ More\\n\\n\\n        The coronavirus disease 2019 (COVID-19) has become a public health emergency of international concern affecting more than 200 countries and territories worldwide. As of September 30, 2020, it has caused a pandemic outbreak with more than 33 million confirmed infections and more than 1 million reported deaths worldwide. Several statistical, machine learning, and hybrid models have previously tried to forecast COVID-19 confirmed cases for profoundly affected countries. Due to extreme uncertainty and nonstationarity in the time series data, forecasting of COVID-19 confirmed cases has become a very challenging job. For univariate time series forecasting, there are various statistical and machine learning models available in the literature. But, epidemic forecasting has a dubious track record. Its failures became more prominent due to insufficient data input, flaws in modeling assumptions, high sensitivity of estimates, lack of incorporation of epidemiological features, inadequate past evidence on effects of available interventions, lack of transparency, errors, lack of determinacy, and lack of expertise in crucial disciplines. This chapter focuses on assessing different short-term forecasting models that can forecast the daily COVID-19 cases for various countries. In the form of an empirical study on forecasting accuracy, this chapter provides evidence to show that there is no universal method available that can accurately forecast pandemic data. Still, forecasters' predictions are useful for the effective allocation of healthcare resources and will act as an early-warning system for government policymakers.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        …and social actions for interacting with humans. The robot will operate in a task environment where appropriate and safe interaction with children, parents/caregivers, and healthcare professionals is required. In addition to addressing the core technical challenge of building an autonomous social robot, the project will incorporate co-design techniques invol…\\n        ▽ More\\n\\n\\n        This paper describes a new research project that aims to develop a social robot designed to help children cope with painful and distressing medical procedures in a clinical setting. While robots have previously been trialled for this task, with promising initial results, the systems have tended to be teleoperated, limiting their flexibility and robustness. This project will use epistemic planning techniques as a core component for action selection in the robot system, in order to generate plans that include physical, sensory, and social actions for interacting with humans. The robot will operate in a task environment where appropriate and safe interaction with children, parents/caregivers, and healthcare professionals is required. In addition to addressing the core technical challenge of building an autonomous social robot, the project will incorporate co-design techniques involving all participant groups, and the final robot system will be evaluated in a two-site clinical trial.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        AI and Machine Learning can offer powerful tools to help in the fight against Covid-19. In this paper we present a study and a concrete tool based on machine learning to predict the prognosis of hospitalised patients with Covid-19. In particular we address the task of predicting the risk of death of a patient at different times of the hospitalisation, on the base of some demographic information, c…\\n        ▽ More\\n\\n\\n        AI and Machine Learning can offer powerful tools to help in the fight against Covid-19. In this paper we present a study and a concrete tool based on machine learning to predict the prognosis of hospitalised patients with Covid-19. In particular we address the task of predicting the risk of death of a patient at different times of the hospitalisation, on the base of some demographic information, chest X-ray scores and several laboratory findings. Our machine learning models use ensembles of decision trees trained and tested using data from more than 2000 patients. An experimental evaluation of the models shows good performance in solving the addressed task.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Pervasive healthcare is a promising assisted-living solution for chronic patients. However, current cutting-edge communication technologies are not able to strictly meet the requirements of these applications, especially in the case of life-threatening events. To bridge this gap, this paper proposes a new architecture to support indoor…\\n        ▽ More\\n\\n\\n        Pervasive healthcare is a promising assisted-living solution for chronic patients. However, current cutting-edge communication technologies are not able to strictly meet the requirements of these applications, especially in the case of life-threatening events. To bridge this gap, this paper proposes a new architecture to support indoor healthcare monitoring, with a focus on epileptic patients. Several novel elements are introduced. The first element is the cascading of a WLAN and a cellular network, where IEEE 802.11ax is used for the wireless local area network to collect physiological and environmental data in-home and 5G-enabled Fixed Wireless Access links transfer them to a remote hospital. The second element is the extension of the network slicing concept to the WLAN, and the introduction of two new slice types to support both regular monitoring and emergency handling. Moreover, the inclusion of local computing capabilities at the WLAN router, together with a mobile edge computing resource, represents a further architectural enhancement. Local computation is required to trigger not only health-related alarms, but also the network slicing change in case of emergency: in fact, proper radio resource scheduling is necessary for the cascaded networks to handle healthcare traffic together with other promiscuous everyday communication services. Numerical results demonstrate the effectiveness of the proposed approach while highlighting the performance gain achieved with respect to baseline solutions.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        The increasing availability of healthcare data requires accurate analysis of disease diagnosis, progression, and realtime monitoring to provide improved treatments to the patients. In this context, Machine Learning (ML) models are used to extract valuable features and insights from high-dimensional and heterogeneous…\\n        ▽ More\\n\\n\\n        The increasing availability of healthcare data requires accurate analysis of disease diagnosis, progression, and realtime monitoring to provide improved treatments to the patients. In this context, Machine Learning (ML) models are used to extract valuable features and insights from high-dimensional and heterogeneous healthcare data to detect different diseases and patient activities in a Smart Healthcare System (SHS). However, recent researches show that ML models used in different application domains are vulnerable to adversarial attacks. In this paper, we introduce a new type of adversarial attacks to exploit the ML classifiers used in a SHS. We consider an adversary who has partial knowledge of data distribution, SHS model, and ML algorithm to perform both targeted and untargeted attacks. Employing these adversarial capabilities, we manipulate medical device readings to alter patient status (disease-affected, normal condition, activities, etc.) in the outcome of the SHS. Our attack utilizes five different adversarial ML algorithms (HopSkipJump, Fast Gradient Method, Crafting Decision Tree, Carlini & Wagner, Zeroth Order Optimization) to perform different malicious activities (e.g., data poisoning, misclassify outputs, etc.) on a SHS. Moreover, based on the training and testing phase capabilities of an adversary, we perform white box and black box attacks on a SHS. We evaluate the performance of our work in different SHS settings and medical devices. Our extensive evaluation shows that our proposed adversarial attack can significantly degrade the performance of a ML-based SHS in detecting diseases and normal activities of the patients correctly, which eventually leads to erroneous treatment.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …Infant-Prints can deliver accurate and reliable recognition (over time) of infants enrolled between the ages of 2-3 months, in time for effective delivery of vaccinations, healthcare, and nutritional supplements (TAR=95.2% @ FAR = 1.0% for infants aged 8-16 weeks at enrollment and authenticated 3 months later).\\n        ▽ More\\n\\n\\n        In many of the least developed and developing countries, a multitude of infants continue to suffer and die from vaccine-preventable diseases and malnutrition. Lamentably, the lack of official identification documentation makes it exceedingly difficult to track which infants have been vaccinated and which infants have received nutritional supplements. Answering these questions could prevent this infant suffering and premature death around the world. To that end, we propose Infant-Prints, an end-to-end, low-cost, infant fingerprint recognition system. Infant-Prints is comprised of our (i) custom built, compact, low-cost (85 USD), high-resolution (1,900 ppi), ergonomic fingerprint reader, and (ii) high-resolution infant fingerprint matcher. To evaluate the efficacy of Infant-Prints, we collected a longitudinal infant fingerprint database captured in 4 different sessions over a 12-month time span (December 2018 to January 2020), from 315 infants at the Saran Ashram Hospital, a charitable hospital in Dayalbagh, Agra, India. Our experimental results demonstrate, for the first time, that Infant-Prints can deliver accurate and reliable recognition (over time) of infants enrolled between the ages of 2-3 months, in time for effective delivery of vaccinations, healthcare, and nutritional supplements (TAR=95.2% @ FAR = 1.0% for infants aged 8-16 weeks at enrollment and authenticated 3 months later).\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        In smart healthcare, Human Activity Recognition (HAR) is considered to be an efficient model in pervasive computation from sensor readings. The Ambient Assisted Living (AAL) in the home or community helps the people in providing independent care and enhanced living quality. However, many AAL models were restricted using many factors that include computationa…\\n        ▽ More\\n\\n\\n        In smart healthcare, Human Activity Recognition (HAR) is considered to be an efficient model in pervasive computation from sensor readings. The Ambient Assisted Living (AAL) in the home or community helps the people in providing independent care and enhanced living quality. However, many AAL models were restricted using many factors that include computational cost and system complexity. Moreover, the HAR concept has more relevance because of its applications. Hence, this paper tempts to implement the HAR system using deep learning with the data collected from smart sensors that are publicly available in the UC Irvine Machine Learning Repository (UCI). The proposed model involves three processes: (1) Data collection, (b) Optimal feature selection, (c) Recognition. The data gathered from the benchmark repository is initially subjected to optimal feature selection that helps to select the most significant features. The proposed optimal feature selection is based on a new meta-heuristic algorithm called Colliding Bodies Optimization (CBO). An objective function derived by the recognition accuracy is used for accomplishing the optimal feature selection. Here, the deep learning model called Recurrent Neural Network (RNN) is used for activity recognition. The proposed model on the concerned benchmark dataset outperforms existing learning methods, providing high performance compared to the conventional models.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …of the HIV prevalence in the subset of African countries we chose. These results can help in identification and targeting of high-prevalent regions to increase the supply of healthcare services to reduce the spread of the disease and increase the health quality of people living with HIV.\\n        ▽ More\\n\\n\\n        Local estimates of HIV-prevalence provide information that can be used to target interventions and consequently increase the efficiency of the resources. This closer-to-optimal allocation can lead to better health outcomes, including the control of the disease spread, and for more people. Producing reliable estimates at smaller geographical levels can be challenging and careful consideration of the nature of the data and the epidemiologic rational is needed. In this paper, we use the DHS data phase V to estimate HIV prevalence at the first-subnational level in Kenya, Tanzania, and Mozambique. We fit the data to a spatial random effect intrinsic conditional autoregressive (ICAR) model to smooth the outcome. We also use a sampling specification from a multistage cluster design. We found that Nyanza (P=14.2%) and Nairobi (P=7.8%) in Kenya, Iringa (P=16.2%) and Dar es Salaam (P=10.1%) in Tanzania, and Gaza (P=13.7%) and Maputo City (P=12.7%) in Mozambique are the regions with the highest prevalence of HIV, within country. Our results are based on statistically rigorous methods that allowed us to obtain an accurate visual representation of the HIV prevalence in the subset of African countries we chose. These results can help in identification and targeting of high-prevalent regions to increase the supply of healthcare services to reduce the spread of the disease and increase the health quality of people living with HIV.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        Sequence classification is the task of predicting a class label given a sequence of observations. In many applications such as healthcare monitoring or intrusion detection, early classification is crucial to prompt intervention. In this work, we learn sequence classifiers that favour early classification from an evolving observation trace. While many state-o…\\n        ▽ More\\n\\n\\n        Sequence classification is the task of predicting a class label given a sequence of observations. In many applications such as healthcare monitoring or intrusion detection, early classification is crucial to prompt intervention. In this work, we learn sequence classifiers that favour early classification from an evolving observation trace. While many state-of-the-art sequence classifiers are neural networks, and in particular LSTMs, our classifiers take the form of finite state automata and are learned via discrete optimization. Our automata-based classifiers are interpretable---supporting explanation, counterfactual reasoning, and human-in-the-loop modification---and have strong empirical performance. Experiments over a suite of goal recognition and behaviour classification datasets show our learned automata-based classifiers to have comparable test performance to LSTM-based classifiers, with the added advantage of being interpretable.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        The Affordable care Act of 2010 had introduced Readmission reduction program in 2012 to reduce avoidable re-admissions to control rising healthcare costs. Wound care impacts 15 of medicare beneficiaries making it one of the major contributors of medicare health care cost. Health plans have been exploring proactive health care services that can focus on preve…\\n        ▽ More\\n\\n\\n        The Affordable care Act of 2010 had introduced Readmission reduction program in 2012 to reduce avoidable re-admissions to control rising healthcare costs. Wound care impacts 15 of medicare beneficiaries making it one of the major contributors of medicare health care cost. Health plans have been exploring proactive health care services that can focus on preventing wound recurrences and re-admissions to control the wound care costs. With rising costs of Wound care industry, it has become of paramount importance to reduce wound recurrences & patient re-admissions. What factors are responsible for a Wound to recur which ultimately lead to hospitalization or re-admission? Is there a way to identify the patients at risk of re-admission before the occurrence using data driven analysis? Patient re-admission risk management has become critical for patients suffering from chronic wounds such as diabetic ulcers, pressure ulcers, and vascular ulcers. Understanding the risk & the factors that cause patient readmission can help care providers and patients avoid wound recurrences. Our work focuses on identifying patients who are at high risk of re-admission & determining the time period with in which a patient might get re-admitted. Frequent re-admissions add financial stress to the patient & Health plan and deteriorate the quality of life of the patient. Having this information can allow a provider to set up preventive measures that can delay, if not prevent, patients' re-admission. On a combined wound & episode-level data set of patient's wound care information, our extended autoprognosis achieves a recall of 92 and a precision of 92 for the predicting a patient's re-admission risk. For new patient class, precision and recall are as high as 91 and 98, respectively. We are also able to predict the patient's discharge event for a re-admission event to occur through our model with a MAE of 2.3 weeks.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        The recent outbreak of SARS COV-2 gave us a unique opportunity to study for a non interventional and sustainable AI solution. Lung disease remains a major healthcare challenge with high morbidity and mortality worldwide. The predominant lung disease was lung cancer. Until recently, the world has witnessed the global pandemic of COVID19, the Novel coronavirus…\\n        ▽ More\\n\\n\\n        The recent outbreak of SARS COV-2 gave us a unique opportunity to study for a non interventional and sustainable AI solution. Lung disease remains a major healthcare challenge with high morbidity and mortality worldwide. The predominant lung disease was lung cancer. Until recently, the world has witnessed the global pandemic of COVID19, the Novel coronavirus outbreak. We have experienced how viral infection of lung and heart claimed thousands of lives worldwide. With the unprecedented advancement of Artificial Intelligence in recent years, Machine learning can be used to easily detect and classify medical imagery. It is much faster and most of the time more accurate than human radiologists. Once implemented, it is more cost-effective and time-saving. In our study, we evaluated the efficacy of Microsoft Cognitive Service to detect and classify COVID19 induced pneumonia from other Viral/Bacterial pneumonia based on X-Ray and CT images. We wanted to assess the implication and accuracy of the Automated ML-based Rapid Application Development (RAD) environment in the field of Medical Image diagnosis. This study will better equip us to respond with an ML-based diagnostic Decision Support System(DSS) for a Pandemic situation like COVID19. After optimization, the trained network achieved 96.8% Average Precision which was implemented as a Web Application for consumption. However, the same trained network did not perform the same like Web Application when ported to Smartphone for Real-time inference. Which was our main interest of study. The authors believe, there is scope for further study on this issue. One of the main goal of this study was to develop and evaluate the performance of AI-powered Smartphone-based Real-time Application. Facilitating primary diagnostic services in less equipped and understaffed rural healthcare centers of the world with unreliable internet service.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        …extraction, storage, and querying of patient care information. However, developing a scalable solution is extremely challenging, specifically for radiology reports, as most healthcare institutes use either no template or department/institute specific templates. Moreover, radiologists' reporting style varies from one to another as sentences are telegraphi…\\n        ▽ More\\n\\n\\n        Automatic structuring of electronic medical records is of high demand for clinical workflow solutions to facilitate extraction, storage, and querying of patient care information. However, developing a scalable solution is extremely challenging, specifically for radiology reports, as most healthcare institutes use either no template or department/institute specific templates. Moreover, radiologists' reporting style varies from one to another as sentences are telegraphic and do not follow general English grammar rules. We present an ensemble method that consolidates the predictions of three models, capturing various attributes of textual information for automatic labeling of sentences with section labels. These three models are: 1) Focus Sentence model, capturing context of the target sentence; 2) Surrounding Context model, capturing the neighboring context of the target sentence; and finally, 3) Formatting/Layout model, aimed at learning report formatting cues. We utilize Bi-directional LSTMs, followed by sentence encoders, to acquire the context. Furthermore, we define several features that incorporate the structure of reports. We compare our proposed approach against multiple baselines and state-of-the-art approaches on a proprietary dataset as well as 100 manually annotated radiology notes from the MIMIC-III dataset, which we are making publicly available. Our proposed approach significantly outperforms other approaches by achieving 97.1% accuracy.\\n        △ Less\\n\\n\",\n",
       " '\\nAbstract:\\n      \\n        Efficient design of biological sequences will have a great impact across many industrial and healthcare domains. However, discovering improved sequences requires solving a difficult optimization problem. Traditionally, this challenge was approached by biologists through a model-free method known as \"directed evolution\", the iterative process of rando…\\n        ▽ More\\n\\n\\n        Efficient design of biological sequences will have a great impact across many industrial and healthcare domains. However, discovering improved sequences requires solving a difficult optimization problem. Traditionally, this challenge was approached by biologists through a model-free method known as \"directed evolution\", the iterative process of random mutation and selection. As the ability to build models that capture the sequence-to-function map improves, such models can be used as oracles to screen sequences before running experiments. In recent years, interest in better algorithms that effectively use such oracles to outperform model-free approaches has intensified. These span from approaches based on Bayesian Optimization, to regularized generative models and adaptations of reinforcement learning. In this work, we implement an open-source Fitness Landscape EXploration Sandbox (FLEXS: github.com/samsinai/FLEXS) environment to test and evaluate these algorithms based on their optimality, consistency, and robustness. Using FLEXS, we develop an easy-to-implement, scalable, and robust evolutionary greedy algorithm (AdaLead). Despite its simplicity, we show that AdaLead is a remarkably strong benchmark that out-competes more complex state of the art approaches in a variety of biologically motivated sequence design challenges.\\n        △ Less\\n\\n',\n",
       " '\\nAbstract:\\n      \\n        …language processing, and speech recognition. However, the decision-making processes of these models are generally not interpretable to users. In various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have r…\\n        ▽ More\\n\\n\\n        Deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes of these models are generally not interpretable to users. In various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.\\n  In this thesis, I investigate two major directions for explaining deep neural networks. The first direction consists of feature-based post-hoc explanatory methods, that is, methods that aim to explain an already trained and fixed model (post-hoc), and that provide explanations in terms of input features, such as tokens for text and superpixels for images (feature-based). The second direction consists of self-explanatory neural models that generate natural language explanations, that is, models that have a built-in module that generates explanations for the predictions of the model.\\n        △ Less\\n\\n',\n",
       " \"\\nAbstract:\\n      \\n        …(AI) systems since their conception, with the need for explainability growing as more complex AI models are increasingly used in critical, high-stakes settings such as healthcare. Explanations have often added to an AI system in a non-principled, post-hoc manner. With greater adoption of these systems and emphasis on user-centric explainability, there is a n…\\n        ▽ More\\n\\n\\n        Explainability has been a goal for Artificial Intelligence (AI) systems since their conception, with the need for explainability growing as more complex AI models are increasingly used in critical, high-stakes settings such as healthcare. Explanations have often added to an AI system in a non-principled, post-hoc manner. With greater adoption of these systems and emphasis on user-centric explainability, there is a need for a structured representation that treats explainability as a primary consideration, mapping end user needs to specific explanation types and the system's AI capabilities. We design an explanation ontology to model both the role of explanations, accounting for the system and user attributes in the process, and the range of different literature-derived explanation types. We indicate how the ontology can support user requirements for explanations in the domain of healthcare. We evaluate our ontology with a set of competency questions geared towards a system designer who might use our ontology to decide which explanation types to include, given a combination of users' needs and a system's capabilities, both in system design settings and in real-time operations. Through the use of this ontology, system designers will be able to make informed choices on which explanations AI systems can and should provide.\\n        △ Less\\n\\n\"]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#abstract=abstract.str.replace('\\n','',regex=True)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>article link</th>\n",
       "      <th>pdf link</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tag</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      \\n        Interpretable Deep Learning ...</td>\n",
       "      <td>2010.10328</td>\n",
       "      <td>https://arxiv.org/abs/2010.10328</td>\n",
       "      <td>https://arxiv.org/pdf/2010.10328</td>\n",
       "      <td>Dongdong Zhang,Xiaohui Yuan,Ping Zhang,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …of cardiologists...</td>\n",
       "      <td>20 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      \\n        Leveraging Technology for He...</td>\n",
       "      <td>2010.10285</td>\n",
       "      <td>https://arxiv.org/abs/2010.10285</td>\n",
       "      <td>https://arxiv.org/pdf/2010.10285</td>\n",
       "      <td>Ayan Chatterjee,Ali Shahaab,Martin W. Gerdes,S...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Health data is a ...</td>\n",
       "      <td>20 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      \\n        Towards new forms of particl...</td>\n",
       "      <td>2010.10269</td>\n",
       "      <td>https://arxiv.org/abs/2010.10269</td>\n",
       "      <td>https://arxiv.org/pdf/2010.10269</td>\n",
       "      <td>Jinlong Zhu,Ni Zhao,Renjie Zhou,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …advancement in a...</td>\n",
       "      <td>8 September, 202</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      \\n        University Operations During...</td>\n",
       "      <td>2010.10112</td>\n",
       "      <td>https://arxiv.org/abs/2010.10112</td>\n",
       "      <td>https://arxiv.org/pdf/2010.10112</td>\n",
       "      <td>Himanshu Kharkwal,Dakota Olson,Jiali Huang,Abh...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Modeling infectio...</td>\n",
       "      <td>20 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      \\n        The Role of Robotics in Infe...</td>\n",
       "      <td>2010.09909</td>\n",
       "      <td>https://arxiv.org/abs/2010.09909</td>\n",
       "      <td>https://arxiv.org/pdf/2010.09909</td>\n",
       "      <td>Gregory Hager,Vijay Kumar,Robin Murphy,Daniela...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        The recent corona...</td>\n",
       "      <td>19 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n      \\n        Multiclass Wound Image Class...</td>\n",
       "      <td>2010.09593</td>\n",
       "      <td>https://arxiv.org/abs/2010.09593</td>\n",
       "      <td>https://arxiv.org/pdf/2010.09593</td>\n",
       "      <td>Behrouz Rostami,D. M. Anisuzzaman,Chuanbo Wang...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Acute and chronic...</td>\n",
       "      <td>19 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n      \\n        A Privacy-Preserving Data In...</td>\n",
       "      <td>2010.09427</td>\n",
       "      <td>https://arxiv.org/abs/2010.09427</td>\n",
       "      <td>https://arxiv.org/pdf/2010.09427</td>\n",
       "      <td>James Jin Kang,Mahdi Dibaei,Gang Luo,Wencheng ...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Privacy protectio...</td>\n",
       "      <td>19 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n      \\n        Knowledge Graph-based Questi...</td>\n",
       "      <td>2010.09394</td>\n",
       "      <td>https://arxiv.org/abs/2010.09394</td>\n",
       "      <td>https://arxiv.org/pdf/2010.09394</td>\n",
       "      <td>Junwoo Park,Youngwoo Cho,Haneol Lee,Jaegul Cho...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Question Answerin...</td>\n",
       "      <td>19 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n      \\n        MyWear: A Smart Wear for Con...</td>\n",
       "      <td>2010.08866</td>\n",
       "      <td>https://arxiv.org/abs/2010.08866</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08866</td>\n",
       "      <td>Sibi C. Sethuraman,Pranav Kompally,Saraju P. M...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Smart healthcare ...</td>\n",
       "      <td>17 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n      \\n        Threats and Corrective Measu...</td>\n",
       "      <td>2010.08793</td>\n",
       "      <td>https://arxiv.org/abs/2010.08793</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08793</td>\n",
       "      <td>Sita Rani,Aman Kataria,Smarajit Ghosh,Vinod Ka...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …discussed in det...</td>\n",
       "      <td>17 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n      \\n        Is Image Encoding Beneficial...</td>\n",
       "      <td>2010.08698</td>\n",
       "      <td>https://arxiv.org/abs/2010.08698</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08698</td>\n",
       "      <td>Dan Wang,Tianrui Wang,Ionuţ Florescu,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …technique (Hilbe...</td>\n",
       "      <td>16 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td>10.1109/JIOT.2020.3030492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n      \\n        Semantics of the Black-Box: ...</td>\n",
       "      <td>2010.08660</td>\n",
       "      <td>https://arxiv.org/abs/2010.08660</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08660</td>\n",
       "      <td>Manas Gaur,Keyur Faldu,Amit Sheth,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …how this makes a...</td>\n",
       "      <td>16 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\n      \\n        Generating Fact Checking Sum...</td>\n",
       "      <td>2010.08570</td>\n",
       "      <td>https://arxiv.org/abs/2010.08570</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08570</td>\n",
       "      <td>Rahul Mishra,Dhruv Gupta,Markus Leippold,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …art by using imp...</td>\n",
       "      <td>16 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n      \\n        Biodegradable Polymeric Micr...</td>\n",
       "      <td>2010.08250</td>\n",
       "      <td>https://arxiv.org/abs/2010.08250</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08250</td>\n",
       "      <td>Mario Milazzo,Giuseppe Gallone,Elena Marcello,...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Bacterial coloniz...</td>\n",
       "      <td>16 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td>10.3390/jfb11030060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n      \\n        Risk-Aware Decision Making i...</td>\n",
       "      <td>2010.08124</td>\n",
       "      <td>https://arxiv.org/abs/2010.08124</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08124</td>\n",
       "      <td>Roya Sabbagh Novin,Amir Yazdani,Andrew Merrywe...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …is a crucial cap...</td>\n",
       "      <td>15 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n      \\n        When Virtual Therapy and Art...</td>\n",
       "      <td>2010.08100</td>\n",
       "      <td>https://arxiv.org/abs/2010.08100</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08100</td>\n",
       "      <td>Lauren Baron,Brian Cohn,Roghayeh Barmaki,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …among participan...</td>\n",
       "      <td>15 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\n      \\n        IoT Platform for COVID-19 Pr...</td>\n",
       "      <td>2010.08056</td>\n",
       "      <td>https://arxiv.org/abs/2010.08056</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08056</td>\n",
       "      <td>Yudi Dong,Yu-Dong Yao,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …platform is pref...</td>\n",
       "      <td>15 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n      \\n        QReLU and m-QReLU: Two novel...</td>\n",
       "      <td>2010.08031</td>\n",
       "      <td>https://arxiv.org/abs/2010.08031</td>\n",
       "      <td>https://arxiv.org/pdf/2010.08031</td>\n",
       "      <td>L. Parisi,D. Neagu,R. Ma,F. Campean,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …its unresolved d...</td>\n",
       "      <td>15 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\n      \\n        Double Robust Representation...</td>\n",
       "      <td>2010.07866</td>\n",
       "      <td>https://arxiv.org/abs/2010.07866</td>\n",
       "      <td>https://arxiv.org/pdf/2010.07866</td>\n",
       "      <td>Shuxi Zeng,Serge Assaad,Chenyang Tao,Shounak D...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Causal inference,...</td>\n",
       "      <td>16 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n      \\n        Tracking Results and Utiliza...</td>\n",
       "      <td>2010.07437</td>\n",
       "      <td>https://arxiv.org/abs/2010.07437</td>\n",
       "      <td>https://arxiv.org/pdf/2010.07437</td>\n",
       "      <td>Axel Wismüller,Larry Stockmaster,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …times in patient...</td>\n",
       "      <td>14 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\n      \\n        Keys from the Sky: A First E...</td>\n",
       "      <td>2010.07194</td>\n",
       "      <td>https://arxiv.org/abs/2010.07194</td>\n",
       "      <td>https://arxiv.org/pdf/2010.07194</td>\n",
       "      <td>Pascal Zimmer,Roland Weinreich,Christian T. Ze...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …group-key establ...</td>\n",
       "      <td>14 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n      \\n        Machine Learning Research To...</td>\n",
       "      <td>2010.07036</td>\n",
       "      <td>https://arxiv.org/abs/2010.07036</td>\n",
       "      <td>https://arxiv.org/pdf/2010.07036</td>\n",
       "      <td>Osama Shahid,Mohammad Nasajpour,Seyedamin Pour...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …and millions of ...</td>\n",
       "      <td>29 September, 20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n      \\n        Basic principles and concept...</td>\n",
       "      <td>2010.07029</td>\n",
       "      <td>https://arxiv.org/abs/2010.07029</td>\n",
       "      <td>https://arxiv.org/pdf/2010.07029</td>\n",
       "      <td>Juan M Garcia-Gomez,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …radiation, along...</td>\n",
       "      <td>29 September, 20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\n      \\n        Review the Enterprise Resour...</td>\n",
       "      <td>2010.06989</td>\n",
       "      <td>https://arxiv.org/abs/2010.06989</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06989</td>\n",
       "      <td>Fatima Zahra Yamani,Mohamed El Merouani,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …to specific area...</td>\n",
       "      <td>22 September, 20</td>\n",
       "      <td></td>\n",
       "      <td>10.5281/zenodo.3987129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\n      \\n        Equitable Allocation of Heal...</td>\n",
       "      <td>2010.06820</td>\n",
       "      <td>https://arxiv.org/abs/2010.06820</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06820</td>\n",
       "      <td>Kamrun Naher Keya,Rashidul Islam,Shimei Pan,Ia...</td>\n",
       "      <td>\\nAbstract:\\n      \\nHealthcare programs such ...</td>\n",
       "      <td>14 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\n      \\n        A standardized framework for...</td>\n",
       "      <td>2010.06430</td>\n",
       "      <td>https://arxiv.org/abs/2010.06430</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06430</td>\n",
       "      <td>Alexandros Rekkas,David van Klaveren,Patrick B...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Aim: One of the a...</td>\n",
       "      <td>13 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\n      \\n        RANDGAN: Randomized Generati...</td>\n",
       "      <td>2010.06418</td>\n",
       "      <td>https://arxiv.org/abs/2010.06418</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06418</td>\n",
       "      <td>Saman Motamed,Patrik Rogalla,Farzad Khalvati,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        COVID-19 spread a...</td>\n",
       "      <td>6 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\n      \\n        Humane Visual AI: Telling th...</td>\n",
       "      <td>2010.06296</td>\n",
       "      <td>https://arxiv.org/abs/2010.06296</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06296</td>\n",
       "      <td>Wonyoung So,Edyta P. Bogucka,Sanja Šćepanović,...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …mind on previous...</td>\n",
       "      <td>13 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\n      \\n        COVID-19 Imaging Data Privac...</td>\n",
       "      <td>2010.06177</td>\n",
       "      <td>https://arxiv.org/abs/2010.06177</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06177</td>\n",
       "      <td>Anwaar Ulhaq,Oliver Burmeister,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        To address COVID-...</td>\n",
       "      <td>13 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\n      \\n        A Framework for Addressing t...</td>\n",
       "      <td>2010.06059</td>\n",
       "      <td>https://arxiv.org/abs/2010.06059</td>\n",
       "      <td>https://arxiv.org/pdf/2010.06059</td>\n",
       "      <td>Sonia Baee,Mark Rucker,Anna Baglione,Mawulolo ...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Virtual coaching ...</td>\n",
       "      <td>12 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td>10.1145/3421937.3421971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\\n      \\n        Fully Automatic Wound Segmen...</td>\n",
       "      <td>2010.05855</td>\n",
       "      <td>https://arxiv.org/abs/2010.05855</td>\n",
       "      <td>https://arxiv.org/pdf/2010.05855</td>\n",
       "      <td>Chuanbo Wang,DM Anisuzzaman,Victor Williamson,...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Acute and chronic...</td>\n",
       "      <td>12 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\n      \\n        Inferring Causal Direction f...</td>\n",
       "      <td>2010.05635</td>\n",
       "      <td>https://arxiv.org/abs/2010.05635</td>\n",
       "      <td>https://arxiv.org/pdf/2010.05635</td>\n",
       "      <td>Nikolaos Nikolaou,Konstantinos Sechidis,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        At the heart of c...</td>\n",
       "      <td>12 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\n      \\n        ComStreamClust: A communicat...</td>\n",
       "      <td>2010.05349</td>\n",
       "      <td>https://arxiv.org/abs/2010.05349</td>\n",
       "      <td>https://arxiv.org/pdf/2010.05349</td>\n",
       "      <td>Ali Najafi,Araz Gholipour-Shilabin,Rahim Dehkh...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …ideas with other...</td>\n",
       "      <td>11 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n      \\n        Telerobotic Operation of Int...</td>\n",
       "      <td>2010.05247</td>\n",
       "      <td>https://arxiv.org/abs/2010.05247</td>\n",
       "      <td>https://arxiv.org/pdf/2010.05247</td>\n",
       "      <td>Balazs P. Vagvolgyi,Mikhail Khrenov,Jonathan C...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …disease caused b...</td>\n",
       "      <td>11 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\n      \\n        A General Model of Conversat...</td>\n",
       "      <td>2010.05164</td>\n",
       "      <td>https://arxiv.org/abs/2010.05164</td>\n",
       "      <td>https://arxiv.org/pdf/2010.05164</td>\n",
       "      <td>Laurence A. Clarfeld,Robert Gramling,Donna M. ...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …patterns vary ac...</td>\n",
       "      <td>11 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\n      \\n        Nowcasting of COVID-19 confi...</td>\n",
       "      <td>2010.05079</td>\n",
       "      <td>https://arxiv.org/abs/2010.05079</td>\n",
       "      <td>https://arxiv.org/pdf/2010.05079</td>\n",
       "      <td>Tanujit Chakraborty,Indrajit Ghosh,Tirna Mahaj...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …to show that the...</td>\n",
       "      <td>10 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\n      \\n        Towards Social HRI for Impro...</td>\n",
       "      <td>2010.04652</td>\n",
       "      <td>https://arxiv.org/abs/2010.04652</td>\n",
       "      <td>https://arxiv.org/pdf/2010.04652</td>\n",
       "      <td>Mary Ellen Foster,Ronald P. A. Petrick,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …and social actio...</td>\n",
       "      <td>9 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\n      \\n        Prognosis Prediction in Covi...</td>\n",
       "      <td>2010.04420</td>\n",
       "      <td>https://arxiv.org/abs/2010.04420</td>\n",
       "      <td>https://arxiv.org/pdf/2010.04420</td>\n",
       "      <td>Alfonso Emilio Gerevini,Roberto Maroldi,Matteo...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        AI and Machine Le...</td>\n",
       "      <td>9 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n      \\n        Cascaded WLAN-FWA Networking...</td>\n",
       "      <td>2010.03805</td>\n",
       "      <td>https://arxiv.org/abs/2010.03805</td>\n",
       "      <td>https://arxiv.org/pdf/2010.03805</td>\n",
       "      <td>Sergio Martiradonna,Giulia Cisotto,Gennaro Bog...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Pervasive healthc...</td>\n",
       "      <td>8 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\n      \\n        Adversarial Attacks to Machi...</td>\n",
       "      <td>2010.03671</td>\n",
       "      <td>https://arxiv.org/abs/2010.03671</td>\n",
       "      <td>https://arxiv.org/pdf/2010.03671</td>\n",
       "      <td>AKM Iqtidar Newaz,Nur Imtiazul Haque,Amit Kuma...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        The increasing av...</td>\n",
       "      <td>7 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\\n      \\n        Infant-ID: Fingerprints for ...</td>\n",
       "      <td>2010.03624</td>\n",
       "      <td>https://arxiv.org/abs/2010.03624</td>\n",
       "      <td>https://arxiv.org/pdf/2010.03624</td>\n",
       "      <td>Joshua J. Engelsma,Debayan Deb,Kai Cao,Anjoo B...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …Infant-Prints ca...</td>\n",
       "      <td>7 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\\n      \\n        Automated Human Activity Rec...</td>\n",
       "      <td>2010.03324</td>\n",
       "      <td>https://arxiv.org/abs/2010.03324</td>\n",
       "      <td>https://arxiv.org/pdf/2010.03324</td>\n",
       "      <td>Pankaj Khatiwada,Matrika Subedi,Ayan Chatterje...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        In smart healthca...</td>\n",
       "      <td>7 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\\n      \\n        HIV-prevalence mapping using...</td>\n",
       "      <td>2010.03114</td>\n",
       "      <td>https://arxiv.org/abs/2010.03114</td>\n",
       "      <td>https://arxiv.org/pdf/2010.03114</td>\n",
       "      <td>Enrique M. Saldarriaga,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …of the HIV preva...</td>\n",
       "      <td>6 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\\n      \\n        Interpretable Sequence Class...</td>\n",
       "      <td>2010.02819</td>\n",
       "      <td>https://arxiv.org/abs/2010.02819</td>\n",
       "      <td>https://arxiv.org/pdf/2010.02819</td>\n",
       "      <td>Maayan Shvo,Andrew C. Li,Rodrigo Toro Icarte,S...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Sequence classifi...</td>\n",
       "      <td>6 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\\n      \\n        Wound and episode level read...</td>\n",
       "      <td>2010.02742</td>\n",
       "      <td>https://arxiv.org/abs/2010.02742</td>\n",
       "      <td>https://arxiv.org/pdf/2010.02742</td>\n",
       "      <td>Subba Reddy Oota,Nafisur Rahman,Shahid Saleem ...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        The Affordable ca...</td>\n",
       "      <td>5 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\n      \\n        Assessing Automated Machine ...</td>\n",
       "      <td>2010.02715</td>\n",
       "      <td>https://arxiv.org/abs/2010.02715</td>\n",
       "      <td>https://arxiv.org/pdf/2010.02715</td>\n",
       "      <td>Razib Mustafiz,Khaled Mohsin,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        The recent outbre...</td>\n",
       "      <td>3 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td>10.20944/preprints202009.0647.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\\n      \\n        An Ensemble Approach for Aut...</td>\n",
       "      <td>2010.02256</td>\n",
       "      <td>https://arxiv.org/abs/2010.02256</td>\n",
       "      <td>https://arxiv.org/pdf/2010.02256</td>\n",
       "      <td>Morteza Pourreza Shahri,Amir Tahmasebi,Bingyan...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …extraction, stor...</td>\n",
       "      <td>10 October, 2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\\n      \\n        AdaLead: A simple and robust...</td>\n",
       "      <td>2010.02141</td>\n",
       "      <td>https://arxiv.org/abs/2010.02141</td>\n",
       "      <td>https://arxiv.org/pdf/2010.02141</td>\n",
       "      <td>Sam Sinai,Richard Wang,Alexander Whatley,Stewa...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        Efficient design ...</td>\n",
       "      <td>5 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\\n      \\n        Explaining Deep Neural Netwo...</td>\n",
       "      <td>2010.01496</td>\n",
       "      <td>https://arxiv.org/abs/2010.01496</td>\n",
       "      <td>https://arxiv.org/pdf/2010.01496</td>\n",
       "      <td>Oana-Maria Camburu,</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …language process...</td>\n",
       "      <td>4 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>\\n      \\n        Explanation Ontology: A Mode...</td>\n",
       "      <td>2010.01479</td>\n",
       "      <td>https://arxiv.org/abs/2010.01479</td>\n",
       "      <td>https://arxiv.org/pdf/2010.01479</td>\n",
       "      <td>Shruthi Chari,Oshani Seneviratne,Daniel M. Gru...</td>\n",
       "      <td>\\nAbstract:\\n      \\n        …(AI) systems sin...</td>\n",
       "      <td>3 October, 2020;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title    arxiv_id  \\\n",
       "0   \\n      \\n        Interpretable Deep Learning ...  2010.10328   \n",
       "1   \\n      \\n        Leveraging Technology for He...  2010.10285   \n",
       "2   \\n      \\n        Towards new forms of particl...  2010.10269   \n",
       "3   \\n      \\n        University Operations During...  2010.10112   \n",
       "4   \\n      \\n        The Role of Robotics in Infe...  2010.09909   \n",
       "5   \\n      \\n        Multiclass Wound Image Class...  2010.09593   \n",
       "6   \\n      \\n        A Privacy-Preserving Data In...  2010.09427   \n",
       "7   \\n      \\n        Knowledge Graph-based Questi...  2010.09394   \n",
       "8   \\n      \\n        MyWear: A Smart Wear for Con...  2010.08866   \n",
       "9   \\n      \\n        Threats and Corrective Measu...  2010.08793   \n",
       "10  \\n      \\n        Is Image Encoding Beneficial...  2010.08698   \n",
       "11  \\n      \\n        Semantics of the Black-Box: ...  2010.08660   \n",
       "12  \\n      \\n        Generating Fact Checking Sum...  2010.08570   \n",
       "13  \\n      \\n        Biodegradable Polymeric Micr...  2010.08250   \n",
       "14  \\n      \\n        Risk-Aware Decision Making i...  2010.08124   \n",
       "15  \\n      \\n        When Virtual Therapy and Art...  2010.08100   \n",
       "16  \\n      \\n        IoT Platform for COVID-19 Pr...  2010.08056   \n",
       "17  \\n      \\n        QReLU and m-QReLU: Two novel...  2010.08031   \n",
       "18  \\n      \\n        Double Robust Representation...  2010.07866   \n",
       "19  \\n      \\n        Tracking Results and Utiliza...  2010.07437   \n",
       "20  \\n      \\n        Keys from the Sky: A First E...  2010.07194   \n",
       "21  \\n      \\n        Machine Learning Research To...  2010.07036   \n",
       "22  \\n      \\n        Basic principles and concept...  2010.07029   \n",
       "23  \\n      \\n        Review the Enterprise Resour...  2010.06989   \n",
       "24  \\n      \\n        Equitable Allocation of Heal...  2010.06820   \n",
       "25  \\n      \\n        A standardized framework for...  2010.06430   \n",
       "26  \\n      \\n        RANDGAN: Randomized Generati...  2010.06418   \n",
       "27  \\n      \\n        Humane Visual AI: Telling th...  2010.06296   \n",
       "28  \\n      \\n        COVID-19 Imaging Data Privac...  2010.06177   \n",
       "29  \\n      \\n        A Framework for Addressing t...  2010.06059   \n",
       "30  \\n      \\n        Fully Automatic Wound Segmen...  2010.05855   \n",
       "31  \\n      \\n        Inferring Causal Direction f...  2010.05635   \n",
       "32  \\n      \\n        ComStreamClust: A communicat...  2010.05349   \n",
       "33  \\n      \\n        Telerobotic Operation of Int...  2010.05247   \n",
       "34  \\n      \\n        A General Model of Conversat...  2010.05164   \n",
       "35  \\n      \\n        Nowcasting of COVID-19 confi...  2010.05079   \n",
       "36  \\n      \\n        Towards Social HRI for Impro...  2010.04652   \n",
       "37  \\n      \\n        Prognosis Prediction in Covi...  2010.04420   \n",
       "38  \\n      \\n        Cascaded WLAN-FWA Networking...  2010.03805   \n",
       "39  \\n      \\n        Adversarial Attacks to Machi...  2010.03671   \n",
       "40  \\n      \\n        Infant-ID: Fingerprints for ...  2010.03624   \n",
       "41  \\n      \\n        Automated Human Activity Rec...  2010.03324   \n",
       "42  \\n      \\n        HIV-prevalence mapping using...  2010.03114   \n",
       "43  \\n      \\n        Interpretable Sequence Class...  2010.02819   \n",
       "44  \\n      \\n        Wound and episode level read...  2010.02742   \n",
       "45  \\n      \\n        Assessing Automated Machine ...  2010.02715   \n",
       "46  \\n      \\n        An Ensemble Approach for Aut...  2010.02256   \n",
       "47  \\n      \\n        AdaLead: A simple and robust...  2010.02141   \n",
       "48  \\n      \\n        Explaining Deep Neural Netwo...  2010.01496   \n",
       "49  \\n      \\n        Explanation Ontology: A Mode...  2010.01479   \n",
       "\n",
       "                        article link                          pdf link  \\\n",
       "0   https://arxiv.org/abs/2010.10328  https://arxiv.org/pdf/2010.10328   \n",
       "1   https://arxiv.org/abs/2010.10285  https://arxiv.org/pdf/2010.10285   \n",
       "2   https://arxiv.org/abs/2010.10269  https://arxiv.org/pdf/2010.10269   \n",
       "3   https://arxiv.org/abs/2010.10112  https://arxiv.org/pdf/2010.10112   \n",
       "4   https://arxiv.org/abs/2010.09909  https://arxiv.org/pdf/2010.09909   \n",
       "5   https://arxiv.org/abs/2010.09593  https://arxiv.org/pdf/2010.09593   \n",
       "6   https://arxiv.org/abs/2010.09427  https://arxiv.org/pdf/2010.09427   \n",
       "7   https://arxiv.org/abs/2010.09394  https://arxiv.org/pdf/2010.09394   \n",
       "8   https://arxiv.org/abs/2010.08866  https://arxiv.org/pdf/2010.08866   \n",
       "9   https://arxiv.org/abs/2010.08793  https://arxiv.org/pdf/2010.08793   \n",
       "10  https://arxiv.org/abs/2010.08698  https://arxiv.org/pdf/2010.08698   \n",
       "11  https://arxiv.org/abs/2010.08660  https://arxiv.org/pdf/2010.08660   \n",
       "12  https://arxiv.org/abs/2010.08570  https://arxiv.org/pdf/2010.08570   \n",
       "13  https://arxiv.org/abs/2010.08250  https://arxiv.org/pdf/2010.08250   \n",
       "14  https://arxiv.org/abs/2010.08124  https://arxiv.org/pdf/2010.08124   \n",
       "15  https://arxiv.org/abs/2010.08100  https://arxiv.org/pdf/2010.08100   \n",
       "16  https://arxiv.org/abs/2010.08056  https://arxiv.org/pdf/2010.08056   \n",
       "17  https://arxiv.org/abs/2010.08031  https://arxiv.org/pdf/2010.08031   \n",
       "18  https://arxiv.org/abs/2010.07866  https://arxiv.org/pdf/2010.07866   \n",
       "19  https://arxiv.org/abs/2010.07437  https://arxiv.org/pdf/2010.07437   \n",
       "20  https://arxiv.org/abs/2010.07194  https://arxiv.org/pdf/2010.07194   \n",
       "21  https://arxiv.org/abs/2010.07036  https://arxiv.org/pdf/2010.07036   \n",
       "22  https://arxiv.org/abs/2010.07029  https://arxiv.org/pdf/2010.07029   \n",
       "23  https://arxiv.org/abs/2010.06989  https://arxiv.org/pdf/2010.06989   \n",
       "24  https://arxiv.org/abs/2010.06820  https://arxiv.org/pdf/2010.06820   \n",
       "25  https://arxiv.org/abs/2010.06430  https://arxiv.org/pdf/2010.06430   \n",
       "26  https://arxiv.org/abs/2010.06418  https://arxiv.org/pdf/2010.06418   \n",
       "27  https://arxiv.org/abs/2010.06296  https://arxiv.org/pdf/2010.06296   \n",
       "28  https://arxiv.org/abs/2010.06177  https://arxiv.org/pdf/2010.06177   \n",
       "29  https://arxiv.org/abs/2010.06059  https://arxiv.org/pdf/2010.06059   \n",
       "30  https://arxiv.org/abs/2010.05855  https://arxiv.org/pdf/2010.05855   \n",
       "31  https://arxiv.org/abs/2010.05635  https://arxiv.org/pdf/2010.05635   \n",
       "32  https://arxiv.org/abs/2010.05349  https://arxiv.org/pdf/2010.05349   \n",
       "33  https://arxiv.org/abs/2010.05247  https://arxiv.org/pdf/2010.05247   \n",
       "34  https://arxiv.org/abs/2010.05164  https://arxiv.org/pdf/2010.05164   \n",
       "35  https://arxiv.org/abs/2010.05079  https://arxiv.org/pdf/2010.05079   \n",
       "36  https://arxiv.org/abs/2010.04652  https://arxiv.org/pdf/2010.04652   \n",
       "37  https://arxiv.org/abs/2010.04420  https://arxiv.org/pdf/2010.04420   \n",
       "38  https://arxiv.org/abs/2010.03805  https://arxiv.org/pdf/2010.03805   \n",
       "39  https://arxiv.org/abs/2010.03671  https://arxiv.org/pdf/2010.03671   \n",
       "40  https://arxiv.org/abs/2010.03624  https://arxiv.org/pdf/2010.03624   \n",
       "41  https://arxiv.org/abs/2010.03324  https://arxiv.org/pdf/2010.03324   \n",
       "42  https://arxiv.org/abs/2010.03114  https://arxiv.org/pdf/2010.03114   \n",
       "43  https://arxiv.org/abs/2010.02819  https://arxiv.org/pdf/2010.02819   \n",
       "44  https://arxiv.org/abs/2010.02742  https://arxiv.org/pdf/2010.02742   \n",
       "45  https://arxiv.org/abs/2010.02715  https://arxiv.org/pdf/2010.02715   \n",
       "46  https://arxiv.org/abs/2010.02256  https://arxiv.org/pdf/2010.02256   \n",
       "47  https://arxiv.org/abs/2010.02141  https://arxiv.org/pdf/2010.02141   \n",
       "48  https://arxiv.org/abs/2010.01496  https://arxiv.org/pdf/2010.01496   \n",
       "49  https://arxiv.org/abs/2010.01479  https://arxiv.org/pdf/2010.01479   \n",
       "\n",
       "                                               author  \\\n",
       "0             Dongdong Zhang,Xiaohui Yuan,Ping Zhang,   \n",
       "1   Ayan Chatterjee,Ali Shahaab,Martin W. Gerdes,S...   \n",
       "2                    Jinlong Zhu,Ni Zhao,Renjie Zhou,   \n",
       "3   Himanshu Kharkwal,Dakota Olson,Jiali Huang,Abh...   \n",
       "4   Gregory Hager,Vijay Kumar,Robin Murphy,Daniela...   \n",
       "5   Behrouz Rostami,D. M. Anisuzzaman,Chuanbo Wang...   \n",
       "6   James Jin Kang,Mahdi Dibaei,Gang Luo,Wencheng ...   \n",
       "7   Junwoo Park,Youngwoo Cho,Haneol Lee,Jaegul Cho...   \n",
       "8   Sibi C. Sethuraman,Pranav Kompally,Saraju P. M...   \n",
       "9   Sita Rani,Aman Kataria,Smarajit Ghosh,Vinod Ka...   \n",
       "10              Dan Wang,Tianrui Wang,Ionuţ Florescu,   \n",
       "11                 Manas Gaur,Keyur Faldu,Amit Sheth,   \n",
       "12          Rahul Mishra,Dhruv Gupta,Markus Leippold,   \n",
       "13  Mario Milazzo,Giuseppe Gallone,Elena Marcello,...   \n",
       "14  Roya Sabbagh Novin,Amir Yazdani,Andrew Merrywe...   \n",
       "15          Lauren Baron,Brian Cohn,Roghayeh Barmaki,   \n",
       "16                             Yudi Dong,Yu-Dong Yao,   \n",
       "17               L. Parisi,D. Neagu,R. Ma,F. Campean,   \n",
       "18  Shuxi Zeng,Serge Assaad,Chenyang Tao,Shounak D...   \n",
       "19                  Axel Wismüller,Larry Stockmaster,   \n",
       "20  Pascal Zimmer,Roland Weinreich,Christian T. Ze...   \n",
       "21  Osama Shahid,Mohammad Nasajpour,Seyedamin Pour...   \n",
       "22                               Juan M Garcia-Gomez,   \n",
       "23           Fatima Zahra Yamani,Mohamed El Merouani,   \n",
       "24  Kamrun Naher Keya,Rashidul Islam,Shimei Pan,Ia...   \n",
       "25  Alexandros Rekkas,David van Klaveren,Patrick B...   \n",
       "26      Saman Motamed,Patrik Rogalla,Farzad Khalvati,   \n",
       "27  Wonyoung So,Edyta P. Bogucka,Sanja Šćepanović,...   \n",
       "28                    Anwaar Ulhaq,Oliver Burmeister,   \n",
       "29  Sonia Baee,Mark Rucker,Anna Baglione,Mawulolo ...   \n",
       "30  Chuanbo Wang,DM Anisuzzaman,Victor Williamson,...   \n",
       "31           Nikolaos Nikolaou,Konstantinos Sechidis,   \n",
       "32  Ali Najafi,Araz Gholipour-Shilabin,Rahim Dehkh...   \n",
       "33  Balazs P. Vagvolgyi,Mikhail Khrenov,Jonathan C...   \n",
       "34  Laurence A. Clarfeld,Robert Gramling,Donna M. ...   \n",
       "35  Tanujit Chakraborty,Indrajit Ghosh,Tirna Mahaj...   \n",
       "36            Mary Ellen Foster,Ronald P. A. Petrick,   \n",
       "37  Alfonso Emilio Gerevini,Roberto Maroldi,Matteo...   \n",
       "38  Sergio Martiradonna,Giulia Cisotto,Gennaro Bog...   \n",
       "39  AKM Iqtidar Newaz,Nur Imtiazul Haque,Amit Kuma...   \n",
       "40  Joshua J. Engelsma,Debayan Deb,Kai Cao,Anjoo B...   \n",
       "41  Pankaj Khatiwada,Matrika Subedi,Ayan Chatterje...   \n",
       "42                            Enrique M. Saldarriaga,   \n",
       "43  Maayan Shvo,Andrew C. Li,Rodrigo Toro Icarte,S...   \n",
       "44  Subba Reddy Oota,Nafisur Rahman,Shahid Saleem ...   \n",
       "45                      Razib Mustafiz,Khaled Mohsin,   \n",
       "46  Morteza Pourreza Shahri,Amir Tahmasebi,Bingyan...   \n",
       "47  Sam Sinai,Richard Wang,Alexander Whatley,Stewa...   \n",
       "48                                Oana-Maria Camburu,   \n",
       "49  Shruthi Chari,Oshani Seneviratne,Daniel M. Gru...   \n",
       "\n",
       "                                             abstract         submitted tag  \\\n",
       "0   \\nAbstract:\\n      \\n        …of cardiologists...  20 October, 2020       \n",
       "1   \\nAbstract:\\n      \\n        Health data is a ...  20 October, 2020       \n",
       "2   \\nAbstract:\\n      \\n        …advancement in a...  8 September, 202       \n",
       "3   \\nAbstract:\\n      \\n        Modeling infectio...  20 October, 2020       \n",
       "4   \\nAbstract:\\n      \\n        The recent corona...  19 October, 2020       \n",
       "5   \\nAbstract:\\n      \\n        Acute and chronic...  19 October, 2020       \n",
       "6   \\nAbstract:\\n      \\n        Privacy protectio...  19 October, 2020       \n",
       "7   \\nAbstract:\\n      \\n        Question Answerin...  19 October, 2020       \n",
       "8   \\nAbstract:\\n      \\n        Smart healthcare ...  17 October, 2020       \n",
       "9   \\nAbstract:\\n      \\n        …discussed in det...  17 October, 2020       \n",
       "10  \\nAbstract:\\n      \\n        …technique (Hilbe...  16 October, 2020       \n",
       "11  \\nAbstract:\\n      \\n        …how this makes a...  16 October, 2020       \n",
       "12  \\nAbstract:\\n      \\n        …art by using imp...  16 October, 2020       \n",
       "13  \\nAbstract:\\n      \\n        Bacterial coloniz...  16 October, 2020       \n",
       "14  \\nAbstract:\\n      \\n        …is a crucial cap...  15 October, 2020       \n",
       "15  \\nAbstract:\\n      \\n        …among participan...  15 October, 2020       \n",
       "16  \\nAbstract:\\n      \\n        …platform is pref...  15 October, 2020       \n",
       "17  \\nAbstract:\\n      \\n        …its unresolved d...  15 October, 2020       \n",
       "18  \\nAbstract:\\n      \\n        Causal inference,...  16 October, 2020       \n",
       "19  \\nAbstract:\\n      \\n        …times in patient...  14 October, 2020       \n",
       "20  \\nAbstract:\\n      \\n        …group-key establ...  14 October, 2020       \n",
       "21  \\nAbstract:\\n      \\n        …and millions of ...  29 September, 20       \n",
       "22  \\nAbstract:\\n      \\n        …radiation, along...  29 September, 20       \n",
       "23  \\nAbstract:\\n      \\n        …to specific area...  22 September, 20       \n",
       "24  \\nAbstract:\\n      \\nHealthcare programs such ...  14 October, 2020       \n",
       "25  \\nAbstract:\\n      \\n        Aim: One of the a...  13 October, 2020       \n",
       "26  \\nAbstract:\\n      \\n        COVID-19 spread a...  6 October, 2020;       \n",
       "27  \\nAbstract:\\n      \\n        …mind on previous...  13 October, 2020       \n",
       "28  \\nAbstract:\\n      \\n        To address COVID-...  13 October, 2020       \n",
       "29  \\nAbstract:\\n      \\n        Virtual coaching ...  12 October, 2020       \n",
       "30  \\nAbstract:\\n      \\n        Acute and chronic...  12 October, 2020       \n",
       "31  \\nAbstract:\\n      \\n        At the heart of c...  12 October, 2020       \n",
       "32  \\nAbstract:\\n      \\n        …ideas with other...  11 October, 2020       \n",
       "33  \\nAbstract:\\n      \\n        …disease caused b...  11 October, 2020       \n",
       "34  \\nAbstract:\\n      \\n        …patterns vary ac...  11 October, 2020       \n",
       "35  \\nAbstract:\\n      \\n        …to show that the...  10 October, 2020       \n",
       "36  \\nAbstract:\\n      \\n        …and social actio...  9 October, 2020;       \n",
       "37  \\nAbstract:\\n      \\n        AI and Machine Le...  9 October, 2020;       \n",
       "38  \\nAbstract:\\n      \\n        Pervasive healthc...  8 October, 2020;       \n",
       "39  \\nAbstract:\\n      \\n        The increasing av...  7 October, 2020;       \n",
       "40  \\nAbstract:\\n      \\n        …Infant-Prints ca...  7 October, 2020;       \n",
       "41  \\nAbstract:\\n      \\n        In smart healthca...  7 October, 2020;       \n",
       "42  \\nAbstract:\\n      \\n        …of the HIV preva...  6 October, 2020;       \n",
       "43  \\nAbstract:\\n      \\n        Sequence classifi...  6 October, 2020;       \n",
       "44  \\nAbstract:\\n      \\n        The Affordable ca...  5 October, 2020;       \n",
       "45  \\nAbstract:\\n      \\n        The recent outbre...  3 October, 2020;       \n",
       "46  \\nAbstract:\\n      \\n        …extraction, stor...  10 October, 2020       \n",
       "47  \\nAbstract:\\n      \\n        Efficient design ...  5 October, 2020;       \n",
       "48  \\nAbstract:\\n      \\n        …language process...  4 October, 2020;       \n",
       "49  \\nAbstract:\\n      \\n        …(AI) systems sin...  3 October, 2020;       \n",
       "\n",
       "                                  doi  \n",
       "0                                      \n",
       "1                                      \n",
       "2                                      \n",
       "3                                      \n",
       "4                                      \n",
       "5                                      \n",
       "6                                      \n",
       "7                                      \n",
       "8                                      \n",
       "9                                      \n",
       "10         10.1109/JIOT.2020.3030492   \n",
       "11                                     \n",
       "12                                     \n",
       "13               10.3390/jfb11030060   \n",
       "14                                     \n",
       "15                                     \n",
       "16                                     \n",
       "17                                     \n",
       "18                                     \n",
       "19                                     \n",
       "20                                     \n",
       "21                                     \n",
       "22                                     \n",
       "23            10.5281/zenodo.3987129   \n",
       "24                                     \n",
       "25                                     \n",
       "26                                     \n",
       "27                                     \n",
       "28                                     \n",
       "29           10.1145/3421937.3421971   \n",
       "30                                     \n",
       "31                                     \n",
       "32                                     \n",
       "33                                     \n",
       "34                                     \n",
       "35                                     \n",
       "36                                     \n",
       "37                                     \n",
       "38                                     \n",
       "39                                     \n",
       "40                                     \n",
       "41                                     \n",
       "42                                     \n",
       "43                                     \n",
       "44                                     \n",
       "45  10.20944/preprints202009.0647.v1   \n",
       "46                                     \n",
       "47                                     \n",
       "48                                     \n",
       "49                                     "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'title': title, \n",
    "        'arxiv_id': arxiv_id,\n",
    "        'article link': article_link,\n",
    "        'pdf link': pdf_link,\n",
    "        'author': author_list_arr,\n",
    "        'abstract': abstract,\n",
    "        'submitted': date,\n",
    "        'tag': tag_list_arr,\n",
    "        'doi': doi_tag}\n",
    "articles=pd.DataFrame(data, columns=['title','arxiv_id','article link','pdf link','author','abstract','submitted','tag','doi'])\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['clean_text']=articles['abstract'].str.replace(r'[^\\w\\s]', ' ').str.lower()\n",
    "articles['words']=articles['clean_text'].str.split(r'\\W+')\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "stopword\n",
    "wordlist=articles['words'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for word in wordlist:\n",
    "    if word not in stopword:\n",
    "        result.append(word)\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'abstract',\n",
       " 'acute',\n",
       " 'chronic',\n",
       " 'wounds',\n",
       " 'challenge',\n",
       " 'healthcare',\n",
       " 'systems',\n",
       " 'around',\n",
       " 'world',\n",
       " 'affect',\n",
       " 'many',\n",
       " 'people',\n",
       " 'lives',\n",
       " 'annually',\n",
       " 'wound',\n",
       " 'classification',\n",
       " 'key',\n",
       " 'step',\n",
       " 'wound',\n",
       " 'diagnosis',\n",
       " 'would',\n",
       " 'help',\n",
       " 'clinicians',\n",
       " 'identify',\n",
       " 'optimal',\n",
       " 'treatment',\n",
       " 'procedure',\n",
       " 'hence',\n",
       " 'high',\n",
       " 'performance',\n",
       " 'classifier',\n",
       " 'assists',\n",
       " 'specialists',\n",
       " 'field',\n",
       " 'classify',\n",
       " 'wounds',\n",
       " 'l',\n",
       " 'acute',\n",
       " 'chronic',\n",
       " 'wounds',\n",
       " 'challenge',\n",
       " 'healthcare',\n",
       " 'systems',\n",
       " 'around',\n",
       " 'world',\n",
       " 'affect',\n",
       " 'many',\n",
       " 'people',\n",
       " 'lives',\n",
       " 'annually',\n",
       " 'wound',\n",
       " 'classification',\n",
       " 'key',\n",
       " 'step',\n",
       " 'wound',\n",
       " 'diagnosis',\n",
       " 'would',\n",
       " 'help',\n",
       " 'clinicians',\n",
       " 'identify',\n",
       " 'optimal',\n",
       " 'treatment',\n",
       " 'procedure',\n",
       " 'hence',\n",
       " 'high',\n",
       " 'performance',\n",
       " 'classifier',\n",
       " 'assists',\n",
       " 'specialists',\n",
       " 'field',\n",
       " 'classify',\n",
       " 'wounds',\n",
       " 'less',\n",
       " 'financial',\n",
       " 'time',\n",
       " 'costs',\n",
       " 'different',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'based',\n",
       " 'wound',\n",
       " 'classification',\n",
       " 'methods',\n",
       " 'proposed',\n",
       " 'literature',\n",
       " 'study',\n",
       " 'developed',\n",
       " 'ensemble',\n",
       " 'deep',\n",
       " 'convolutional',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'based',\n",
       " 'classifier',\n",
       " 'classify',\n",
       " 'wound',\n",
       " 'images',\n",
       " 'including',\n",
       " 'surgical',\n",
       " 'diabetic',\n",
       " 'venous',\n",
       " 'ulcers',\n",
       " 'multi',\n",
       " 'classes',\n",
       " 'output',\n",
       " 'classification',\n",
       " 'scores',\n",
       " 'two',\n",
       " 'classifiers',\n",
       " 'patch',\n",
       " 'wise',\n",
       " 'image',\n",
       " 'wise',\n",
       " 'fed',\n",
       " 'multi',\n",
       " 'layer',\n",
       " 'perceptron',\n",
       " 'provide',\n",
       " 'superior',\n",
       " 'classification',\n",
       " 'performance',\n",
       " '5',\n",
       " 'fold',\n",
       " 'cross',\n",
       " 'validation',\n",
       " 'approach',\n",
       " 'used',\n",
       " 'evaluate',\n",
       " 'proposed',\n",
       " 'method',\n",
       " 'obtained',\n",
       " 'maximum',\n",
       " 'average',\n",
       " 'classification',\n",
       " 'accuracy',\n",
       " 'values',\n",
       " '96',\n",
       " '4',\n",
       " '94',\n",
       " '28',\n",
       " 'binary',\n",
       " '91',\n",
       " '9',\n",
       " '87',\n",
       " '7',\n",
       " '3',\n",
       " 'class',\n",
       " 'classification',\n",
       " 'problems',\n",
       " 'results',\n",
       " 'show',\n",
       " 'proposed',\n",
       " 'method',\n",
       " 'used',\n",
       " 'effectively',\n",
       " 'decision',\n",
       " 'support',\n",
       " 'system',\n",
       " 'classification',\n",
       " 'wound',\n",
       " 'images',\n",
       " 'related',\n",
       " 'clinical',\n",
       " 'applications',\n",
       " 'less',\n",
       " '']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in wordlist if word not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(wordlist):\n",
    "    return [word for word in wordlist if word not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [, abstract, acute, chronic, wounds, challenge...\n",
       "1     [, abstract, privacy, protection, electronic, ...\n",
       "2     [, abstract, question, answering, qa, electron...\n",
       "3     [, abstract, smart, healthcare, built, smart, ...\n",
       "4     [, abstract, discussed, detail, paper, also, p...\n",
       "5     [, abstract, technique, hilbert, vector, arran...\n",
       "6     [, abstract, makes, fundamental, difference, i...\n",
       "7     [, abstract, art, using, improved, claim, titl...\n",
       "8     [, abstract, bacterial, colonization, ofimplan...\n",
       "9     [, abstract, crucial, capability, autonomous, ...\n",
       "10    [, abstract, among, participants, work, offers...\n",
       "11    [, abstract, platform, preferred, utilized, ac...\n",
       "12    [, abstract, unresolved, dying, relu, problem,...\n",
       "13    [, abstract, causal, inference, counterfactual...\n",
       "14    [, abstract, times, patients, emergent, clinic...\n",
       "15    [, abstract, group, key, establishment, proof,...\n",
       "16    [, abstract, millions, people, virus, deadly, ...\n",
       "17    [, abstract, radiation, along, distance, isola...\n",
       "18    [, abstract, specific, areas, systems, become,...\n",
       "19    [, abstract, healthcare, programs, medicaid, p...\n",
       "20    [, abstract, aim, one, aims, observation, heal...\n",
       "21    [, abstract, covid, 19, spread, across, globe,...\n",
       "22    [, abstract, mind, previously, held, opinions,...\n",
       "23    [, abstract, address, covid, 19, healthcare, c...\n",
       "24    [, abstract, virtual, coaching, rapidly, evolv...\n",
       "25    [, abstract, acute, chronic, wounds, varying, ...\n",
       "26    [, abstract, heart, causal, structure, learnin...\n",
       "27    [, abstract, ideas, others, different, issues,...\n",
       "28    [, abstract, disease, caused, virus, covid, 19...\n",
       "29    [, abstract, patterns, vary, across, narrative...\n",
       "30    [, abstract, show, universal, method, availabl...\n",
       "31    [, abstract, social, actions, interacting, hum...\n",
       "32    [, abstract, ai, machine, learning, offer, pow...\n",
       "33    [, abstract, pervasive, healthcare, promising,...\n",
       "34    [, abstract, increasing, availability, healthc...\n",
       "35    [, abstract, infant, prints, deliver, accurate...\n",
       "36    [, abstract, smart, healthcare, human, activit...\n",
       "37    [, abstract, hiv, prevalence, subset, african,...\n",
       "38    [, abstract, sequence, classification, task, p...\n",
       "39    [, abstract, affordable, care, act, 2010, intr...\n",
       "40    [, abstract, recent, outbreak, sars, cov, 2, g...\n",
       "41    [, abstract, extraction, storage, querying, pa...\n",
       "42    [, abstract, efficient, design, biological, se...\n",
       "43    [, abstract, language, processing, speech, rec...\n",
       "44    [, abstract, ai, systems, since, conception, n...\n",
       "45    [, abstract, reliability, neural, networks, nn...\n",
       "46    [, abstract, vendor, locked, environments, alt...\n",
       "47    [, abstract, catalyzed, intense, flurry, progr...\n",
       "48    [, abstract, encapsulating, common, prediction...\n",
       "49    [, abstract, visualization, useful, technology...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['words'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text=re.sub(r'[^\\w\\s]',' ',text).lower()   ### Remove punctuation by removing non-space alpha-num characters\n",
    "    words=re.split(r'\\W+', text)                   ### Split by remaining non-alphanumeric characters \n",
    "    non_stop_words=[word for word in words if word not in stopword]        ### Remove stopwords\n",
    "    lem_words= [wn.lemmatize(word) for word in non_stop_words]             ### Clean text ==\n",
    "    clean_text= ' '.join(lem_words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer=CountVectorizer()\n",
    "X_counts=count_vectorizer.fit_transform(articles['clean_text'])\n",
    "X_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '03',\n",
       " '05',\n",
       " '10',\n",
       " '100',\n",
       " '109',\n",
       " '11ax',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '180',\n",
       " '19',\n",
       " '1d',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2010',\n",
       " '2012',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2024',\n",
       " '2030s',\n",
       " '22',\n",
       " '27',\n",
       " '271',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '315',\n",
       " '33',\n",
       " '3d',\n",
       " '40',\n",
       " '421',\n",
       " '44',\n",
       " '52',\n",
       " '54',\n",
       " '5g',\n",
       " '60',\n",
       " '71',\n",
       " '77',\n",
       " '802',\n",
       " '85',\n",
       " '87',\n",
       " '889',\n",
       " '900',\n",
       " '91',\n",
       " '92',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " 'aal',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'about',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'abstract',\n",
       " 'access',\n",
       " 'accesses',\n",
       " 'accomplishing',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'acoustic',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'acute',\n",
       " 'acyclic',\n",
       " 'adalead',\n",
       " 'adaptable',\n",
       " 'adaptations',\n",
       " 'adaptive',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admitted',\n",
       " 'adoption',\n",
       " 'adress',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adversarial',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'advice',\n",
       " 'af',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affordable',\n",
       " 'african',\n",
       " 'afs',\n",
       " 'after',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agent',\n",
       " 'ages',\n",
       " 'agra',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aims',\n",
       " 'alarms',\n",
       " 'alert',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'all',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongwith',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'although',\n",
       " 'alzheimer',\n",
       " 'alzheimers',\n",
       " 'ambient',\n",
       " 'amended',\n",
       " 'amidst',\n",
       " 'among',\n",
       " 'amounts',\n",
       " 'an',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anger',\n",
       " 'angiotensin',\n",
       " 'annotated',\n",
       " 'annually',\n",
       " 'anomaly',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'antibacterial',\n",
       " 'antibiotics',\n",
       " 'antifouling',\n",
       " 'antimicrobial',\n",
       " 'any',\n",
       " 'appearing',\n",
       " 'applicability',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'approximately',\n",
       " 'approximators',\n",
       " 'apps',\n",
       " 'april',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'arduously',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'around',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulation',\n",
       " 'artificial',\n",
       " 'as',\n",
       " 'ashram',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'assembler',\n",
       " 'assess',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assisted',\n",
       " 'assistive',\n",
       " 'assists',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'assumptions',\n",
       " 'assurance',\n",
       " 'assuring',\n",
       " 'at',\n",
       " 'atop',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'attention',\n",
       " 'attractive',\n",
       " 'attributes',\n",
       " 'auditing',\n",
       " 'augment',\n",
       " 'augments',\n",
       " 'authenticated',\n",
       " 'authentication',\n",
       " 'authors',\n",
       " 'automata',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automation',\n",
       " 'automl',\n",
       " 'autonomous',\n",
       " 'autoprognosis',\n",
       " 'autoregressive',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'average',\n",
       " 'averse',\n",
       " 'avoid',\n",
       " 'avoidable',\n",
       " 'avoids',\n",
       " 'aware',\n",
       " 'bacterial',\n",
       " 'balanced',\n",
       " 'balancing',\n",
       " 'band',\n",
       " 'base',\n",
       " 'based',\n",
       " 'baseline',\n",
       " 'baselines',\n",
       " 'basic',\n",
       " 'battery',\n",
       " 'battling',\n",
       " 'bayesian',\n",
       " 'be',\n",
       " 'beat',\n",
       " 'beats',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'bench',\n",
       " 'benchmark',\n",
       " 'benchmarks',\n",
       " 'beneficiaries',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bi',\n",
       " 'bias',\n",
       " 'big',\n",
       " 'billion',\n",
       " 'binary',\n",
       " 'biofouling',\n",
       " 'biological',\n",
       " 'biologically',\n",
       " 'biologists',\n",
       " 'biomaterial',\n",
       " 'biomaterials',\n",
       " 'biomedical',\n",
       " 'black',\n",
       " 'blockchain',\n",
       " 'blockers',\n",
       " 'board',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'boosting',\n",
       " 'boosts',\n",
       " 'both',\n",
       " 'box',\n",
       " 'breast',\n",
       " 'bridge',\n",
       " 'bring',\n",
       " 'broad',\n",
       " 'broader',\n",
       " 'brought',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'burden',\n",
       " 'business',\n",
       " 'but',\n",
       " 'by',\n",
       " 'calculate',\n",
       " 'called',\n",
       " 'camera',\n",
       " 'can',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'capabilities',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'capture',\n",
       " 'captured',\n",
       " 'captures',\n",
       " 'capturing',\n",
       " 'car',\n",
       " 'cardea',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'caregivers',\n",
       " 'carlini',\n",
       " 'carried',\n",
       " 'cartesian',\n",
       " 'cascaded',\n",
       " 'cascading',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'catalyzed',\n",
       " 'categories',\n",
       " 'category',\n",
       " 'causal',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cbo',\n",
       " 'cellular',\n",
       " 'census',\n",
       " 'centers',\n",
       " 'central',\n",
       " 'centralized',\n",
       " 'centric',\n",
       " 'certain',\n",
       " 'chain',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'characters',\n",
       " 'charitable',\n",
       " 'checking',\n",
       " 'chemical',\n",
       " 'chest',\n",
       " 'children',\n",
       " 'choices',\n",
       " 'chose',\n",
       " 'chronic',\n",
       " 'chunk',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'claims',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classification',\n",
       " 'classifier',\n",
       " 'classifiers',\n",
       " 'classifies',\n",
       " 'classify',\n",
       " 'clear',\n",
       " 'clinical',\n",
       " 'clinicians',\n",
       " 'closer',\n",
       " 'cloud',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'cnn',\n",
       " 'cnns',\n",
       " 'co',\n",
       " 'coaches',\n",
       " 'coaching',\n",
       " 'coatings',\n",
       " 'code',\n",
       " 'codym',\n",
       " 'codyms',\n",
       " 'cognitive',\n",
       " 'collaborative',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'colliding',\n",
       " 'colonization',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combating',\n",
       " 'combination',\n",
       " 'combined',\n",
       " 'combines',\n",
       " 'combining',\n",
       " 'comfort',\n",
       " 'commercial',\n",
       " 'commercially',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communicative',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'compact',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'comparable',\n",
       " 'comparator',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'competency',\n",
       " 'competes',\n",
       " 'competitive',\n",
       " 'competitiveness',\n",
       " 'complement',\n",
       " 'complements',\n",
       " 'completed',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'complications',\n",
       " 'component',\n",
       " 'components',\n",
       " 'comprehend',\n",
       " 'comprehensive',\n",
       " 'comprised',\n",
       " 'compromising',\n",
       " 'computation',\n",
       " 'computationa',\n",
       " 'computational',\n",
       " 'compute',\n",
       " 'computer',\n",
       " 'computing',\n",
       " 'comstreamclust',\n",
       " 'concatenation',\n",
       " 'concept',\n",
       " 'conception',\n",
       " 'conceptually',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'concisely',\n",
       " 'conclude',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'concrete',\n",
       " 'condensed',\n",
       " 'condition',\n",
       " 'conditional',\n",
       " 'conditions',\n",
       " 'conducting',\n",
       " 'confidence',\n",
       " 'configurations',\n",
       " 'confirmed',\n",
       " 'confirming',\n",
       " 'connected',\n",
       " 'connectivity',\n",
       " 'consequently',\n",
       " 'conserve',\n",
       " 'consider',\n",
       " 'considerable',\n",
       " 'consideration',\n",
       " 'considerations',\n",
       " 'considered',\n",
       " 'consistency',\n",
       " 'consistent',\n",
       " 'consisting',\n",
       " 'consists',\n",
       " 'consolidates',\n",
       " 'constrained',\n",
       " 'construct',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contacts',\n",
       " 'contain',\n",
       " 'context',\n",
       " 'contextual',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continuous',\n",
       " 'continuously',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'contributed',\n",
       " 'contributes',\n",
       " 'contribution',\n",
       " 'contributions',\n",
       " 'contributors',\n",
       " 'control',\n",
       " 'controllable',\n",
       " 'controlling',\n",
       " 'controls',\n",
       " 'convenient',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'conversational',\n",
       " 'conversations',\n",
       " 'converted',\n",
       " 'converting',\n",
       " 'convolutional',\n",
       " 'cope',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'coronavirus',\n",
       " 'corporate',\n",
       " 'corrective',\n",
       " 'correctly',\n",
       " 'correctness',\n",
       " 'corresponding',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'cough',\n",
       " 'could',\n",
       " 'counterfactual',\n",
       " 'countering',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'cov',\n",
       " 'covid',\n",
       " 'covid19',\n",
       " 'covidx',\n",
       " 'cox',\n",
       " 'cps',\n",
       " 'crafting',\n",
       " 'creating',\n",
       " 'creative',\n",
       " 'credence',\n",
       " 'crew',\n",
       " 'crewmember',\n",
       " 'crewmembers',\n",
       " 'criteria',\n",
       " 'critical',\n",
       " 'cross',\n",
       " 'crucial',\n",
       " 'cryptocurrency',\n",
       " 'ct',\n",
       " 'cues',\n",
       " 'culture',\n",
       " 'cumbersome',\n",
       " 'cup',\n",
       " 'cure',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'custom',\n",
       " 'cutting',\n",
       " 'cy',\n",
       " 'cyber',\n",
       " 'cybercrime',\n",
       " 'cybercrimes',\n",
       " 'dag',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'damaged',\n",
       " 'dar',\n",
       " 'data',\n",
       " 'database',\n",
       " 'databases',\n",
       " 'dataset',\n",
       " 'datasets',\n",
       " 'day',\n",
       " 'dayalbagh',\n",
       " 'de',\n",
       " 'deadly',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'death',\n",
       " 'deaths',\n",
       " 'deceivingly',\n",
       " 'december',\n",
       " 'decentralized',\n",
       " 'decide',\n",
       " 'decision',\n",
       " 'decompensation',\n",
       " 'decreased',\n",
       " 'dedicated',\n",
       " 'deep',\n",
       " 'define',\n",
       " 'defined',\n",
       " 'definition',\n",
       " 'definitions',\n",
       " 'definitive',\n",
       " 'degradable',\n",
       " 'degrade',\n",
       " 'delay',\n",
       " 'deliver',\n",
       " 'delivery',\n",
       " 'demand',\n",
       " 'demanded',\n",
       " 'dementia',\n",
       " 'demographic',\n",
       " 'demonstrate',\n",
       " 'demonstrated',\n",
       " 'demonstrates',\n",
       " 'demonstrating',\n",
       " 'dense',\n",
       " 'department',\n",
       " 'dependence',\n",
       " 'dependencies',\n",
       " 'dependent',\n",
       " 'deployment',\n",
       " 'derive',\n",
       " 'derived',\n",
       " 'dermatology',\n",
       " 'describe',\n",
       " 'describes',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'designer',\n",
       " 'designers',\n",
       " 'designing',\n",
       " 'desirable',\n",
       " 'despite',\n",
       " 'detail',\n",
       " 'detect',\n",
       " 'detecting',\n",
       " 'detection',\n",
       " 'detects',\n",
       " 'deteriorate',\n",
       " 'determinacy',\n",
       " 'determining',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'developers',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'device',\n",
       " 'devices',\n",
       " 'devicesis',\n",
       " 'dhs',\n",
       " 'diabetic',\n",
       " 'diagnose',\n",
       " 'diagnoses',\n",
       " 'diagnosis',\n",
       " 'diagnostic',\n",
       " 'did',\n",
       " 'die',\n",
       " 'died',\n",
       " 'differ',\n",
       " 'difference',\n",
       " 'differences',\n",
       " 'different',\n",
       " 'differential',\n",
       " 'differentially',\n",
       " 'difficult',\n",
       " 'difficulty',\n",
       " 'digital',\n",
       " 'dimensional',\n",
       " 'dir',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'direction',\n",
       " 'directional',\n",
       " 'directions',\n",
       " 'directly',\n",
       " 'discharge',\n",
       " 'disciplines',\n",
       " 'discover',\n",
       " 'discovered',\n",
       " 'discovering',\n",
       " 'discrete',\n",
       " 'discuss',\n",
       " 'discussed',\n",
       " 'discussing',\n",
       " 'disease',\n",
       " 'diseases',\n",
       " 'disruptive',\n",
       " 'distance',\n",
       " 'distancing',\n",
       " 'distinguishing',\n",
       " 'distressing',\n",
       " 'distribution',\n",
       " 'divergence',\n",
       " 'diverse',\n",
       " 'diversified',\n",
       " 'dl',\n",
       " 'dls',\n",
       " 'dnn',\n",
       " 'do',\n",
       " 'document',\n",
       " 'documentation',\n",
       " 'documents',\n",
       " 'does',\n",
       " 'doff',\n",
       " 'doffing',\n",
       " 'doing',\n",
       " 'domain',\n",
       " 'domains',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donning',\n",
       " 'double',\n",
       " 'dpbd',\n",
       " 'drawing',\n",
       " 'drawings',\n",
       " 'driven',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'dss',\n",
       " 'dubious',\n",
       " 'due',\n",
       " 'during',\n",
       " 'dying',\n",
       " 'dynamic',\n",
       " 'dynamics',\n",
       " 'each',\n",
       " 'ear',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'economic',\n",
       " 'economy',\n",
       " 'edgar',\n",
       " 'edge',\n",
       " 'education',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effectiveness',\n",
       " 'effects',\n",
       " 'efficacy',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'ehr',\n",
       " 'either',\n",
       " 'electronic',\n",
       " 'electronics',\n",
       " 'electrostatic',\n",
       " 'element',\n",
       " 'elements',\n",
       " 'embedding',\n",
       " 'embeddings',\n",
       " 'embolism',\n",
       " 'emergency',\n",
       " 'emergent',\n",
       " 'emerging',\n",
       " 'emotions',\n",
       " 'emphasis',\n",
       " 'empirical',\n",
       " 'employing',\n",
       " 'enabled',\n",
       " 'enabling',\n",
       " 'encapsulating',\n",
       " 'encoders',\n",
       " 'encoding',\n",
       " 'encompass',\n",
       " 'encourage',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'engagement',\n",
       " 'engineering',\n",
       " 'england',\n",
       " 'english',\n",
       " 'enhance',\n",
       " 'enhanced',\n",
       " 'enhancement',\n",
       " 'enormous',\n",
       " 'enough',\n",
       " 'enrolled',\n",
       " 'enrollment',\n",
       " 'ensemble',\n",
       " 'ensembles',\n",
       " 'ensembling',\n",
       " 'ensure',\n",
       " 'ensuring',\n",
       " 'entanglement',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'enterprise',\n",
       " 'entities',\n",
       " 'entropy',\n",
       " 'environment',\n",
       " 'environmental',\n",
       " 'environments',\n",
       " 'enzyme',\n",
       " 'epidemic',\n",
       " 'epidemics',\n",
       " 'epidemiologic',\n",
       " 'epidemiological',\n",
       " 'epileptic',\n",
       " 'episode',\n",
       " 'epistemic',\n",
       " 'epoch',\n",
       " 'equally',\n",
       " 'equip',\n",
       " 'equipment',\n",
       " 'equipped',\n",
       " 'equitable',\n",
       " 'ergonomic',\n",
       " 'erp',\n",
       " 'erroneous',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'es',\n",
       " 'especially',\n",
       " 'essentially',\n",
       " 'establish',\n",
       " 'establishment',\n",
       " 'estimate',\n",
       " 'estimated',\n",
       " 'estimates',\n",
       " 'estimation',\n",
       " 'estimators',\n",
       " 'etc',\n",
       " 'ethics',\n",
       " 'etiologies',\n",
       " 'etiology',\n",
       " 'europe',\n",
       " 'evaluate',\n",
       " 'evaluated',\n",
       " 'evaluating',\n",
       " 'evaluation',\n",
       " 'evaluations',\n",
       " 'even',\n",
       " 'event',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'ever',\n",
       " 'everyday',\n",
       " 'evidence',\n",
       " 'evolution',\n",
       " 'evolutionary',\n",
       " 'evolvability',\n",
       " 'evolved',\n",
       " 'evolving',\n",
       " 'examine',\n",
       " 'example',\n",
       " 'examples',\n",
       " 'exceed',\n",
       " 'exceedingly',\n",
       " 'exchange',\n",
       " 'exchanges',\n",
       " 'existing',\n",
       " 'exists',\n",
       " 'expansion',\n",
       " 'expected',\n",
       " 'expedition',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experiments',\n",
       " 'expertise',\n",
       " 'explain',\n",
       " 'explainability',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'explanation',\n",
       " 'explanations',\n",
       " 'explanatory',\n",
       " 'exploit',\n",
       " 'explorat',\n",
       " 'exploration',\n",
       " 'exploratory',\n",
       " 'explored',\n",
       " 'exploring',\n",
       " 'expressions',\n",
       " 'extend',\n",
       " 'extended',\n",
       " 'extensible',\n",
       " 'extension',\n",
       " 'extensive',\n",
       " 'extensively',\n",
       " 'extract',\n",
       " 'extraction',\n",
       " 'extractive',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'f1',\n",
       " 'fa',\n",
       " 'facilitate',\n",
       " 'facilitating',\n",
       " 'facility',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'failure',\n",
       " 'failures',\n",
       " 'fair',\n",
       " 'fairness',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'favorable',\n",
       " 'favour',\n",
       " 'favourable',\n",
       " 'fear',\n",
       " 'feasibility',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'february',\n",
       " 'fed',\n",
       " 'federated',\n",
       " 'females',\n",
       " 'fhir',\n",
       " 'field',\n",
       " 'fields',\n",
       " 'fight',\n",
       " 'filings',\n",
       " 'filtering',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'finance',\n",
       " 'finances',\n",
       " 'financial',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'findings',\n",
       " 'finger',\n",
       " 'fingerprint',\n",
       " 'fingerprints',\n",
       " 'finite',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fitness',\n",
       " 'five',\n",
       " 'fixed',\n",
       " 'flaws',\n",
       " 'flexibility',\n",
       " 'flexs',\n",
       " 'flight',\n",
       " 'flow',\n",
       " 'flurry',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'focuses',\n",
       " 'focusing',\n",
       " 'fog',\n",
       " 'fold',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'forcing',\n",
       " 'forecast',\n",
       " 'forecasters',\n",
       " 'forecasting',\n",
       " 'forensics',\n",
       " 'foreseeable',\n",
       " 'form',\n",
       " 'formatting',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'foundational',\n",
       " 'four',\n",
       " 'framework',\n",
       " 'frameworks',\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=count_vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>109</th>\n",
       "      <th>11ax</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>would</th>\n",
       "      <th>wound</th>\n",
       "      <th>wounds</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>zeroth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 2480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  03  05  10  100  109  11ax  12  13  14  ...  works  world  worldwide  \\\n",
       "0     0   0   0   0    0    0     0   0   0   0  ...      0      2          0   \n",
       "1     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "2     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "3     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "4     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "5     0   0   0   0    0    0     0   0   0   0  ...      2      0          0   \n",
       "6     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "7     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "8     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "9     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "10    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "11    0   0   0   0    0    0     0   0   0   0  ...      0      0          1   \n",
       "12    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "13    0   0   0   0    0    0     0   0   0   0  ...      0      1          0   \n",
       "14    0   0   1   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "15    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "16    0   0   0   0    0    0     0   0   0   0  ...      0      0          1   \n",
       "17    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "18    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "19    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "20    0   1   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "21    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "22    0   0   0   2    0    0     0   0   0   1  ...      0      0          0   \n",
       "23    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "24    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "25    0   0   0   0    0    1     0   0   0   0  ...      0      2          0   \n",
       "26    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "27    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "28    2   0   0   0    0    1     0   0   0   0  ...      0      0          2   \n",
       "29    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "30    0   0   0   0    0    0     0   0   0   0  ...      0      0          2   \n",
       "31    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "32    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "33    0   0   0   0    0    0     1   0   0   0  ...      0      0          0   \n",
       "34    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "35    0   0   0   0    0    0     0   1   0   0  ...      0      1          0   \n",
       "36    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "37    0   0   0   1    0    0     0   1   1   1  ...      0      0          0   \n",
       "38    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "39    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "40    0   0   0   0    0    0     0   0   0   0  ...      0      3          3   \n",
       "41    0   0   0   0    1    0     0   0   0   0  ...      0      0          0   \n",
       "42    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "43    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "44    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "45    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "46    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "47    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "48    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "49    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "\n",
       "    would  wound  wounds  year  years  yet  zeroth  \n",
       "0       2      7       4     0      0    0       0  \n",
       "1       0      0       0     0      0    0       0  \n",
       "2       0      0       0     0      0    0       0  \n",
       "3       0      0       0     0      0    0       0  \n",
       "4       0      0       0     0      0    0       0  \n",
       "5       0      0       0     0      0    0       0  \n",
       "6       0      0       0     0      0    1       0  \n",
       "7       0      0       0     0      0    0       0  \n",
       "8       1      0       0     2      0    0       0  \n",
       "9       0      0       0     0      0    0       0  \n",
       "10      0      0       0     0      0    0       0  \n",
       "11      0      0       0     0      1    0       0  \n",
       "12      0      0       0     0      0    0       0  \n",
       "13      0      0       0     0      0    0       0  \n",
       "14      0      0       0     0      0    0       0  \n",
       "15      0      0       0     0      0    0       0  \n",
       "16      0      0       0     0      0    0       0  \n",
       "17      1      0       0     0      0    0       0  \n",
       "18      0      0       0     0      0    0       0  \n",
       "19      0      0       0     0      0    0       0  \n",
       "20      0      0       0     0      0    0       0  \n",
       "21      0      0       0     0      0    0       0  \n",
       "22      0      0       0     0      0    1       0  \n",
       "23      0      0       0     0      0    0       0  \n",
       "24      0      0       0     0      0    0       0  \n",
       "25      0     10       2     0      0    0       0  \n",
       "26      0      0       0     0      0    0       0  \n",
       "27      2      0       0     0      0    0       0  \n",
       "28      0      0       0     0      0    0       0  \n",
       "29      0      0       0     0      0    0       0  \n",
       "30      0      0       0     0      0    0       0  \n",
       "31      0      0       0     0      0    0       0  \n",
       "32      0      0       0     0      0    0       0  \n",
       "33      0      0       0     0      0    0       0  \n",
       "34      0      0       0     0      0    0       1  \n",
       "35      0      0       0     0      0    0       0  \n",
       "36      0      0       0     0      0    0       0  \n",
       "37      0      0       0     0      0    0       0  \n",
       "38      0      0       0     0      0    0       0  \n",
       "39      0     10       1     0      0    0       0  \n",
       "40      0      0       0     0      1    0       0  \n",
       "41      0      0       0     0      0    0       0  \n",
       "42      0      0       0     0      1    0       0  \n",
       "43      0      0       0     0      0    0       0  \n",
       "44      0      0       0     0      0    0       0  \n",
       "45      0      0       0     0      0    0       0  \n",
       "46      0      0       0     0      0    0       0  \n",
       "47      0      0       0     1      0    0       0  \n",
       "48      0      0       0     0      0    0       0  \n",
       "49      0      0       0     0      0    0       0  \n",
       "\n",
       "[50 rows x 2480 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_counts.toarray(), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>109</th>\n",
       "      <th>11ax</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>would</th>\n",
       "      <th>wound</th>\n",
       "      <th>wounds</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>zeroth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 2480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  03  05  10  100  109  11ax  12  13  14  ...  works  world  worldwide  \\\n",
       "0     0   0   0   0    0    0     0   0   0   0  ...      0      2          0   \n",
       "1     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "2     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "3     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "4     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "5     0   0   0   0    0    0     0   0   0   0  ...      2      0          0   \n",
       "6     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "7     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "8     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "9     0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "10    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "11    0   0   0   0    0    0     0   0   0   0  ...      0      0          1   \n",
       "12    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "13    0   0   0   0    0    0     0   0   0   0  ...      0      1          0   \n",
       "14    0   0   1   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "15    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "16    0   0   0   0    0    0     0   0   0   0  ...      0      0          1   \n",
       "17    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "18    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "19    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "20    0   1   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "21    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "22    0   0   0   2    0    0     0   0   0   1  ...      0      0          0   \n",
       "23    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "24    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "25    0   0   0   0    0    1     0   0   0   0  ...      0      2          0   \n",
       "26    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "27    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "28    2   0   0   0    0    1     0   0   0   0  ...      0      0          2   \n",
       "29    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "30    0   0   0   0    0    0     0   0   0   0  ...      0      0          2   \n",
       "31    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "32    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "33    0   0   0   0    0    0     1   0   0   0  ...      0      0          0   \n",
       "34    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "35    0   0   0   0    0    0     0   1   0   0  ...      0      1          0   \n",
       "36    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "37    0   0   0   1    0    0     0   1   1   1  ...      0      0          0   \n",
       "38    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "39    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "40    0   0   0   0    0    0     0   0   0   0  ...      0      3          3   \n",
       "41    0   0   0   0    1    0     0   0   0   0  ...      0      0          0   \n",
       "42    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "43    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "44    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "45    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "46    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "47    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "48    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "49    0   0   0   0    0    0     0   0   0   0  ...      0      0          0   \n",
       "\n",
       "    would  wound  wounds  year  years  yet  zeroth  \n",
       "0       2      7       4     0      0    0       0  \n",
       "1       0      0       0     0      0    0       0  \n",
       "2       0      0       0     0      0    0       0  \n",
       "3       0      0       0     0      0    0       0  \n",
       "4       0      0       0     0      0    0       0  \n",
       "5       0      0       0     0      0    0       0  \n",
       "6       0      0       0     0      0    1       0  \n",
       "7       0      0       0     0      0    0       0  \n",
       "8       1      0       0     2      0    0       0  \n",
       "9       0      0       0     0      0    0       0  \n",
       "10      0      0       0     0      0    0       0  \n",
       "11      0      0       0     0      1    0       0  \n",
       "12      0      0       0     0      0    0       0  \n",
       "13      0      0       0     0      0    0       0  \n",
       "14      0      0       0     0      0    0       0  \n",
       "15      0      0       0     0      0    0       0  \n",
       "16      0      0       0     0      0    0       0  \n",
       "17      1      0       0     0      0    0       0  \n",
       "18      0      0       0     0      0    0       0  \n",
       "19      0      0       0     0      0    0       0  \n",
       "20      0      0       0     0      0    0       0  \n",
       "21      0      0       0     0      0    0       0  \n",
       "22      0      0       0     0      0    1       0  \n",
       "23      0      0       0     0      0    0       0  \n",
       "24      0      0       0     0      0    0       0  \n",
       "25      0     10       2     0      0    0       0  \n",
       "26      0      0       0     0      0    0       0  \n",
       "27      2      0       0     0      0    0       0  \n",
       "28      0      0       0     0      0    0       0  \n",
       "29      0      0       0     0      0    0       0  \n",
       "30      0      0       0     0      0    0       0  \n",
       "31      0      0       0     0      0    0       0  \n",
       "32      0      0       0     0      0    0       0  \n",
       "33      0      0       0     0      0    0       0  \n",
       "34      0      0       0     0      0    0       1  \n",
       "35      0      0       0     0      0    0       0  \n",
       "36      0      0       0     0      0    0       0  \n",
       "37      0      0       0     0      0    0       0  \n",
       "38      0      0       0     0      0    0       0  \n",
       "39      0     10       1     0      0    0       0  \n",
       "40      0      0       0     0      1    0       0  \n",
       "41      0      0       0     0      0    0       0  \n",
       "42      0      0       0     0      1    0       0  \n",
       "43      0      0       0     0      0    0       0  \n",
       "44      0      0       0     0      0    0       0  \n",
       "45      0      0       0     0      0    0       0  \n",
       "46      0      0       0     0      0    0       0  \n",
       "47      0      0       0     1      0    0       0  \n",
       "48      0      0       0     0      0    0       0  \n",
       "49      0      0       0     0      0    0       0  \n",
       "\n",
       "[50 rows x 2480 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_count=pd.DataFrame(X_counts.todense(), columns=count_vectorizer.get_feature_names())\n",
    "name_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000    50\n",
       "03     50\n",
       "05     50\n",
       "10     50\n",
       "100    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count words from each description\n",
    "name_count.count().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50x2464 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6120 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vectorize the query\n",
    "query_vector=count_vectorizer.transform(articles['clean_text'])\n",
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.51613043, 0.43960406, 0.57217214, 0.52523005,\n",
       "       0.49820793, 0.37305726, 0.45250644, 0.5285823 , 0.59166091,\n",
       "       0.53063855, 0.48889908, 0.51940127, 0.4938682 , 0.52259309,\n",
       "       0.41029431, 0.35675303, 0.55823709, 0.45878142, 0.41801359,\n",
       "       0.54491464, 0.55689067, 0.48143831, 0.47693994, 0.49577064,\n",
       "       0.54598726, 0.54981683, 0.49200046, 0.4271614 , 0.59936792,\n",
       "       0.44115616, 0.45797978, 0.56115957, 0.44091216, 0.47456162,\n",
       "       0.4608993 , 0.4768654 , 0.50493306, 0.47221379, 0.38281454,\n",
       "       0.373791  , 0.36863724, 0.52159429, 0.45168412, 0.47172138,\n",
       "       0.50631377, 0.52359437, 0.5568999 , 0.48550416, 0.42140516])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_vals=cosine_similarity(query_vector, X_counts)[0]\n",
    "similarity_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 29,  9,  3, 32, 17, 47, 21, 26, 25, 20, 10,  8,  4, 46, 14, 42,\n",
       "       12,  1, 45, 37,  5, 24, 13, 27, 11, 48, 22, 23, 36, 34, 38, 44, 35,\n",
       "       18, 31,  7, 43, 30, 33,  2, 28, 49, 19, 15, 39, 40,  6, 41, 16])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings=np.argsort(similarity_vals)[::-1]\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nabstract \\n      \\n        bacterial colonization ofimplanted biomedical devicesis themain cause of healthcare associated infections  estimated to be 8 8 million per year in europe  many infections originate from damaged skin  which lets microorganisms exploit injuries and surgical accesses as passageways to reach the implant site and inner organs  therefore  an effective treatment of \\n          more\\n\\n\\n        bacterial colonization ofimplanted biomedical devicesis themain cause of healthcare associated infections  estimated to be 8 8 million per year in europe  many infections originate from damaged skin  which lets microorganisms exploit injuries and surgical accesses as passageways to reach the implant site and inner organs  therefore  an effective treatment of skin damage is highly desirable for the success of many biomaterial related surgical procedures  due to gained resistance to antibiotics  new antibacterial treatments are becoming vital to control nosocomial infections arising as surgical and post surgical complications  surface coatings can avoid biofouling and bacterial colonization thanks to biomaterial inherent properties  e g   super hydrophobicity   specifically without using drugs  which may cause bacterial resistance  the focus of this review is to highlight the emerging role of degradable polymeric micro  and nano structures that show intrinsic antifouling and antimicrobial properties  with a special outlook towards biomedical applications dealing with skin and skin damage  the intrinsic properties owned by the biomaterials encompass three main categories   1  physical mechanical   2  chemical  and  3  electrostatic  clinical relevance in ear prostheses and breast implants is reported  collecting and discussing the updated outcomes in this field would help the development of better performing biomaterial based antimicrobial strategies  which are useful to prevent infections \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         of the hiv prevalence in the subset of african countries we chose  these results can help in identification and targeting of high prevalent regions to increase the supply of healthcare services to reduce the spread of the disease and increase the health quality of people living with hiv \\n          more\\n\\n\\n        local estimates of hiv prevalence provide information that can be used to target interventions and consequently increase the efficiency of the resources  this closer to optimal allocation can lead to better health outcomes  including the control of the disease spread  and for more people  producing reliable estimates at smaller geographical levels can be challenging and careful consideration of the nature of the data and the epidemiologic rational is needed  in this paper  we use the dhs data phase v to estimate hiv prevalence at the first subnational level in kenya  tanzania  and mozambique  we fit the data to a spatial random effect intrinsic conditional autoregressive  icar  model to smooth the outcome  we also use a sampling specification from a multistage cluster design  we found that nyanza  p 14 2   and nairobi  p 7 8   in kenya  iringa  p 16 2   and dar es salaam  p 10 1   in tanzania  and gaza  p 13 7   and maputo city  p 12 7   in mozambique are the regions with the highest prevalence of hiv  within country  our results are based on statistically rigorous methods that allowed us to obtain an accurate visual representation of the hiv prevalence in the subset of african countries we chose  these results can help in identification and targeting of high prevalent regions to increase the supply of healthcare services to reduce the spread of the disease and increase the health quality of people living with hiv \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         radiation  along with distance  isolation and hostile environment are expected to increase medical events with unidentified manifestations along the crewmembers  the current healthcare strategy based on telemedicine and the possibility to stabilise and transport the injured crewmember to a terrestrial definitive medical facility is not applicable in explorat \\n          more\\n\\n\\n        space agencies and private companies prepare the beginning of the human space exploration for the 2030s with missions to put the first human on the mars surface  the absence of gravity and radiation  along with distance  isolation and hostile environment are expected to increase medical events with unidentified manifestations along the crewmembers  the current healthcare strategy based on telemedicine and the possibility to stabilise and transport the injured crewmember to a terrestrial definitive medical facility is not applicable in exploration class missions  therefore  full autonomous capability to solve medical situations will guide design of future healthcare systems on board \\n  this study presents ten basic principles and the concept design of medea  an on board clinical decision support system to help crewmembers to deal with medical conditions  with special attention to emergency care situations and critical monitoring  therefore  medea is conceptually designed as a software suite of four interconnected modules  the main of them is responsible to give direct advice to the crew by means of a deep learning multitask neural network to predict the characters of the medical event  a classifier of the tertiary medical intervention and an optimiser of medical action plans  this module is continuously evaluate and re trained with changing physiological data from the crew by an adaptive deep learning module  ensuring fairness  interpretability and traceability of decision making during the full operational time of medea  finally  medea would be semantically interoperable with health information systems on board by a fhir module \\n  the deployment of medea on board of future missions to mars will facilitate the deployment of a comprehensive preventive medical strategy  future quantitative medicine on earth and on the expansion of humans throughout the solar system \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         platform is preferred to be utilized to achieve this goal  due to its ubiquitous sensing ability and seamless connectivity  iot technology is changing our lives through smart healthcare  smart home  and smart city  which aims to build a more convenient and intelligent community  this paper presents how the iot could be incorporated into the epidemic preventi \\n          more\\n\\n\\n        as a result of the worldwide transmission of severe acute respiratory syndrome coronavirus 2  sars cov 2   coronavirus disease 2019  covid 19  has evolved into an unprecedented pandemic  currently  with unavailable pharmaceutical treatments and vaccines  this novel coronavirus results in a great impact on public health  human society  and global economy  which is likely to last for many years  one of the lessons learned from the covid 19 pandemic is that a long term system with non pharmaceutical interventions for preventing and controlling new infectious diseases is desirable to be implemented  internet of things  iot  platform is preferred to be utilized to achieve this goal  due to its ubiquitous sensing ability and seamless connectivity  iot technology is changing our lives through smart healthcare  smart home  and smart city  which aims to build a more convenient and intelligent community  this paper presents how the iot could be incorporated into the epidemic prevention and control system  specifically  we demonstrate a potential fog cloud combined iot platform that can be used in the systematic and intelligent covid 19 prevention and control  which involves five interventions including covid 19 symptom diagnosis  quarantine monitoring  contact tracing    social distancing  covid 19 outbreak forecasting  and sars cov 2 mutation tracking  we investigate and review the state of the art literatures of these five interventions to present the capabilities of iot in countering against the current covid 19 pandemic or future infectious disease epidemics \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        the recent outbreak of sars cov 2 gave us a unique opportunity to study for a non interventional and sustainable ai solution  lung disease remains a major healthcare challenge with high morbidity and mortality worldwide  the predominant lung disease was lung cancer  until recently  the world has witnessed the global pandemic of covid19  the novel coronavirus \\n          more\\n\\n\\n        the recent outbreak of sars cov 2 gave us a unique opportunity to study for a non interventional and sustainable ai solution  lung disease remains a major healthcare challenge with high morbidity and mortality worldwide  the predominant lung disease was lung cancer  until recently  the world has witnessed the global pandemic of covid19  the novel coronavirus outbreak  we have experienced how viral infection of lung and heart claimed thousands of lives worldwide  with the unprecedented advancement of artificial intelligence in recent years  machine learning can be used to easily detect and classify medical imagery  it is much faster and most of the time more accurate than human radiologists  once implemented  it is more cost effective and time saving  in our study  we evaluated the efficacy of microsoft cognitive service to detect and classify covid19 induced pneumonia from other viral bacterial pneumonia based on x ray and ct images  we wanted to assess the implication and accuracy of the automated ml based rapid application development  rad  environment in the field of medical image diagnosis  this study will better equip us to respond with an ml based diagnostic decision support system dss  for a pandemic situation like covid19  after optimization  the trained network achieved 96 8  average precision which was implemented as a web application for consumption  however  the same trained network did not perform the same like web application when ported to smartphone for real time inference  which was our main interest of study  the authors believe  there is scope for further study on this issue  one of the main goal of this study was to develop and evaluate the performance of ai powered smartphone based real time application  facilitating primary diagnostic services in less equipped and understaffed rural healthcare centers of the world with unreliable internet service \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        acute and chronic wounds have varying etiologies and are an economic burden to healthcare systems around the world  the advanced wound care market is expected to exceed  22 billion by 2024  wound care professionals rely heavily on images and image documentation for proper diagnosis and treatment  unfortunately lack of expertise can lead to improper diagnosis \\n          more\\n\\n\\n        acute and chronic wounds have varying etiologies and are an economic burden to healthcare systems around the world  the advanced wound care market is expected to exceed  22 billion by 2024  wound care professionals rely heavily on images and image documentation for proper diagnosis and treatment  unfortunately lack of expertise can lead to improper diagnosis of wound etiology and inaccurate wound management and documentation  fully automatic segmentation of wound areas in natural images is an important part of the diagnosis and care protocol since it is crucial to measure the area of the wound and provide quantitative parameters in the treatment  various deep learning models have gained success in image analysis including semantic segmentation  particularly  mobilenetv2 stands out among others due to its lightweight architecture and uncompromised performance  this manuscript proposes a novel convolutional framework based on mobilenetv2 and connected component labelling to segment wound regions from natural images  we build an annotated wound image dataset consisting of 1 109 foot ulcer images from 889 patients to train and test the deep learning models  we demonstrate the effectiveness and mobility of our method by conducting comprehensive experiments and analyses on various segmentation neural networks \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        the transparent and decentralized characteristics associated with blockchain can be both appealing and problematic when applied to a healthcare use case  as health data is highly sensitive  it is also highly regulated to ensure the privacy of patients  at the same time  access to health data and interoperability is in high demand  regulatory frameworks such \\n          more\\n\\n\\n        the transparent and decentralized characteristics associated with blockchain can be both appealing and problematic when applied to a healthcare use case  as health data is highly sensitive  it is also highly regulated to ensure the privacy of patients  at the same time  access to health data and interoperability is in high demand  regulatory frameworks such as gdpr and hipaa are  amongst other objectives  meant to contribute to mitigating the risk of privacy violations in health data  blockchain features can likely improve interoperability and access control to health data  and at the same time  preserve or even increase  the privacy of patients  blockchain applications should address compliance with the current regulatory framework to increase real world feasibility  this exploratory work indicates that published proof of concepts in the health domain comply with gdrp  to an extent  blockchain developers need to make design choices to be compliant with gdpr since currently  none available blockchain platform can show compliance out of the box \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         patterns vary across narrative time and differ under expressions of anger  fear and sadness  potential applications of codyms range from assessment and training of effective healthcare communication to comparing conversational dynamics across language and culture  with the prospect of identifying universal similarities and unique  fingerprints  of in \\n          more\\n\\n\\n        conversation has been a primary means for the exchange of information since ancient times  understanding patterns of information flow in conversations is a critical step in assessing and improving communication quality  in this paper  we describe conversational dynamics model  codym  analysis  a novel approach for studying patterns of information flow in conversations  codyms are markov models that capture sequential dependencies in the lengths of speaker turns  the proposed method is automated and scalable  and preserves the privacy of the conversational participants  the primary function of codym analysis is to quantify and visualize patterns of information flow  concisely summarized over sequential turns from one or more conversations  our approach is general and complements existing methods  providing a new tool for use in the analysis of any type of conversation  as an important first application  we demonstrate the model on transcribed conversations between palliative care clinicians and seriously ill patients  these conversations are dynamic and complex  taking place amidst heavy emotions  and include difficult topics such as end of life preferences and patient values  we perform a versatile set of codym analyses that  a  establish the validity of the model by confirming known patterns of conversational turn taking and word usage   b  identify normative patterns of information flow in serious illness conversations  and  c  show how these patterns vary across narrative time and differ under expressions of anger  fear and sadness  potential applications of codyms range from assessment and training of effective healthcare communication to comparing conversational dynamics across language and culture  with the prospect of identifying universal similarities and unique  fingerprints  of information flow \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        the increasing availability of healthcare data requires accurate analysis of disease diagnosis  progression  and realtime monitoring to provide improved treatments to the patients  in this context  machine learning  ml  models are used to extract valuable features and insights from high dimensional and heterogeneous \\n          more\\n\\n\\n        the increasing availability of healthcare data requires accurate analysis of disease diagnosis  progression  and realtime monitoring to provide improved treatments to the patients  in this context  machine learning  ml  models are used to extract valuable features and insights from high dimensional and heterogeneous healthcare data to detect different diseases and patient activities in a smart healthcare system  shs   however  recent researches show that ml models used in different application domains are vulnerable to adversarial attacks  in this paper  we introduce a new type of adversarial attacks to exploit the ml classifiers used in a shs  we consider an adversary who has partial knowledge of data distribution  shs model  and ml algorithm to perform both targeted and untargeted attacks  employing these adversarial capabilities  we manipulate medical device readings to alter patient status  disease affected  normal condition  activities  etc   in the outcome of the shs  our attack utilizes five different adversarial ml algorithms  hopskipjump  fast gradient method  crafting decision tree  carlini   wagner  zeroth order optimization  to perform different malicious activities  e g   data poisoning  misclassify outputs  etc   on a shs  moreover  based on the training and testing phase capabilities of an adversary  we perform white box and black box attacks on a shs  we evaluate the performance of our work in different shs settings and medical devices  our extensive evaluation shows that our proposed adversarial attack can significantly degrade the performance of a ml based shs in detecting diseases and normal activities of the patients correctly  which eventually leads to erroneous treatment \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        pervasive healthcare is a promising assisted living solution for chronic patients  however  current cutting edge communication technologies are not able to strictly meet the requirements of these applications  especially in the case of life threatening events  to bridge this gap  this paper proposes a new architecture to support indoor \\n          more\\n\\n\\n        pervasive healthcare is a promising assisted living solution for chronic patients  however  current cutting edge communication technologies are not able to strictly meet the requirements of these applications  especially in the case of life threatening events  to bridge this gap  this paper proposes a new architecture to support indoor healthcare monitoring  with a focus on epileptic patients  several novel elements are introduced  the first element is the cascading of a wlan and a cellular network  where ieee 802 11ax is used for the wireless local area network to collect physiological and environmental data in home and 5g enabled fixed wireless access links transfer them to a remote hospital  the second element is the extension of the network slicing concept to the wlan  and the introduction of two new slice types to support both regular monitoring and emergency handling  moreover  the inclusion of local computing capabilities at the wlan router  together with a mobile edge computing resource  represents a further architectural enhancement  local computation is required to trigger not only health related alarms  but also the network slicing change in case of emergency  in fact  proper radio resource scheduling is necessary for the cascaded networks to handle healthcare traffic together with other promiscuous everyday communication services  numerical results demonstrate the effectiveness of the proposed approach while highlighting the performance gain achieved with respect to baseline solutions \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         disease caused by this virus  covid 19  in the us alone  there have been approximately 7 million cases and over 200 000 deaths  this outbreak has placed an enormous strain on healthcare systems and workers  severe cases require hospital care  and 8 5   of patients require mechanical ventilation in an intensive care unit  icu   one major challenge is the nece \\n          more\\n\\n\\n        since the first reports of a novel coronavirus  sars cov 2  in december 2019  over 33 million people have been infected worldwide and approximately 1 million people worldwide have died from the disease caused by this virus  covid 19  in the us alone  there have been approximately 7 million cases and over 200 000 deaths  this outbreak has placed an enormous strain on healthcare systems and workers  severe cases require hospital care  and 8 5   of patients require mechanical ventilation in an intensive care unit  icu   one major challenge is the necessity for clinical care personnel to don and doff cumbersome personal protective equipment  ppe  in order to enter an icu unit to make simple adjustments to ventilator settings  although future ventilators and other icu equipment may be controllable remotely through computer networks  the enormous installed base of existing ventilators do not have this capability  this paper reports the development of a simple  low cost telerobotic system that permits adjustment of ventilator settings from outside the icu  the system consists of a small cartesian robot capable of operating a ventilator touch screen with camera vision control via a wirelessly connected tablet master device located outside the room  engineering system tests demonstrated that the open loop mechanical repeatability of the device was 7 5  mm  and that the average positioning error of the robotic finger under visual servoing control was 5 94  mm  successful usability tests in a simulated icu environment were carried out and are reported  in addition to enabling a significant reduction in ppe consumption  the prototype system has been shown in a preliminary evaluation to significantly reduce the total time required for a respiratory therapist to perform typical setting adjustments on a commercial ventilator  including donning and doffing ppe  from 271 seconds to 109 seconds \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         to specific areas  these systems have become an indispensable element within any hospital  the goal of our study is to discover how the erp has been used in moroccan healthcare sector and how these software should be implemented and used to improve healthcare services \\n          more\\n\\n\\n        the hospital information systems  his  in morocco take a central place in the process of patient care  an approach is made to analyze the current situation of the his within the institutions in order to bring an integral and generic vision  allowing the judicious articulation of the business and it layers  currently  the enterprise resource planning  erp  implemented remains a system consisting of several applications dedicated to specific areas  these systems have become an indispensable element within any hospital  the goal of our study is to discover how the erp has been used in moroccan healthcare sector and how these software should be implemented and used to improve healthcare services \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         and millions of people  the virus is deadly  and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality  medicine and healthcare industries have surged towards finding a cure  and different policies have been amended to mitigate the spread of the virus  while machine learning  ml  methods have been wid \\n          more\\n\\n\\n        covid 19 was first discovered in december 2019 and has continued to rapidly spread across countries worldwide infecting thousands and millions of people  the virus is deadly  and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality  medicine and healthcare industries have surged towards finding a cure  and different policies have been amended to mitigate the spread of the virus  while machine learning  ml  methods have been widely used in other domains  there is now a high demand for ml aided diagnosis systems for screening  tracking  and predicting the spread of covid 19 and finding a cure against it  in this paper  we present a journey of what role ml has played so far in combating the virus  mainly looking at it from a screening  forecasting  and vaccine perspectives  we present a comprehensive survey of the ml algorithms and models that can be used on this expedition and aid with battling the virus \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         its unresolved dying relu problem  which poses challenges to reliable applications  this issue has obvious important implications for critical applications  such as those in healthcare  recent approaches are just proposing variations of the activation function within the same unresolved dying relu challenge  this contribution reports a different research dir \\n          more\\n\\n\\n        the relu activation function  af  has been extensively applied in deep neural networks  in particular convolutional neural networks  cnn   for image classification despite its unresolved dying relu problem  which poses challenges to reliable applications  this issue has obvious important implications for critical applications  such as those in healthcare  recent approaches are just proposing variations of the activation function within the same unresolved dying relu challenge  this contribution reports a different research direction by investigating the development of an innovative quantum approach to the relu af that avoids the dying relu problem by disruptive design  the leaky relu was leveraged as a baseline on which the two quantum principles of entanglement and superposition were applied to derive the proposed quantum relu  qrelu  and the modified qrelu  m qrelu  activation functions  both qrelu and m qrelu are implemented and made freely available in tensorflow and keras  this original approach is effective and validated extensively in case studies that facilitate the detection of covid 19 and parkinson disease  pd  from medical images  the two novel afs were evaluated in a two layered cnn against nine relu based afs on seven benchmark datasets  including images of spiral drawings taken via graphic tablets from patients with parkinson disease and healthy subjects  and point of care ultrasound images on the lungs of patients with covid 19  those with pneumonia and healthy controls  despite a higher computational cost  results indicated an overall higher classification accuracy  precision  recall and f1 score brought about by either quantum afs on five of the seven bench mark datasets  thus demonstrating its potential to be the new benchmark or gold standard af in cnns and aid image classification tasks involved in critical applications  such as medical diagnoses of covid 19 and pd \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        electronic health records  ehrs  are longitudinal records of a patient s interactions with healthcare systems  a patient s ehr data is organized as a three level hierarchy from top to bottom  patient journey   all the experiences of diagnoses and treatments over a period of time  individual visit   a set of medical codes in a particular visit  and me \\n          more\\n\\n\\n        electronic health records  ehrs  are longitudinal records of a patient s interactions with healthcare systems  a patient s ehr data is organized as a three level hierarchy from top to bottom  patient journey   all the experiences of diagnoses and treatments over a period of time  individual visit   a set of medical codes in a particular visit  and medical code   a specific record in the form of medical codes  as ehrs begin to amass in millions  the potential benefits  which these data might hold for medical research and medical outcome prediction  are staggering   including  for example  predicting future admissions to hospitals  diagnosing illnesses or determining the efficacy of medical treatments  each of these analytics tasks requires a domain knowledge extraction method to transform the hierarchical patient journey into a vector representation for further prediction procedure  the representations should embed a sequence of visits and a set of medical codes with a specific timestamp  which are crucial to any downstream prediction tasks  hence  expressively powerful representations are appealing to boost learning performance  to this end  we propose a novel self attention mechanism that captures the contextual dependency and temporal relationships within a patient s healthcare journey  an end to end bidirectional temporal encoder network  bitenet  then learns representations of the patient s journeys  based solely on the proposed attention mechanism  we have evaluated the effectiveness of our methods on two supervised prediction and two unsupervised clustering tasks with a real world ehr dataset  the empirical results demonstrate the proposed bitenet model produces higher quality representations than state of the art baseline methods \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         mind on previously held opinions  10  gave more importance to the psychological aspects of medical conditions  and 27  were more favourable to the use of social media data in healthcare  suggesting the importance of persuasive elements in interactive visualizations \\n          more\\n\\n\\n        a biological understanding is key for managing medical conditions  yet psychological and social aspects matter too  the main problem is that these two aspects are hard to quantify and inherently difficult to communicate  to quantify psychological aspects  this work mined around half a million reddit posts in the sub communities specialised in 14 medical conditions  and it did so with a new deep learning framework  in so doing  it was able to associate mentions of medical conditions with those of emotions  to then quantify social aspects  this work designed a probabilistic approach that mines open prescription data from the national health service in england to compute the prevalence of drug prescriptions  and to relate such a prevalence to census data  to finally visually communicate each medical condition s biological  psychological  and social aspects through storytelling  we designed a narrative style layered martini glass visualization  in a user study involving 52 participants  after interacting with our visualization  a considerable number of them changed their mind on previously held opinions  10  gave more importance to the psychological aspects of medical conditions  and 27  were more favourable to the use of social media data in healthcare  suggesting the importance of persuasive elements in interactive visualizations \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        unhealthy behaviors  e g   physical inactivity and unhealthful food choice  are the primary healthcare cost drivers in developed countries  pervasive computational  sensing  and communication technology provided by smartphones and smartwatches have made it possible to support individuals in their everyday lives to develop healthier lifestyles  in this paper  \\n          more\\n\\n\\n        unhealthy behaviors  e g   physical inactivity and unhealthful food choice  are the primary healthcare cost drivers in developed countries  pervasive computational  sensing  and communication technology provided by smartphones and smartwatches have made it possible to support individuals in their everyday lives to develop healthier lifestyles  in this paper  we propose an exercise recommendation system that also predicts individual success rates   the system  consisting of two inter connected recurrent neural networks  rnns   uses the history of workouts to recommend the next workout activity for each individual  the system then predicts the probability of successful completion of the predicted activity by the individual  the prediction accuracy of this interconnected rnn model is assessed on previously published data from a four week mobile health experiment and is shown to improve upon previous predictions from a computational cognitive model \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        aim  one of the aims of the observation health data sciences and informatics  ohdsi  initiative is population level treatment effect estimation in large observational databases  since treatment effects are well known to vary across groups of patients with different baseline risk  we aimed to extend the ohdsi methods library with a framework for risk based assessment of treatment effect heterogenei \\n          more\\n\\n\\n        aim  one of the aims of the observation health data sciences and informatics  ohdsi  initiative is population level treatment effect estimation in large observational databases  since treatment effects are well known to vary across groups of patients with different baseline risk  we aimed to extend the ohdsi methods library with a framework for risk based assessment of treatment effect heterogeneity \\n  materials and methods  the proposed framework consists of five steps  1  definition of the problem  i e  the population  the treatment  the comparator and the outcome s  of interest  2  identification of relevant databases  3  development of a prediction model for the outcome s  of interest  4  estimation of propensity scores within strata of predicted risk and estimation of relative and absolute treatment effect within strata of predicted risk  5  evaluation and presentation of results \\n  results  we demonstrate our framework by evaluating heterogeneity of the effect of angiotensin converting enzyme  ace  inhibitors versus beta blockers on a set of 9 outcomes of interest across three observational databases  with increasing risk of acute myocardial infarction we observed increasing absolute benefits  i e  from  0 03  to 0 54  in the lowest to highest risk groups  cough related absolute harms decreased from 4 1  to 2 6  \\n  conclusions  the proposed framework may be useful for the evaluation of heterogeneity of treatment effect on observational data that are mapped to the omop common data model  the proof of concept study demonstrates its feasibility in large observational data  further insights may arise by application to safety and effectiveness questions across the global data network \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         is a crucial capability for autonomous systems to operate reliably in uncertain and dynamic environments  the concern of patient safety becomes even more critical in healthcare settings where robots interact with humans  in this paper  we propose a novel risk aware planning framework to minimize the risk of patient falls by providing a patient with an assist \\n          more\\n\\n\\n        planning under uncertainty is a crucial capability for autonomous systems to operate reliably in uncertain and dynamic environments  the concern of patient safety becomes even more critical in healthcare settings where robots interact with humans  in this paper  we propose a novel risk aware planning framework to minimize the risk of patient falls by providing a patient with an assistive device  our approach combines learning based prediction with model based control to plan for the fall prevention tasks  this provides advantages compared to end to end learning methods in which the robot s performance is limited to specific scenarios  or purely model based approaches that use relatively simple function approximators and are prone to high modeling errors  we compare two different risk metrics and the combination of them and report the results from various simulated scenarios  the results show that using the proposed cost function  the robot can plan interventions to avoid high fall score events \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         benefit from such computational methods  however  surgeons and computer scientists should partner to develop and assess deep learning applications of value to patients and healthcare systems  this chapter and the accompanying hands on material were designed for surgeons willing to understand the intuitions behind neural networks  become familiar with deep le \\n          more\\n\\n\\n        deep neural networks power most recent successes of artificial intelligence  spanning from self driving cars to computer aided diagnosis in radiology and pathology  the high stake data intensive process of surgery could highly benefit from such computational methods  however  surgeons and computer scientists should partner to develop and assess deep learning applications of value to patients and healthcare systems  this chapter and the accompanying hands on material were designed for surgeons willing to understand the intuitions behind neural networks  become familiar with deep learning concepts and tasks  grasp what implementing a deep learning model in surgery means  and finally appreciate the specific challenges and limitations of deep neural networks in surgery  for the associated hands on material  please see https   github com camma public ai4surgery \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        reliability in neural networks  nns  is crucial in safety critical applications like healthcare  and uncertainty estimation is a widely researched method to highlight the confidence of nns in deployment  in this work  we propose an uncertainty aware boosting technique for multi modal ensembling to predict alzheimer s dementia severity  the propagation of \\n          more\\n\\n\\n        reliability in neural networks  nns  is crucial in safety critical applications like healthcare  and uncertainty estimation is a widely researched method to highlight the confidence of nns in deployment  in this work  we propose an uncertainty aware boosting technique for multi modal ensembling to predict alzheimer s dementia severity  the propagation of uncertainty across acoustic  cognitive  and linguistic features produces an ensemble system robust to heteroscedasticity in the data  weighing the different modalities based on the uncertainty estimates  we experiment on the benchmark adress dataset  a subject independent and balanced dataset  to show that our method outperforms the state of the art methods while also reducing the overall entropy of the system  this work aims to encourage fair and aware models  the source code is available at https   github com wazeerzulfikar alzheimers dementia\\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        causal inference  or counterfactual prediction  is central to decision making in healthcare  policy and social sciences  to de bias causal estimators with high dimensional data in observational studies  recent advances suggest the importance of combining machine learning models for both the propensity score and the outcome function  we propose a novel scalab \\n          more\\n\\n\\n        causal inference  or counterfactual prediction  is central to decision making in healthcare  policy and social sciences  to de bias causal estimators with high dimensional data in observational studies  recent advances suggest the importance of combining machine learning models for both the propensity score and the outcome function  we propose a novel scalable method to learn double robust representations for counterfactual predictions  leading to consistent causal estimation if the model for either the propensity score or the outcome  but not necessarily both  is correctly specified  specifically  we use the entropy balancing method to learn the weights that minimize the jensen shannon divergence of the representation between the treated and control groups  based on which we make robust and efficient counterfactual predictions for both individual and average treatment effects  we provide theoretical justifications for the proposed method  the algorithm shows competitive performance with the state of the art on real world and synthetic data \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        ai and machine learning can offer powerful tools to help in the fight against covid 19  in this paper we present a study and a concrete tool based on machine learning to predict the prognosis of hospitalised patients with covid 19  in particular we address the task of predicting the risk of death of a patient at different times of the hospitalisation  on the base of some demographic information  c \\n          more\\n\\n\\n        ai and machine learning can offer powerful tools to help in the fight against covid 19  in this paper we present a study and a concrete tool based on machine learning to predict the prognosis of hospitalised patients with covid 19  in particular we address the task of predicting the risk of death of a patient at different times of the hospitalisation  on the base of some demographic information  chest x ray scores and several laboratory findings  our machine learning models use ensembles of decision trees trained and tested using data from more than 2000 patients  an experimental evaluation of the models shows good performance in solving the addressed task \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        covid 19 spread across the globe at an immense rate has left healthcare systems incapacitated to diagnose and test patients at the needed rate  studies have shown promising results for detection of covid 19 from viral bacterial pneumonia in chest x rays  automation of covid 19 testing using medical images can speed up the testing process of patients where he \\n          more\\n\\n\\n        covid 19 spread across the globe at an immense rate has left healthcare systems incapacitated to diagnose and test patients at the needed rate  studies have shown promising results for detection of covid 19 from viral bacterial pneumonia in chest x rays  automation of covid 19 testing using medical images can speed up the testing process of patients where health care systems lack sufficient numbers of the reverse transcription polymerase chain reaction  rt pcr  tests  supervised deep learning models such as convolutional neural networks  cnn  need enough labeled data for all classes to correctly learn the task of detection  gathering labeled data is a cumbersome task and requires time and resources which could further strain health care systems and radiologists at the early stages of a pandemic such as covid 19  in this study  we propose a randomized generative adversarial network  randgan  that detects images of an unknown class  covid 19  from known and labelled classes  normal and viral pneumonia  without the need for labels and training data from the unknown class of images  covid 19   we used the largest publicly available covid 19 chest x ray dataset  covidx  which is comprised of normal  pneumonia  and covid 19 images from multiple public databases  in this work  we use transfer learning to segment the lungs in the covidx dataset  next  we show why segmentation of the region of interest  lungs  is vital to correctly learn the task of classification  specifically in datasets that contain images from different resources as it is the case for the covidx dataset  finally  we show improved results in detection of covid 19 cases using our generative model  randgan  compared to conventional generative adversarial networks  gans  for anomaly detection in medical images  improving the area under the roc curve from 0 71 to 0 77 \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         infant prints can deliver accurate and reliable recognition  over time  of infants enrolled between the ages of 2 3 months  in time for effective delivery of vaccinations  healthcare  and nutritional supplements  tar 95 2    far   1 0  for infants aged 8 16 weeks at enrollment and authenticated 3 months later  \\n          more\\n\\n\\n        in many of the least developed and developing countries  a multitude of infants continue to suffer and die from vaccine preventable diseases and malnutrition  lamentably  the lack of official identification documentation makes it exceedingly difficult to track which infants have been vaccinated and which infants have received nutritional supplements  answering these questions could prevent this infant suffering and premature death around the world  to that end  we propose infant prints  an end to end  low cost  infant fingerprint recognition system  infant prints is comprised of our  i  custom built  compact  low cost  85 usd   high resolution  1 900 ppi   ergonomic fingerprint reader  and  ii  high resolution infant fingerprint matcher  to evaluate the efficacy of infant prints  we collected a longitudinal infant fingerprint database captured in 4 different sessions over a 12 month time span  december 2018 to january 2020   from 315 infants at the saran ashram hospital  a charitable hospital in dayalbagh  agra  india  our experimental results demonstrate  for the first time  that infant prints can deliver accurate and reliable recognition  over time  of infants enrolled between the ages of 2 3 months  in time for effective delivery of vaccinations  healthcare  and nutritional supplements  tar 95 2    far   1 0  for infants aged 8 16 weeks at enrollment and authenticated 3 months later  \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\nhealthcare programs such as medicaid provide crucial services to vulnerable populations  but due to limited resources  many of the individuals who need these services the most languish on waiting lists  survival models  e g  the cox proportional hazards model  can potentially improve this situation by predicting individuals  levels of need  which can the \\n          more\\n\\n\\nhealthcare programs such as medicaid provide crucial services to vulnerable populations  but due to limited resources  many of the individuals who need these services the most languish on waiting lists  survival models  e g  the cox proportional hazards model  can potentially improve this situation by predicting individuals  levels of need  which can then be used to prioritize the waiting lists  providing care to those in need can prevent institutionalization for those individuals  which both improves quality of life and reduces overall costs  while the benefits of such an approach are clear  care must be taken to ensure that the prioritization process is fair or independent of demographic information based harmful stereotypes  in this work  we develop multiple fairness definitions for survival models and corresponding fair cox proportional hazards models to ensure equitable allocation of healthcare resources  we demonstrate the utility of our methods in terms of fairness and predictive accuracy on two publicly available survival datasets \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        the internet of things  iot  envisions the integration of physical objects into software systems for automating crucial aspects of our lives  such as healthcare  security  agriculture  and city management  although the vision is promising  with the rapid advancement of hardware and communication technologies  iot systems are becoming increasingly dynamic  la \\n          more\\n\\n\\n        the internet of things  iot  envisions the integration of physical objects into software systems for automating crucial aspects of our lives  such as healthcare  security  agriculture  and city management  although the vision is promising  with the rapid advancement of hardware and communication technologies  iot systems are becoming increasingly dynamic  large  and complex to the extent that manual management becomes infeasible  thus  it is of paramount importance to provide software engineering foundations for constructing autonomic iot systems  in this paper  i introduce a novel paradigm referred to as self organizing software models in which iot software systems are not explicitly programmed  but emerge in a decentralized manner during system operation  with minimal or without human intervention  i particularly present an overview of those models by including their definition  motivation  research challenges  and potential directions \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         to show that there is no universal method available that can accurately forecast pandemic data  still  forecasters  predictions are useful for the effective allocation of healthcare resources and will act as an early warning system for government policymakers \\n          more\\n\\n\\n        the coronavirus disease 2019  covid 19  has become a public health emergency of international concern affecting more than 200 countries and territories worldwide  as of september 30  2020  it has caused a pandemic outbreak with more than 33 million confirmed infections and more than 1 million reported deaths worldwide  several statistical  machine learning  and hybrid models have previously tried to forecast covid 19 confirmed cases for profoundly affected countries  due to extreme uncertainty and nonstationarity in the time series data  forecasting of covid 19 confirmed cases has become a very challenging job  for univariate time series forecasting  there are various statistical and machine learning models available in the literature  but  epidemic forecasting has a dubious track record  its failures became more prominent due to insufficient data input  flaws in modeling assumptions  high sensitivity of estimates  lack of incorporation of epidemiological features  inadequate past evidence on effects of available interventions  lack of transparency  errors  lack of determinacy  and lack of expertise in crucial disciplines  this chapter focuses on assessing different short term forecasting models that can forecast the daily covid 19 cases for various countries  in the form of an empirical study on forecasting accuracy  this chapter provides evidence to show that there is no universal method available that can accurately forecast pandemic data  still  forecasters  predictions are useful for the effective allocation of healthcare resources and will act as an early warning system for government policymakers \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         and social actions for interacting with humans  the robot will operate in a task environment where appropriate and safe interaction with children  parents caregivers  and healthcare professionals is required  in addition to addressing the core technical challenge of building an autonomous social robot  the project will incorporate co design techniques invol \\n          more\\n\\n\\n        this paper describes a new research project that aims to develop a social robot designed to help children cope with painful and distressing medical procedures in a clinical setting  while robots have previously been trialled for this task  with promising initial results  the systems have tended to be teleoperated  limiting their flexibility and robustness  this project will use epistemic planning techniques as a core component for action selection in the robot system  in order to generate plans that include physical  sensory  and social actions for interacting with humans  the robot will operate in a task environment where appropriate and safe interaction with children  parents caregivers  and healthcare professionals is required  in addition to addressing the core technical challenge of building an autonomous social robot  the project will incorporate co design techniques involving all participant groups  and the final robot system will be evaluated in a two site clinical trial \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n          ai  systems since their conception  with the need for explainability growing as more complex ai models are increasingly used in critical  high stakes settings such as healthcare  explanations have often added to an ai system in a non principled  post hoc manner  with greater adoption of these systems and emphasis on user centric explainability  there is a n \\n          more\\n\\n\\n        explainability has been a goal for artificial intelligence  ai  systems since their conception  with the need for explainability growing as more complex ai models are increasingly used in critical  high stakes settings such as healthcare  explanations have often added to an ai system in a non principled  post hoc manner  with greater adoption of these systems and emphasis on user centric explainability  there is a need for a structured representation that treats explainability as a primary consideration  mapping end user needs to specific explanation types and the system s ai capabilities  we design an explanation ontology to model both the role of explanations  accounting for the system and user attributes in the process  and the range of different literature derived explanation types  we indicate how the ontology can support user requirements for explanations in the domain of healthcare  we evaluate our ontology with a set of competency questions geared towards a system designer who might use our ontology to decide which explanation types to include  given a combination of users  needs and a system s capabilities  both in system design settings and in real time operations  through the use of this ontology  system designers will be able to make informed choices on which explanations ai systems can and should provide \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        efficient design of biological sequences will have a great impact across many industrial and healthcare domains  however  discovering improved sequences requires solving a difficult optimization problem  traditionally  this challenge was approached by biologists through a model free method known as  directed evolution   the iterative process of rando \\n          more\\n\\n\\n        efficient design of biological sequences will have a great impact across many industrial and healthcare domains  however  discovering improved sequences requires solving a difficult optimization problem  traditionally  this challenge was approached by biologists through a model free method known as  directed evolution   the iterative process of random mutation and selection  as the ability to build models that capture the sequence to function map improves  such models can be used as oracles to screen sequences before running experiments  in recent years  interest in better algorithms that effectively use such oracles to outperform model free approaches has intensified  these span from approaches based on bayesian optimization  to regularized generative models and adaptations of reinforcement learning  in this work  we implement an open source fitness landscape exploration sandbox  flexs  github com samsinai flexs  environment to test and evaluate these algorithms based on their optimality  consistency  and robustness  using flexs  we develop an easy to implement  scalable  and robust evolutionary greedy algorithm  adalead   despite its simplicity  we show that adalead is a remarkably strong benchmark that out competes more complex state of the art approaches in a variety of biologically motivated sequence design challenges \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         vendor locked environments  although blockchain has commonly been used as the operational model behind cryptocurrency  it has far more foreseeable utilities in domains like healthcare  where efficient data flow is highly demanded  particularly  blockchain and related technologies have been touted as foundational technologies for addressing \\n          more\\n\\n\\n        known for its decentralized and tamper aware properties  blockchain is attractive to enhance the infrastructure of systems that have been constrained by traditionally centralized and vendor locked environments  although blockchain has commonly been used as the operational model behind cryptocurrency  it has far more foreseeable utilities in domains like healthcare  where efficient data flow is highly demanded  particularly  blockchain and related technologies have been touted as foundational technologies for addressing healthcare interoperability challenges  such as promoting effective communications and securing data exchanges across various healthcare systems  despite the increasing interests in leveraging blockchain technology to improve healthcare infrastructures  a major gap in literature is the lack of available recommendations for concrete architectural styles and design considerations for creating blockchain based apps and systems with a healthcare focus  this research provides two contributions to bridge the gap in existing research  first  we introduce a pattern sequence for designing blockchain based healthcare systems focused on secure and at scale data exchange  our approach adapts traditional software patterns and proposes novel patterns that take into account both the technical requirements specific to healthcare systems and the implications of these requirements on naive blockchain based solutions  second  we provide a pattern oriented reference architecture using an example application of the pattern sequence for guiding software developers to design interoperable  on the technical level  healthcare it systems atop blockchain based infrastructures  the reference architecture focuses on minimizing storage requirements on chain  preserving the privacy of sensitive information  facilitating scalable communications  and maximizing evolvability of the system \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         susceptible individuals  thus making infection outbreaks both common and challenging  in recent years  there has been a sharp incidence of antimicrobial resistance amongst healthcare associated infections  a situation now considered endemic in many countries  here we present network based analyses of a data set capturing the movement of patients harbouring d \\n          more\\n\\n\\n        hospitals constitute highly interconnected systems that bring into contact an abundance of infectious pathogens and susceptible individuals  thus making infection outbreaks both common and challenging  in recent years  there has been a sharp incidence of antimicrobial resistance amongst healthcare associated infections  a situation now considered endemic in many countries  here we present network based analyses of a data set capturing the movement of patients harbouring drug resistant bacteria across three large london hospitals  we show that there are substantial memory effects in the movement of hospital patients colonised with drug resistant bacteria  such memory effects break first order markovian transitive assumptions and substantially alter the conclusions from the analysis  specifically on node rankings and the evolution of diffusive processes  we capture variable length memory effects by constructing a lumped state memory network  which we then use to identify overlapping communities of wards  we find that these communities of wards display a quasi hierarchical structure at different levels of granularity which is consistent with different aspects of patient flows related to hospital locations and medical specialties \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         language processing  and speech recognition  however  the decision making processes of these models are generally not interpretable to users  in various domains  such as healthcare  finance  or law  it is critical to know the reasons behind a decision made by an artificial intelligence system  therefore  several directions for explaining neural models have r \\n          more\\n\\n\\n        deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas  such as computer vision  natural language processing  and speech recognition  however  the decision making processes of these models are generally not interpretable to users  in various domains  such as healthcare  finance  or law  it is critical to know the reasons behind a decision made by an artificial intelligence system  therefore  several directions for explaining neural models have recently been explored \\n  in this thesis  i investigate two major directions for explaining deep neural networks  the first direction consists of feature based post hoc explanatory methods  that is  methods that aim to explain an already trained and fixed model  post hoc   and that provide explanations in terms of input features  such as tokens for text and superpixels for images  feature based   the second direction consists of self explanatory neural models that generate natural language explanations  that is  models that have a built in module that generates explanations for the predictions of the model \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        at the heart of causal structure learning from observational data lies a deceivingly simple question  given two statistically dependent random variables  which one has a causal effect on the other  this is impossible to answer using statistical dependence testing alone and requires that we make additional assumptions  we propose several fast and simple criteria for distinguishing cause and effect \\n          more\\n\\n\\n        at the heart of causal structure learning from observational data lies a deceivingly simple question  given two statistically dependent random variables  which one has a causal effect on the other  this is impossible to answer using statistical dependence testing alone and requires that we make additional assumptions  we propose several fast and simple criteria for distinguishing cause and effect in pairs of discrete or continuous random variables  the intuition behind them is that predicting the effect variable using the cause variable should be  simpler  than the reverse    different notions of  simplicity  giving rise to different criteria  we demonstrate the accuracy of the criteria on synthetic data generated under a broad family of causal mechanisms and types of noise \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        the affordable care act of 2010 had introduced readmission reduction program in 2012 to reduce avoidable re admissions to control rising healthcare costs  wound care impacts 15 of medicare beneficiaries making it one of the major contributors of medicare health care cost  health plans have been exploring proactive health care services that can focus on preve \\n          more\\n\\n\\n        the affordable care act of 2010 had introduced readmission reduction program in 2012 to reduce avoidable re admissions to control rising healthcare costs  wound care impacts 15 of medicare beneficiaries making it one of the major contributors of medicare health care cost  health plans have been exploring proactive health care services that can focus on preventing wound recurrences and re admissions to control the wound care costs  with rising costs of wound care industry  it has become of paramount importance to reduce wound recurrences   patient re admissions  what factors are responsible for a wound to recur which ultimately lead to hospitalization or re admission  is there a way to identify the patients at risk of re admission before the occurrence using data driven analysis  patient re admission risk management has become critical for patients suffering from chronic wounds such as diabetic ulcers  pressure ulcers  and vascular ulcers  understanding the risk   the factors that cause patient readmission can help care providers and patients avoid wound recurrences  our work focuses on identifying patients who are at high risk of re admission   determining the time period with in which a patient might get re admitted  frequent re admissions add financial stress to the patient   health plan and deteriorate the quality of life of the patient  having this information can allow a provider to set up preventive measures that can delay  if not prevent  patients  re admission  on a combined wound   episode level data set of patient s wound care information  our extended autoprognosis achieves a recall of 92 and a precision of 92 for the predicting a patient s re admission risk  for new patient class  precision and recall are as high as 91 and 98  respectively  we are also able to predict the patient s discharge event for a re admission event to occur through our model with a mae of 2 3 weeks \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         group key establishment and proof of location  fields of application include secure car to car communication  privacy preserving and secure distance evidence for healthcare or location based feature activation  existing technologies do not solve the problem satisfactorily  due to communication restrictions  e g   ultra wide band  uwb  based time of flight me \\n          more\\n\\n\\n        in this paper  we investigate physical layer security  pls  methods for proximity based group key establishment and proof of location  fields of application include secure car to car communication  privacy preserving and secure distance evidence for healthcare or location based feature activation  existing technologies do not solve the problem satisfactorily  due to communication restrictions  e g   ultra wide band  uwb  based time of flight measurements  or trusted hardware  e g   using global navigation satellite system  gnss  positioning data \\n  we introduce pls as a solution candidate  it is information theoretically secure  which also means post quantum resistant  and has the potential to run on resource constrained devices with low latency  furthermore  we use wireless channel properties of satellite to earth links  demonstrate the first feasibility study using off the shelf hardware testbeds and present first evaluation results and future directions for research \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         1 million lives  since its emergence in late 2019  this highly contagious disease can easily spread  and if not controlled in a timely fashion  can rapidly incapacitate healthcare systems  the current standard diagnosis method  the reverse transcription polymerase chain reaction  rt  pcr   is time consuming  and subject to low sensitivity  chest radiograph   \\n          more\\n\\n\\n        novel coronavirus  covid 19  has drastically overwhelmed more than 200 countries affecting millions and claiming almost 1 million lives  since its emergence in late 2019  this highly contagious disease can easily spread  and if not controlled in a timely fashion  can rapidly incapacitate healthcare systems  the current standard diagnosis method  the reverse transcription polymerase chain reaction  rt  pcr   is time consuming  and subject to low sensitivity  chest radiograph  cxr   the first imaging modality to be used  is readily available and gives immediate results  however  it has notoriously lower sensitivity than computed tomography  ct   which can be used efficiently to complement other diagnostic methods  this paper introduces a new covid 19 ct scan dataset  referred to as covid ct md  consisting of not only covid 19 cases  but also healthy and subjects infected by community acquired pneumonia  cap   covid ct md dataset  which is accompanied with lobe level  slice level and patient level labels  has the potential to facilitate the covid 19 research  in particular covid ct md can assist in development of advanced machine learning  ml  and deep neural network  dnn  based solutions \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        sequence classification is the task of predicting a class label given a sequence of observations  in many applications such as healthcare monitoring or intrusion detection  early classification is crucial to prompt intervention  in this work  we learn sequence classifiers that favour early classification from an evolving observation trace  while many state o \\n          more\\n\\n\\n        sequence classification is the task of predicting a class label given a sequence of observations  in many applications such as healthcare monitoring or intrusion detection  early classification is crucial to prompt intervention  in this work  we learn sequence classifiers that favour early classification from an evolving observation trace  while many state of the art sequence classifiers are neural networks  and in particular lstms  our classifiers take the form of finite state automata and are learned via discrete optimization  our automata based classifiers are interpretable   supporting explanation  counterfactual reasoning  and human in the loop modification   and have strong empirical performance  experiments over a suite of goal recognition and behaviour classification datasets show our learned automata based classifiers to have comparable test performance to lstm based classifiers  with the added advantage of being interpretable \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         extraction  storage  and querying of patient care information  however  developing a scalable solution is extremely challenging  specifically for radiology reports  as most healthcare institutes use either no template or department institute specific templates  moreover  radiologists  reporting style varies from one to another as sentences are telegraphi \\n          more\\n\\n\\n        automatic structuring of electronic medical records is of high demand for clinical workflow solutions to facilitate extraction  storage  and querying of patient care information  however  developing a scalable solution is extremely challenging  specifically for radiology reports  as most healthcare institutes use either no template or department institute specific templates  moreover  radiologists  reporting style varies from one to another as sentences are telegraphic and do not follow general english grammar rules  we present an ensemble method that consolidates the predictions of three models  capturing various attributes of textual information for automatic labeling of sentences with section labels  these three models are  1  focus sentence model  capturing context of the target sentence  2  surrounding context model  capturing the neighboring context of the target sentence  and finally  3  formatting layout model  aimed at learning report formatting cues  we utilize bi directional lstms  followed by sentence encoders  to acquire the context  furthermore  we define several features that incorporate the structure of reports  we compare our proposed approach against multiple baselines and state of the art approaches on a proprietary dataset as well as 100 manually annotated radiology notes from the mimic iii dataset  which we are making publicly available  our proposed approach significantly outperforms other approaches by achieving 97 1  accuracy \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         among participants  this work offers implications on virtual reality and 3d interactive systems  with specific contributions to virtual therapy  and serious games for healthcare applications \\n          more\\n\\n\\n        there have been a resurge lately on virtual therapy and other virtual  and tele medicine services due to the new normal of practicing  shelter at home   in this paper  we propose a creative drawing game for virtual therapy and investigate user s comfort and movement freedom in a pilot study  in a mixed design study  healthy participants  n 16  8 females  completed one of the easy or hard trajectories of the virtual therapy game in standing and seated arrangements using a virtual reality headset  the results from participants  movement accuracy  task completion time  and usability questionnaires indicate that participants had significant performance differences on two levels of the game based on its difficulty  between subjects factor   but no difference in seated and standing configurations  within subjects factor   also  the hard mode was more favorable among participants  this work offers implications on virtual reality and 3d interactive systems  with specific contributions to virtual therapy  and serious games for healthcare applications \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        in smart healthcare  human activity recognition  har  is considered to be an efficient model in pervasive computation from sensor readings  the ambient assisted living  aal  in the home or community helps the people in providing independent care and enhanced living quality  however  many aal models were restricted using many factors that include computationa \\n          more\\n\\n\\n        in smart healthcare  human activity recognition  har  is considered to be an efficient model in pervasive computation from sensor readings  the ambient assisted living  aal  in the home or community helps the people in providing independent care and enhanced living quality  however  many aal models were restricted using many factors that include computational cost and system complexity  moreover  the har concept has more relevance because of its applications  hence  this paper tempts to implement the har system using deep learning with the data collected from smart sensors that are publicly available in the uc irvine machine learning repository  uci   the proposed model involves three processes   1  data collection   b  optimal feature selection   c  recognition  the data gathered from the benchmark repository is initially subjected to optimal feature selection that helps to select the most significant features  the proposed optimal feature selection is based on a new meta heuristic algorithm called colliding bodies optimization  cbo   an objective function derived by the recognition accuracy is used for accomplishing the optimal feature selection  here  the deep learning model called recurrent neural network  rnn  is used for activity recognition  the proposed model on the concerned benchmark dataset outperforms existing learning methods  providing high performance compared to the conventional models \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         this is useful when we are interested in jointly learning the causal effects of interventions on different subsets of variables in a dag  which is common in field such as healthcare or operations research  we propose the first multi task causal gaussian process  gp  model  which we call dag gp  that allows for information sharing across continuous intervent \\n          more\\n\\n\\n        this paper studies the problem of learning the correlation structure of a set of intervention functions defined on the directed acyclic graph  dag  of a causal model  this is useful when we are interested in jointly learning the causal effects of interventions on different subsets of variables in a dag  which is common in field such as healthcare or operations research  we propose the first multi task causal gaussian process  gp  model  which we call dag gp  that allows for information sharing across continuous interventions and across experiments on different variables  dag gp accommodates different assumptions in terms of data availability and captures the correlation between functions lying in input spaces of different dimensionality via a well defined integral operator  we give theoretical results detailing when and how the dag gp model can be formulated depending on the dag  we test both the quality of its predictions and its calibrated uncertainties  compared to single task models  dag gp achieves the best fitting performance in a variety of real and synthetic settings  in addition  it helps to select optimal interventions faster than competing approaches when used within sequential decision making frameworks  like active learning or bayesian optimization \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         ideas with others about different issues  one such prevalent issue is the covid 19 pandemic  detecting and tracking topics on these kinds of issues would help governments and healthcare companies deal with this phenomenon  in this paper  we propose a novel communicative clustering approach  so called comstreamclust for clustering sub topics inside a broader \\n          more\\n\\n\\n        topic detection is the task of determining and tracking hot topics in social media  twitter is arguably the most popular platform for people to share their ideas with others about different issues  one such prevalent issue is the covid 19 pandemic  detecting and tracking topics on these kinds of issues would help governments and healthcare companies deal with this phenomenon  in this paper  we propose a novel communicative clustering approach  so called comstreamclust for clustering sub topics inside a broader topic  e g  covid 19  the proposed approach was evaluated on two datasets  the covid 19 and the fa cup  the results obtained from comstreamclust approve the effectiveness of the proposed approach when compared to existing methods such as lda \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        to address covid 19 healthcare challenges  we need frequent sharing of health data  knowledge and resources at a global scale  however  in this digital age  data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data  in this paper  we introduce differential privacy \\n          more\\n\\n\\n        to address covid 19 healthcare challenges  we need frequent sharing of health data  knowledge and resources at a global scale  however  in this digital age  data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data  in this paper  we introduce differential privacy by design  dpbd  framework and discuss its embedding into the federated machine learning system  to limit the scope of our paper  we focus on the problem scenario of covid 19 imaging data privacy for disease diagnosis by computer vision and deep learning approaches  we discuss the evaluation of the proposed design of federated machine learning systems and discuss how differential privacy by design  dpbd  framework can enhance data privacy in federated learning systems with scalability and robustness  we argue that scalable differentially private federated learning design is a promising solution for building a secure  private and collaborative machine learning model such as required to combat covid19 challenge \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         catalyzed an intense flurry of progress in computer vision  benchmark tasks have propelled other sub fields of machine learning forward at an equally impressive pace  but in healthcare it has primarily been image processing tasks  such as in dermatology and radiology  that have experienced similar benchmark driven progress  in the present study  we performed \\n          more\\n\\n\\n        the large scale visual recognition challenge based on the well known imagenet dataset catalyzed an intense flurry of progress in computer vision  benchmark tasks have propelled other sub fields of machine learning forward at an equally impressive pace  but in healthcare it has primarily been image processing tasks  such as in dermatology and radiology  that have experienced similar benchmark driven progress  in the present study  we performed a comprehensive review of benchmarks in medical machine learning for structured data  identifying one based on the medical information mart for intensive care  mimic iii  that allows the first direct comparison of predictive performance and thus the evaluation of progress on four clinical prediction tasks  mortality  length of stay  phenotyping  and patient decompensation  we find that little meaningful progress has been made over a 3 year period on these tasks  despite significant community engagement  through our meta analysis  we find that the performance of deep recurrent models is only superior to logistic regression on certain tasks  we conclude with a synthesis of these results  possible explanations  and a list of desirable qualities for future benchmarks in medical machine learning \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         encapsulating common prediction problems in the health domain and allows users to build predictive models with their own data  this system relies on two components  fast healthcare interoperability resources  fhir     a standardized data structure for electronic health systems    and several automl frameworks for automated feature engineering  model selectio \\n          more\\n\\n\\n        an estimated 180 papers focusing on deep learning and ehr were published between 2010 and 2018  despite the common workflow structure appearing in these publications  no trusted and verified software framework exists  forcing researchers to arduously repeat previous work  in this paper  we propose cardea  an extensible open source automated machine learning framework encapsulating common prediction problems in the health domain and allows users to build predictive models with their own data  this system relies on two components  fast healthcare interoperability resources  fhir     a standardized data structure for electronic health systems    and several automl frameworks for automated feature engineering  model selection  and tuning  we augment these components with an adaptive data assembler and comprehensive data  and model  auditing capabilities  we demonstrate our framework via 5 prediction tasks on mimic iii and kaggle datasets  which highlight cardea s human competitiveness  flexibility in problem definition  extensive feature generation capability  adaptable automatic data assembler  and its usability \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n         times in patients with emergent clinical findings  such as ich or pulmonary embolism we analyzed data of n 9 421 emergency setting non contrast head ct studies at a major us healthcare system acquired from november 1  2019 through june 2  2020  and compared two observation periods  namely  i  a pre pandemic epoch from november 1  2019 through february 29  20 \\n          more\\n\\n\\n        objective  to introduce a method for tracking results and utilization of artificial intelligence  tru ai  in radiology  by tracking both large scale utilization and ai results data  the tru ai approach is designed to calculate surrogates for measuring important disease related observational quantities over time  such as the prevalence of intracranial hemorrhage during the covid 19 pandemic outbreak  methods  to quantitatively investigate the clinical applicability of the tru ai approach  we analyzed service requests for automatically identifying intracranial hemorrhage  ich  on head ct using a commercial ai solution  this software is typically used for ai based prioritization of radiologists  reading lists for reducing turnaround times in patients with emergent clinical findings  such as ich or pulmonary embolism we analyzed data of n 9 421 emergency setting non contrast head ct studies at a major us healthcare system acquired from november 1  2019 through june 2  2020  and compared two observation periods  namely  i  a pre pandemic epoch from november 1  2019 through february 29  2020  and  ii  a period during the covid 19 pandemic outbreak  april 1 30  2020  results  although daily ct scan counts were significantly lower during  40 1     7 9  than before  44 4     7 6  the covid 19 outbreak  we found that ich was more likely to be observed by ai during than before the covid 19 outbreak  p 0 05   with approximately one daily ich  case more than statistically expected  conclusion  our results suggest that  by tracking both large scale utilization and ai results data in radiology  the tru ai approach can contribute clinical value as a versatile exploratory tool  aiming at a better understanding of pandemic related effects on healthcare \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        visualization is a useful technology in health science  and especially for community network analysis  because visualization applications in healthcare are typically risk averse  health psychologists can play a significant role in ensuring appropriate and effective uses of visualization techniques in \\n          more\\n\\n\\n        visualization is a useful technology in health science  and especially for community network analysis  because visualization applications in healthcare are typically risk averse  health psychologists can play a significant role in ensuring appropriate and effective uses of visualization techniques in healthcare  in this paper  we examine the role of health psychologists in the triangle of  health science    visualization technology   and  visualization psychology   we conclude that health psychologists can use visualization to aid data intelligence workflows in healthcare and health psychology  while researching into visualization psychology to aid the improvement and optimization of data visualization processes \\n          less\\n\\n',\n",
       " '\\nabstract \\n      \\n        virtual coaching has rapidly evolved into a foundational component of modern clinical practice  at a time when healthcare professionals are in short supply and the demand for low cost treatments is ever increasing  virtual health coaches  vhcs  offer intervention on demand for those limited by finances or geographic access to care  more recently  ai powered \\n          more\\n\\n\\n        virtual coaching has rapidly evolved into a foundational component of modern clinical practice  at a time when healthcare professionals are in short supply and the demand for low cost treatments is ever increasing  virtual health coaches  vhcs  offer intervention on demand for those limited by finances or geographic access to care  more recently  ai powered virtual coaches have become a viable complement to human coaches  however  the push for ai powered coaching systems raises several important issues for researchers  designers  clinicians  and patients  in this paper  we present a novel framework to guide the design and development of virtual coaching systems  this framework augments a traditional data science pipeline with four key guiding goals  reliability  fairness  engagement  and ethics \\n          less\\n\\n']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[articles['clean_text'][i] for i in rankings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.        , 0.56642336, 0.53500898, ..., 0.530837  , 0.58928571,\n",
       "         0.37954769],\n",
       "        [0.47030303, 1.        , 0.48653501, ..., 0.49229075, 0.56071429,\n",
       "         0.41199607],\n",
       "        [0.36121212, 0.39562044, 1.        , ..., 0.32048458, 0.40357143,\n",
       "         0.29891839],\n",
       "        ...,\n",
       "        [0.58424242, 0.65255474, 0.52244165, ..., 1.        , 0.60357143,\n",
       "         0.39921337],\n",
       "        [0.4       , 0.45839416, 0.40574506, ..., 0.3722467 , 1.        ,\n",
       "         0.3480826 ],\n",
       "        [0.46787879, 0.61167883, 0.54578097, ..., 0.44713656, 0.63214286,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(query_vector, X_counts.T)/(np.linalg.norm(query_vector.todense(), axis=1)*np.linalg.norm(X_counts.todense(), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-rank-text-content-by-semantic-similarity-4d2419a84c32 \n",
    "\n",
    "there are two types of methods for text searches. \n",
    "1. term frequency-inverse document frequency (TF-idf) \n",
    "2. semantic similarity\n",
    "\n",
    "Both can be used to calculate the similarity of text. I think the easier way to calculate is the TF-idf because its is an exact comparision. For example 1=1 but if 1=0, the text is not compariable. \n",
    "\n",
    "Semantic similarity is more flexible and is good for ranking content in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
